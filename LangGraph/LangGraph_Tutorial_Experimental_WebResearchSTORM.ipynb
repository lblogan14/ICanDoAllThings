{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15782,
     "status": "ok",
     "timestamp": 1734057731824,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "ugCN5kyiIdUk",
    "outputId": "c2df72a7-be85-4f4f-afec-3770d026ec6a"
   },
   "outputs": [],
   "source": [
    "!pip install -qU langgraph langchain openai tavily-python langchain_openai langchain_community wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1734057731824,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "nxha4gcPJFGv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'YOUR_OPENAI_API_KEY'\n",
    "os.environ['TAVILY_API_KEY'] = 'YOUR_TAVILY_API_KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRA3--6UJFeM"
   },
   "source": [
    "# Web Research (STORM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VXZGmn-JJdU"
   },
   "source": [
    "**STORM** is a research assistant to extend the idea of \"outline-driven RAG\" for richer article generation.\n",
    "\n",
    "STORM is designed to generate Wikipedia-style articles on a user-provided topic. It applies two main insights to produce more organized and comprehensive articles:\n",
    "1. **Creating an outline** (planning) by querying similar topics helps improve converage.\n",
    "2. **Multi-perspective**, grounded (in search) conversation simulation helps increase the reference count and information density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lwOxCdFJq6N"
   },
   "source": [
    "STORM has a few main stages:\n",
    "1. Generate initial outline + Survey related subjects\n",
    "2. Identify distinct perspectives\n",
    "3. \"Interview subject matter experts\" (role-playing LLMs)\n",
    "4. Refine outline (using references)\n",
    "5. Write sections, then write article\n",
    "\n",
    "The expert interview stage occurs between the role-playing article writer and a research expert. The \"expert\" is able to query external knowledge and respond to pointed questions, saving cited sources to a vectorstore so that the later refinement stages can synthesize the full article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugkUDllF5J_K"
   },
   "source": [
    "# Select LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-Ivwiu95Mg0"
   },
   "source": [
    "We need a faster LLM do most of the work, but a slower, long-context model to distill the conversations and write the final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8208,
     "status": "ok",
     "timestamp": 1734057744739,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "pap2HbWjJHjQ"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "fast_llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "long_context_llm = ChatOpenAI(model='gpt-4o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwvhuPdc5cwx"
   },
   "source": [
    "# Generate Initial Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGorKOIl5eqB"
   },
   "source": [
    "For many topics, our LLMs may have an initial idea of the important and related topics. We can generate an initial outline to be refined after our research. Here, we will use our \"fast\" LLM to generate the outline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1734058000742,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "ryWPCKEt5ePx"
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "direct_gen_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            'You are a Wikipedia writer. Write an outline for a Wikipedia page about a user-provided topic.'\n",
    "            ' Be comprehensive and specific.',\n",
    "        ),\n",
    "        (\n",
    "            'user',\n",
    "            '{topic}',\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class SubSection(BaseModel):\n",
    "    subsection_title: str = Field(\n",
    "        ...,\n",
    "        title='Title of the subsection',\n",
    "    )\n",
    "    description: str = Field(\n",
    "        ...,\n",
    "        title='Content of the subsection',\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"### {self.subsection_title}\\n\\n{self.description}\".strip()\n",
    "\n",
    "\n",
    "class Section(BaseModel):\n",
    "    section_title: str = Field(\n",
    "        ...,\n",
    "        title='Title of the section',\n",
    "    )\n",
    "    description: str = Field(\n",
    "        ...,\n",
    "        title='Content of the section',\n",
    "    )\n",
    "    subsections: Optional[List[SubSection]] = Field(\n",
    "        default=None,\n",
    "        title='Titles and descriptions of each subsection of the Wikipedia page.',\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        subsections = \"\\n\\n\".join(\n",
    "            f\"### {subsection.subsection_title}\\n\\n{subsection.description}\"\n",
    "            for subsection in self.subsections or []\n",
    "        )\n",
    "\n",
    "        return f\"## {self.section_title}\\n\\n{self.description}\\n\\n{subsections}\".strip()\n",
    "\n",
    "\n",
    "class Outline(BaseModel):\n",
    "    page_title: str = Field(\n",
    "        ...,\n",
    "        title='Title of the Wikipedia page',\n",
    "    )\n",
    "    sections: List[Section] = Field(\n",
    "        default_factory=list,\n",
    "        title='Titles and descriptions for each section of the Wikipedia page.',\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        sections = \"\\n\\n\".join(section.as_str for section in self.sections)\n",
    "        return f\"# {self.page_title}\\n\\n{sections}\".strip()\n",
    "\n",
    "\n",
    "\n",
    "generate_outline_direct = direct_gen_outline_prompt | fast_llm.with_structured_output(Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5280,
     "status": "ok",
     "timestamp": 1734058006945,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "dYa32UgA8DPu",
    "outputId": "bbdec577-fad6-4e3b-9916-b987459fdbdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Impact of Million-Plus Token Context Window Language Models on RAG\n",
      "\n",
      "## Introduction\n",
      "\n",
      "An overview of language models with million-plus token context windows, the concept of Retrieval-Augmented Generation (RAG), and the importance of studying their impact.\n",
      "\n",
      "## Background\n",
      "\n",
      "A detailed explanation of language models, context windows, and the evolution towards million-plus token models.\n",
      "\n",
      "## Retrieval-Augmented Generation (RAG)\n",
      "\n",
      "Definition of RAG, its components, and the process of combining retrieval and generation in language models.\n",
      "\n",
      "## Impact of Million-Plus Token Context Windows on RAG\n",
      "\n",
      "Analysis of how million-plus token context windows enhance RAG performance.\n",
      "\n",
      "## Advantages of Extended Context Windows\n",
      "\n",
      "Exploration of the benefits of using longer context windows in RAG, including improved coherence, relevance, and information retention.\n",
      "\n",
      "## Challenges and Limitations\n",
      "\n",
      "Discussion of the technical challenges and limitations associated with implementing million-plus token context windows in RAG.\n",
      "\n",
      "## Applications of RAG with Extended Context Windows\n",
      "\n",
      "Examples of real-world applications and industries that benefit from million-plus token context models in RAG.\n",
      "\n",
      "## Future Directions and Research Opportunities\n",
      "\n",
      "Potential future developments in language models and RAG, including ongoing research and technological advancements.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Summary of key points discussed in the article and the overall significance of million-plus token context windows on RAG.\n",
      "\n",
      "## References\n",
      "\n",
      "Citations and references to academic papers, articles, and other resources relevant to the topic.\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "example_topic = \"Impact of million-plus token context window language models on RAG\"\n",
    "\n",
    "initial_outline = generate_outline_direct.invoke({'topic': example_topic})\n",
    "\n",
    "print(initial_outline.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEFxbNTAcMiK"
   },
   "source": [
    "# Expand Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3QPQWencUde"
   },
   "source": [
    "While language models do store some Wikipedia-like knowledge in their parameters, we will get better results by incorporating relevant and recent information using a search engine.\n",
    "\n",
    "We start our search by generating a list of related topics, sourced from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1734058098988,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "y-TwyYU_cT1k"
   },
   "outputs": [],
   "source": [
    "gen_related_topics_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"I'm writing a Wikipedia page for a topic mentioned below.\n",
    "    Please identify and recommend some Wikipedia pages on closely related subjects.\n",
    "    I'm looking for examples that provide insights into interesting aspects commonly associated with this topic,\n",
    "    or examples that help me understand the typical content and structure included in Wikipedia pages for similar topics.\n",
    "\n",
    "    Please list only 3 subjects\n",
    "\n",
    "    Topic of interest: {topic}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "class RelatedSubjects(BaseModel):\n",
    "    topics: List[str] = Field(\n",
    "        description=\"Comprehensive list of related subjects as background research.\",\n",
    "    )\n",
    "\n",
    "\n",
    "expand_chain = gen_related_topics_prompt | fast_llm.with_structured_output(\n",
    "    RelatedSubjects\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 914,
     "status": "ok",
     "timestamp": 1734058106539,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "5sUXvdpIdfdc",
    "outputId": "e9f57759-ee5e-4944-a3b1-e33a4a97e068"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RelatedSubjects(topics=['Token context window', 'Language models', 'Retrieval-Augmented Generation (RAG)'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "related_subjects = await expand_chain.ainvoke({'topic': example_topic})\n",
    "\n",
    "related_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hamxIPyld1co"
   },
   "source": [
    "# Generate Perspectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aKrglECd5Ea"
   },
   "source": [
    "From these related subjects, we can select representative Wikipedia editors as \"subject matter experts\" with distinct background and affiliations.\n",
    "\n",
    "These will help distribute the search process to encourage a more well-rounded final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 93,
     "status": "ok",
     "timestamp": 1734058193461,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "If6j1Khcdo6E"
   },
   "outputs": [],
   "source": [
    "class Editor(BaseModel):\n",
    "    affiliation: str = Field(\n",
    "        description='Primary affiliation of the editor.',\n",
    "    )\n",
    "    name: str = Field(\n",
    "        description='Name of the editor. Name only contains alphanumeric characters, underscores (_), or hyphens (-), with no spaces or periods.',\n",
    "        pattern=r\"^[a-zA-Z0-9_-]{1,64}$\", # only allows alphanumeric characters, _, and - with length between 1 and 64\n",
    "        #pattern=r\"^[a-zA-Z0-9 ._-]{1,64}$\",  # Added space and period\n",
    "    )\n",
    "    role: str = Field(\n",
    "        description='Role of the editor in the context of the topic.',\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"Description of the editor's focus, concerns, and motives.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
    "\n",
    "\n",
    "class Perspectives(BaseModel):\n",
    "    editors: List[Editor] = Field(\n",
    "        description=\"Comprehensive list of editors with their roles and affiliations.\",\n",
    "        # Add a pydantic validation/restriction to be at most M editors\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 94,
     "status": "ok",
     "timestamp": 1734058194912,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "Wc-7Db-9fDFK"
   },
   "outputs": [],
   "source": [
    "gen_perspectives_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            \"\"\"You need to select a diverse (and distinct) group of Wikipedia editors who will work together to create a comprehensive article on the topic.\n",
    "            Each of them represents a different perspective, role, or affiliation related to this topic.\n",
    "            You can use other Wikipedia pages of related topics for inspiration.\n",
    "            For each editor, add a description of what they will focus on.\n",
    "\n",
    "            Wiki page outlines of related topics for inspiration:\n",
    "            {examples}\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\n",
    "            'user',\n",
    "            'Topic of interest: {topic}',\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_perspectives_chain = gen_perspectives_prompt | fast_llm.with_structured_output(Perspectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1734058196353,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "SGamGHZ5f_lw"
   },
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables import chain as as_runnable\n",
    "\n",
    "\n",
    "wikipedia_retriever = WikipediaRetriever(load_all_available_meta=True,\n",
    "                                         top_k_results=1)\n",
    "\n",
    "\n",
    "def format_doc(doc, max_length=1000):\n",
    "    related = \"- \".join(doc.metadata['categories'])\n",
    "    return f\"### {doc.metadata['title']}\\n\\nSummary: {doc.page_content}\\n\\nRelated\\n{related}\"[: max_length]\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(format_doc(doc) for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 102,
     "status": "ok",
     "timestamp": 1734058197785,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "Tquwomemgtg_"
   },
   "outputs": [],
   "source": [
    "@as_runnable\n",
    "async def survey_subjects(topic: str):\n",
    "    related_subjects = await expand_chain.ainvoke({'topic': topic})\n",
    "    retrieved_docs = await wikipedia_retriever.abatch(\n",
    "        related_subjects.topics,\n",
    "        return_exceptions=True,\n",
    "    )\n",
    "\n",
    "    all_docs = []\n",
    "    for docs in retrieved_docs:\n",
    "        if isinstance(docs, BaseException):\n",
    "            continue\n",
    "        all_docs.extend(docs)\n",
    "\n",
    "    formatted = format_docs(all_docs)\n",
    "\n",
    "    return await gen_perspectives_chain.ainvoke({'examples': formatted, 'topic': topic})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 11453,
     "status": "ok",
     "timestamp": 1734058210448,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "5XoXzM7bhcSF"
   },
   "outputs": [],
   "source": [
    "perspectives = await survey_subjects.ainvoke(example_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734058210449,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "rUK_eZEvhiHm",
    "outputId": "90ba4fc3-c544-4d9a-8b13-c3a08e619501"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'editors': [{'affiliation': 'AI Research Lab',\n",
       "   'name': 'DrAliceSmith',\n",
       "   'role': 'AI Researcher',\n",
       "   'description': 'Dr. Alice Smith will focus on the theoretical implications of million-plus token context windows for large language models, particularly how they enhance the performance of retrieval-augmented generation (RAG) systems. She will provide insights into the architecture changes required and how these models can process and utilize extensive context effectively.'},\n",
       "  {'affiliation': 'Tech Industry',\n",
       "   'name': 'JohnDoe123',\n",
       "   'role': 'Software Engineer',\n",
       "   'description': 'John Doe, a software engineer at a leading tech company, will discuss practical applications of million-plus token context windows in RAG implementations. He will share case studies from industry projects that utilize these models to improve information retrieval and generation, illustrating the real-world benefits and challenges faced.'},\n",
       "  {'affiliation': 'Linguistics Department, University',\n",
       "   'name': 'ProfJaneDoe',\n",
       "   'role': 'Linguist and NLP Expert',\n",
       "   'description': 'Professor Jane Doe will explore the linguistic implications of using extended context windows in language models. She will analyze how this impacts natural language processing tasks and the nuances of language understanding and generation, particularly in the context of RAG systems.'},\n",
       "  {'affiliation': 'Data Ethics Organization',\n",
       "   'name': 'EthicsAdvocate',\n",
       "   'role': 'Data Ethicist',\n",
       "   'description': 'The Data Ethicist will address ethical considerations related to the deployment of million-plus token context models, including bias, misinformation, and data privacy concerns. They will examine how these factors affect the integrity of RAG outputs and the responsibility of developers and organizations in mitigating risks.'},\n",
       "  {'affiliation': 'OpenAI',\n",
       "   'name': 'TechLead',\n",
       "   'role': 'Technical Lead',\n",
       "   'description': 'The Technical Lead from OpenAI will provide a perspective on the advancements and research behind million-plus token context windows in RAG. They will discuss the implications for model training, user interaction, and future directions in AI development with respect to user experience and AI capabilities.'},\n",
       "  {'affiliation': 'Government Research Agency',\n",
       "   'name': 'GovResearcher',\n",
       "   'role': 'Policy Analyst',\n",
       "   'description': 'The Policy Analyst will focus on the regulatory and policy implications of deploying million-plus token context models in RAG frameworks. They will discuss how government bodies are responding to the advancements in AI and the importance of creating guidelines that ensure responsible use of technology.'}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perspectives.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "py9wZaNXjMa0"
   },
   "source": [
    "# Expert Dialog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lU1e2U8IjOJD"
   },
   "source": [
    "Each wikipedia writer is primed to role-play using the perspectives presented above. It will ask a series of questions of a second \"domain expert\" with access to a search engine. This generate content to generate a refined outline as well as an updated index of reference documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIQilYmPjdaz"
   },
   "source": [
    "## Interview State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnX8L3qyjfJj"
   },
   "source": [
    "The conversation is cyclic, so we will construct it within its own graph.\n",
    "\n",
    "\n",
    "The State will contain messages, the reference docs, and the editor (with its own \"persona\") to make it easy to parallelize these conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1734058355532,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "CVGCVGmlhj_-"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "def add_messages(left, right):\n",
    "    if not isinstance(left, list):\n",
    "        left = [left]\n",
    "    if not isinstance(right, list):\n",
    "        right = [right]\n",
    "\n",
    "    return left + right\n",
    "\n",
    "\n",
    "def update_references(references, new_references):\n",
    "    if not references:\n",
    "        references = {}\n",
    "    references.update(new_references)\n",
    "    return references\n",
    "\n",
    "\n",
    "def update_editor(editor, new_editor):\n",
    "    # can only set at the outset\n",
    "    if not editor:\n",
    "        return new_editor\n",
    "    return editor\n",
    "\n",
    "\n",
    "\n",
    "class InterviewState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    references: Annotated[Optional[dict], update_references]\n",
    "    editor: Annotated[Optional[Editor], update_editor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EWyIQ90ktMO"
   },
   "source": [
    "## Dialog Roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvr3Q3bykuxc"
   },
   "source": [
    "The graph will have two participants: the wikipedia editor (`generate_question`), who asks questions based on its assigned role, and a domain expert (`gen_answer_chain`), who uses a search engine to answer the questions as accurately as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 105,
     "status": "ok",
     "timestamp": 1734058363719,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "eNqYBOFZkraP"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "gen_qn_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            \"\"\"You are an experienced Wikipedia writer and want to edit a specific page.\n",
    "            Besides your identity as a Wikipedia writer, you have a specific focus when researching the topic.\n",
    "            Now, you are chatting with an expert to get information. Ask good questions to get more useful information.\n",
    "\n",
    "            When you have no more questions to ask, say \"Thank you so much for your help!\" to end the conversation.\n",
    "            Please only ask one question at a time and don't ask what you have asked before.\n",
    "            Your questions should be related to the topic you want to write.\n",
    "            Be comprehensive and curious, gaining as much unique insight from the expert as possible.\n",
    "\n",
    "            Stay true to your specific perspective:\n",
    "            {persona}\n",
    "            \"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='messages', optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def tag_with_name(ai_message: AIMessage, name: str):\n",
    "    ai_message.name = name\n",
    "    return ai_message\n",
    "\n",
    "\n",
    "def swap_roles(state: InterviewState, name: str):\n",
    "    converted = []\n",
    "    for message in state['messages']:\n",
    "        if isinstance(message, AIMessage) and message.name != name:\n",
    "            message = HumanMessage(**message.model_dump(exclude={'type'}))\n",
    "\n",
    "        converted.append(message)\n",
    "    return {'messages': converted}\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "async def generate_question(state: InterviewState):\n",
    "    editor = state['editor']\n",
    "\n",
    "    gn_chain = (\n",
    "        RunnableLambda(swap_roles).bind(name=editor.name)\n",
    "        | gen_qn_prompt.partial(persona=editor.persona)\n",
    "        | fast_llm\n",
    "        | RunnableLambda(tag_with_name).bind(name=editor.name)\n",
    "    )\n",
    "\n",
    "    result = await gn_chain.ainvoke(state)\n",
    "    return {'messages': [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 1148,
     "status": "ok",
     "timestamp": 1734058378445,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "wTacR1sLruoP",
    "outputId": "fb60e4ca-7944-46f3-ef4d-09d4d13b8041"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Yes, that's correct! I'm particularly interested in how the implementation of million-plus token context windows can enhance the performance of retrieval-augmented generation systems. What are some specific architectural changes that you believe are necessary to support such extensive context processing in large language models?\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(f\"So you said you were writing an article on {example_topic}?\")\n",
    "]\n",
    "\n",
    "question = await generate_question.ainvoke(\n",
    "    {\n",
    "        'editor': perspectives.editors[0],\n",
    "        'messages': messages,\n",
    "    }\n",
    ")\n",
    "\n",
    "question['messages'][0].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SW-FbdPsJtb"
   },
   "source": [
    "## Answer questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buEm4mgIsLnR"
   },
   "source": [
    "The `gen_answer_chain` first generates queries (query expansion) to answer the editor's question, then responds with citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 116,
     "status": "ok",
     "timestamp": 1734058404165,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "1pcAiOlusFA4"
   },
   "outputs": [],
   "source": [
    "class Queries(BaseModel):\n",
    "    queries: List[str] = Field(\n",
    "        description=\"Comprehensive list of search engine queries to answer the user's questions.\"\n",
    "    )\n",
    "\n",
    "\n",
    "gen_queries_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            \"You are a helpful research assistant. Query the search engine to answer the user's questions.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='messages', optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "gen_queries_chain = gen_queries_prompt | fast_llm.with_structured_output(Queries, include_raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1248,
     "status": "ok",
     "timestamp": 1734058406550,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "svkT6vMusxq7",
    "outputId": "3288fb2b-640d-476b-cfb8-610cbfeda83c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['million-plus token context windows in language models',\n",
       " 'architectural changes for large context windows in language models',\n",
       " 'retrieval-augmented generation systems with large context',\n",
       " 'impact of long context on language model performance',\n",
       " 'enhancing retrieval-augmented generation with extensive context processing',\n",
       " 'large language models architecture for handling million tokens']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "queries = await gen_queries_chain.ainvoke(\n",
    "    {'messages': [HumanMessage(content=question['messages'][0].content)]}\n",
    ")\n",
    "\n",
    "queries['parsed'].queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1734058416723,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "psQOgoGbs9ez"
   },
   "outputs": [],
   "source": [
    "class AnswerWithCitations(BaseModel):\n",
    "    answer: str = Field(\n",
    "        description=\"Comprehensive answer to the user's question with citations.\"\n",
    "    )\n",
    "    cited_urls: List[str] = Field(\n",
    "        description=\"List of urls cited in the answer.\"\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.answer}\\n\\nCitations:\\n\\n\" + \"\\n\".join(\n",
    "            f\"[{i+1}]: {url}\" for i,url in enumerate(self.cited_urls)\n",
    "        )\n",
    "\n",
    "\n",
    "gen_answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            \"\"\"You are an expert who can use information effectively.\n",
    "            You are chatting with a Wikipedia writer who wants to write a Wikipedia page on the topic you know.\n",
    "            You have gathered the related information and willl now use the information to form a response.\n",
    "\n",
    "            Make your response as informative as possible and make sure every sentence is supported by the gathered information.\n",
    "            Each response must be backed up by a citation from a reliable source, formatted as a footnote, reproducing the URLs after your response.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='messages', optional=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "gen_answer_chain = gen_answer_prompt | fast_llm.with_structured_output(AnswerWithCitations, include_raw=True).with_config(run_name='Generate Answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 112,
     "status": "ok",
     "timestamp": 1734058417319,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "wmhxD4N7uKxY"
   },
   "outputs": [],
   "source": [
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "search = TavilySearchAPIWrapper()\n",
    "tavily_search = TavilySearchResults(api_wrapper=search, max_results=4)\n",
    "\n",
    "@tool\n",
    "async def search_engine(query: str):\n",
    "    \"\"\"Search engine to the internet\"\"\"\n",
    "    results = tavily_search.invoke(query)\n",
    "    return [{'content': r['content'], 'url': r['url']} for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4307,
     "status": "ok",
     "timestamp": 1734060076647,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "kf-_xPiFCJ0b",
    "outputId": "320b06d8-3b23-4bb9-e163-33c2048b6057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/3.0 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m2.3/3.0 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "! pip install -qU duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 89,
     "status": "ok",
     "timestamp": 1734060078868,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "HIpTm8_yB2Cy"
   },
   "outputs": [],
   "source": [
    "from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "search_engine = DuckDuckGoSearchAPIWrapper()\n",
    "\n",
    "def search_engine(query: str):\n",
    "    \"\"\"Search engine to the internet\"\"\"\n",
    "    results = DuckDuckGoSearchAPIWrapper()._ddgs_text(query)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1180,
     "status": "ok",
     "timestamp": 1734060174213,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "E-m8lktFCQAE",
    "outputId": "6e20ba86-fb66-4b2e-e13e-825d773f204f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'The Absolute Best Products Available on Amazon Right Now',\n",
       "  'href': 'https://katiecouric.com/lifestyle/best-amazon-products-to-buy-right-now/',\n",
       "  'body': \"The 28 top deals, hidden gems, and best-reviewed items on Amazon, some of which are are sale right now during Amazon Prime Day. From Apple AirPods to TikTok's favorite backpack, here's what's worth hunting for this Prime Day. ... the Katie Couric Media staff scoured the mega retailer's offerings to compile a list of must-have products ...\"},\n",
       " {'title': '20 Things On Amazon That Make Perfect Gifts - HuffPost',\n",
       "  'href': 'https://www.huffpost.com/entry/best-gifts-amazon_l_67565020e4b0015618de03bf',\n",
       "  'body': 'Hands down, the best product for the money.\" — Natalie. $46 at Amazon. Advertisement. 7. amazon.com. A tabletop fire pit. Promising review: \"Love this fun little table top firepit. Just what we needed when we don\\'t feel like lighting a fire for s\\'mores!\" ... — Amazon Customer. $16.99 at Amazon. 11. amazon.com. A pack of waterproof ...'},\n",
       " {'title': '68 of the Best Things to Buy on Amazon Right Now - Good Housekeeping',\n",
       "  'href': 'https://www.goodhousekeeping.com/home-products/g26327540/best-selling-amazon-products/',\n",
       "  'body': 'From top-rated bed sheets and the best-performing blenders to expert-tested vacuums and more, our pros have evaluated thousands of Amazon best-sellers first-hand. So if shopping on Amazon has left ...'},\n",
       " {'title': 'Discover The 67 Best Products You Can Buy On Amazon - HuffPost',\n",
       "  'href': 'https://www.huffpost.com/entry/best-products-amazon_l_66c39ad9e4b0972f8ace190a',\n",
       "  'body': \"A Baroque mirror no one will believe came from Amazon with Prime shipping; A pair of unbelievably soft leggings in a super-buttery, lightweight fabric so comfy, you'll want to buy them in every color; The newest 2nd gen AirPods Pro with active noise cancellation, spatial audio, three silicone tips for customized fit, and over 24 hours of listening time\"},\n",
       " {'title': '70 Of The Best Things To Buy On Amazon - BuzzFeed',\n",
       "  'href': 'https://www.buzzfeed.com/maitlandquitmeyer/best-things-to-buy-on-amazon',\n",
       "  'body': 'Sticky rollers work fine for clothes but this is the only product that has ever COMPLETELY removed all the cat hair from my bed. I have a long-haired 20-pound. tabby and if you run your hands up ...'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_engine(\"best product on amazon.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1734058419499,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "k5T83fUevOEi"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "async def gen_answer(\n",
    "    state: InterviewState,\n",
    "    config: Optional[RunnableConfig] = None,\n",
    "    name: str = \"Subject_Matter_Expert\",\n",
    "    max_str_len: int = 15000,\n",
    "):\n",
    "    # Convert all other AI messages\n",
    "    swapped_state = swap_roles(state, name)\n",
    "\n",
    "    queries = await gen_queries_chain.ainvoke(swapped_state)\n",
    "    query_results = await search_engine.abatch(\n",
    "        queries['parsed'].queries,\n",
    "        config,\n",
    "        return_exceptions=True,\n",
    "    )\n",
    "    successful_results = [\n",
    "        res for res in query_results if not isinstance(res, Exception)\n",
    "    ]\n",
    "    all_query_results = {\n",
    "        res['url']: res['content'] for results in successful_results for res in results\n",
    "    }\n",
    "\n",
    "    # We could be more precise about handling max token length if we want to\n",
    "    dumped = json.dumps(all_query_results)[:max_str_len]\n",
    "    ai_message: AIMessage = queries['raw']\n",
    "    tool_call = queries['raw'].tool_calls[0]\n",
    "    tool_id = tool_call['id']\n",
    "    tool_message = ToolMessage(tool_call_id=tool_id, content=dumped)\n",
    "\n",
    "    swapped_state['messages'].extend([ai_message, tool_message])\n",
    "\n",
    "    # Only update the shared state with the final answer to avoid polluting the dialogue history\n",
    "    # with intermediate messages\n",
    "    generated = await gen_answer_chain.ainvoke(swapped_state)\n",
    "    cited_urls = set(generated['parsed'].cited_urls)\n",
    "\n",
    "    # Save the retrieved information to a shared state for future reference\n",
    "    cited_references = {\n",
    "        k: v for k, v in all_query_results.items() if k in cited_urls\n",
    "    }\n",
    "    formatted_message = AIMessage(name=name, content=generated['parsed'].as_str)\n",
    "\n",
    "    return {'messages': [formatted_message], 'references': cited_references}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "executionInfo": {
     "elapsed": 12859,
     "status": "ok",
     "timestamp": 1734058433240,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "RNjYOCAOzWLj",
    "outputId": "2907949f-5d16-431c-fe97-c303b2d1e375"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"The implementation of million-plus token context windows in retrieval-augmented generation (RAG) systems can significantly enhance their performance by allowing these models to utilize and process a much larger amount of information in a single pass. This capability can improve the relevance and accuracy of generated responses, particularly in complex tasks requiring extensive information synthesis. To support such extensive context processing, several architectural changes are necessary:\\n\\n1. **Memory Augmentation**: Incorporating external memory architectures can help models manage and retrieve vast quantities of information more effectively. Techniques such as memory-augmented neural networks or differentiable neural computers can be integrated to facilitate the storage and retrieval of long-term context information, enabling the model to access and utilize more than just the immediate input context.\\n\\n2. **Sparse Attention Mechanisms**: Traditional attention mechanisms can become computationally expensive with increased context sizes. Implementing sparse attention or local attention strategies can allow the model to focus on the most relevant portions of the context, thereby reducing the computational burden while maintaining performance. This approach can be seen in models like Reformer and Longformer, which utilize efficient attention mechanisms to handle long sequences without a quadratic increase in computational cost.\\n\\n3. **Hierarchical Context Processing**: Organizing the input into hierarchical structures can facilitate the processing of large contexts. For instance, segmenting long texts into smaller, manageable chunks that are processed sequentially or in parallel can help models maintain coherence and relevance across extended contexts. This is akin to the approaches used in hierarchical transformers.\\n\\n4. **Enhanced Training Techniques**: Training methods such as curriculum learning, where models are progressively trained on longer contexts, or using synthetic long-context data can help improve the model's ability to handle extensive inputs. This ensures that the model learns to effectively leverage the information available across large contexts.\\n\\n5. **Improved Tokenization Strategies**: Adopting more efficient tokenization techniques that reduce the number of tokens generated from the same input can also enhance performance. This could involve using subword tokenization methods that better capture the semantics of the input data, allowing for more efficient context utilization.\\n\\n6. **Integration of Retrieval Systems**: RAG systems can be significantly improved by integrating external retrieval systems that can fetch relevant documents or data based on the query context, providing the model with additional information to consider when generating responses. This dual-system approach allows the model to benefit from both generated and retrieved content, enhancing overall output quality.\\n\\nImplementing these architectural changes can lead to improved performance in retrieval-augmented generation systems, enabling them to effectively utilize million-plus token context windows for more informed and contextually relevant responses.\\n\\nCitations:\\n\\n[1]: https://arxiv.org/abs/2007.06799\\n[2]: https://arxiv.org/abs/1910.10683\\n[3]: https://arxiv.org/abs/2004.05150\\n[4]: https://arxiv.org/abs/2006.03654\\n[5]: https://arxiv.org/abs/2005.14165\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_answer = await gen_answer(\n",
    "    {'messages': [HumanMessage(content=question['messages'][0].content)]}\n",
    ")\n",
    "\n",
    "example_answer['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cU2or8EjzmrB"
   },
   "source": [
    "## Construct the interview Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5W2MQ-TDztGI"
   },
   "source": [
    "Now that we have defined the editor and domain expert, we can compose them in a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734058439540,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "4SCcOHL9zlBT"
   },
   "outputs": [],
   "source": [
    "from langgraph.pregel import RetryPolicy\n",
    "\n",
    "max_num_turns = 5\n",
    "\n",
    "\n",
    "def route_messages(state: InterviewState, name: str = \"Subject_Matter_Expert\"):\n",
    "    messages = state['messages']\n",
    "    num_responses = len(\n",
    "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
    "    )\n",
    "\n",
    "    if num_responses >= max_num_turns:\n",
    "        print(\"Reached max number of turns\")\n",
    "        return END\n",
    "\n",
    "    last_question = messages[-2]\n",
    "    if last_question.content.endswith(\"Thank you so much for your help!\"):\n",
    "        return END\n",
    "\n",
    "    return \"ask_question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 95,
     "status": "ok",
     "timestamp": 1734058439833,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "xP9czmXQ0hxJ"
   },
   "outputs": [],
   "source": [
    "builder = StateGraph(InterviewState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node('ask_question', generate_question, retry=RetryPolicy(max_attempts=3))\n",
    "builder.add_node('answer_question', gen_answer, retry=RetryPolicy(max_attempts=3))\n",
    "# Add edges\n",
    "builder.add_edge(START, 'ask_question')\n",
    "builder.add_edge('ask_question', 'answer_question')\n",
    "builder.add_conditional_edges('answer_question', route_messages)\n",
    "\n",
    "\n",
    "interview_graph = builder.compile(checkpointer=False).with_config(\n",
    "    run_name=\"Conduct Interviews\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 852,
     "status": "ok",
     "timestamp": 1734058441178,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "cNZLSlab2Rci",
    "outputId": "f6c7b17a-c0df-4e76-809e-dc373294a97e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(interview_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1734058490523,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "Dl6UrBrK2WEE",
    "outputId": "0330e4b9-0a3b-4fe4-f7d4-b0745547925c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'editor': Editor(affiliation='AI Research Lab', name='DrAliceSmith', role='AI Researcher', description='Dr. Alice Smith will focus on the theoretical implications of million-plus token context windows for large language models, particularly how they enhance the performance of retrieval-augmented generation (RAG) systems. She will provide insights into the architecture changes required and how these models can process and utilize extensive context effectively.'),\n",
       " 'messages': [AIMessage(content='So you said you were writing an article on Impact of million-plus token context window language models on RAG', additional_kwargs={}, response_metadata={}, name='Subject_Matter_Expert')]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_step = None\n",
    "\n",
    "initial_state = {\n",
    "    'editor': perspectives.editors[0],\n",
    "    'messages': [\n",
    "        AIMessage(\n",
    "            content=f\"So you said you were writing an article on {example_topic}\",\n",
    "            name=\"Subject_Matter_Expert\",\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36880,
     "status": "ok",
     "timestamp": 1734058570695,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "5-m-MUcE2kfx",
    "outputId": "31863f4b-8043-4106-960e-2c3722b1b991"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask_question\n",
      "--  [AIMessage(content=\"Yes, I'm focusing on the theoretical implications of million-plus token context windows for large language models, particularly in the context of retrieval-augmented generation (RAG) systems. Could you explain how the ability to process such extensive context could fundamentally \n",
      "answer_question\n",
      "--  [AIMessage(content='The advent of million-plus token context windows in large language models (LLMs) represents a transformative shift in the capabilities of retrieval-augmented generation (RAG) systems. Primarily, such extensive context windows allow these models to retain and process significantly\n",
      "ask_question\n",
      "--  [AIMessage(content='DrAliceSmith: Thank you for that insightful explanation! How do you envision the architectural changes that might be necessary to support the implementation of million-plus token context windows in large language models, especially in the context of RAG systems?', additional_kwar\n",
      "answer_question\n",
      "--  [AIMessage(content=\"To effectively implement million-plus token context windows in large language models (LLMs), significant architectural changes would be necessary, particularly for retrieval-augmented generation (RAG) systems. Firstly, one of the most critical shifts would involve the enhancement\n",
      "ask_question\n",
      "--  [AIMessage(content='DrAliceSmith: This is incredibly helpful information! In your opinion, what are some specific challenges or limitations that might arise when implementing these large context windows in RAG systems, and how might researchers address these issues?', additional_kwargs={'refusal': N\n",
      "answer_question\n",
      "--  [AIMessage(content='While implementing million-plus token context windows in retrieval-augmented generation (RAG) systems presents numerous opportunities, it also poses several significant challenges and limitations. One of the primary challenges is computational efficiency. Processing larger contex\n",
      "ask_question\n",
      "--  [AIMessage(content='DrAliceSmith: Thank you so much for your help!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 1834, 'total_tokens': 1846, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reason\n",
      "Reached max number of turns\n",
      "answer_question\n",
      "--  [AIMessage(content=\"You're welcome! I'm glad I could assist you with your research. If you have any more questions or need further information in the future, feel free to reach out. Good luck with your Wikipedia page on the impact of million-plus token context windows in language models!\\n\\nCitation\n"
     ]
    }
   ],
   "source": [
    "async for step in interview_graph.astream(initial_state):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(\"-- \", str(step[name]['messages'])[:300])\n",
    "\n",
    "final_step = step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1734058579265,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "IVG86KVE3G6U",
    "outputId": "7209a357-0294-4d0e-9d64-a9709c0083af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content=\"You're welcome! I'm glad I could assist you with your research. If you have any more questions or need further information in the future, feel free to reach out. Good luck with your Wikipedia page on the impact of million-plus token context windows in language models!\\n\\nCitations:\\n\\n\", additional_kwargs={}, response_metadata={}, name='Subject_Matter_Expert')],\n",
       " 'references': {}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state = next(iter(final_step.values()))\n",
    "final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiBTbn6c3k62"
   },
   "source": [
    "# Refine Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCHrfGGO3mhJ"
   },
   "source": [
    "At this point in STORM, we have conducted a large amount of research from different perspecties. It is time to refine the original outline based on these investigations.\n",
    "\n",
    "Below, crate a chain using the LLM with a long context window to update the orignal outline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tch8lh1e3kcJ"
   },
   "outputs": [],
   "source": [
    "refine_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            \"\"\"You are a Wikipedia writer. You have gathered information from experts and search engines.\n",
    "            Now, you are refining the outline of the Wikipedia pages.\n",
    "            You need to make sure that the outline is comprehensive and specific.\n",
    "            Topic you are writing about: {topic}\n",
    "\n",
    "            Old outline:\n",
    "\n",
    "            {old_outline}\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\n",
    "            'user',\n",
    "            \"\"\"Refine the outline based on your conversation with subject-matter experts:\\n\\n\n",
    "            Conversations:\\n\\n{conversations}\\n\\n\n",
    "            Write the refined Wikipedia outline:,\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "refine_outline_chain = refine_outline_prompt | long_context_llm.with_structured_output(Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTxKTXQg1WYu"
   },
   "outputs": [],
   "source": [
    "refined_outline = refine_outline_chain.invoke(\n",
    "    {\n",
    "        'topic': example_topic,\n",
    "        'old_outline': initial_outline.as_str,\n",
    "        'conversations': \"\\n\\n\".join(\n",
    "            f\"### {m.name}\\n\\n{m.content}\" for m in final_state['messages']\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1734040108287,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "ruVqAyti1_UG",
    "outputId": "97371364-d868-4518-fdc2-04594c760195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Impact of Million-Plus Token Context Window Language Models on RAG\n",
      "\n",
      "## Introduction\n",
      "\n",
      "An overview of language models, context windows, and the significance of Retrieval-Augmented Generation (RAG) in natural language processing, with a focus on advancements in context window size.\n",
      "\n",
      "## Understanding Context Windows\n",
      "\n",
      "A detailed explanation of context windows within the framework of language models, including the transition from small to million-plus token context windows.\n",
      "\n",
      "### Evolution of Context Windows\n",
      "\n",
      "Tracing the development and expansion of context windows from small to extensive million-plus token capabilities.\n",
      "\n",
      "## Retrieval-Augmented Generation (RAG)\n",
      "\n",
      "Definition and explanation of RAG, including its components, operational mechanics, and its role in enhancing language model outputs.\n",
      "\n",
      "### Components of RAG\n",
      "\n",
      "An overview of the key components of RAG systems and how they function together.\n",
      "\n",
      "### Significance in NLP\n",
      "\n",
      "The importance of RAG in natural language processing applications and its impact on the quality of language model outputs.\n",
      "\n",
      "## Advanced Training Methodologies\n",
      "\n",
      "An in-depth look at advanced training techniques like LongRoPE and PoSE that enhance RAG performance.\n",
      "\n",
      "### LongRoPE\n",
      "\n",
      "Exploration of the LongRoPE methodology and its impact on extending context windows beyond 2 million tokens.\n",
      "\n",
      "### Positional Skip-wise (PoSE)\n",
      "\n",
      "Analysis of the PoSE technique in optimizing retrieval processes for long context windows.\n",
      "\n",
      "## Impact on RAG\n",
      "\n",
      "How million-plus token context windows, supported by advanced methodologies, influence the effectiveness and performance of RAG systems.\n",
      "\n",
      "### Accuracy and Relevance\n",
      "\n",
      "The effects on the accuracy and relevance of generated responses in RAG systems.\n",
      "\n",
      "### Computational Efficiency\n",
      "\n",
      "Discussion on how these methods maintain computational efficiency while managing long context windows.\n",
      "\n",
      "## Case Studies\n",
      "\n",
      "Examples of RAG implementations with million-plus token context models, highlighting successes and challenges.\n",
      "\n",
      "### Successful Implementations\n",
      "\n",
      "Case studies demonstrating successful RAG applications using extensive context windows.\n",
      "\n",
      "### Challenges Faced\n",
      "\n",
      "Potential challenges encountered during implementations and how they were addressed.\n",
      "\n",
      "## Benefits of Million-Plus Token Context Windows in RAG\n",
      "\n",
      "A discussion of the advantages these extensive context windows provide in RAG applications, including improved user satisfaction and engagement.\n",
      "\n",
      "## Challenges and Limitations\n",
      "\n",
      "Analysis of potential drawbacks and limitations of using million-plus token context windows in RAG, including computational costs and complexity.\n",
      "\n",
      "## Future Directions\n",
      "\n",
      "Speculation on future developments in language models and RAG systems, focusing on potential improvements and research areas.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "A summary of the main points covered in the article and the overall impact of million-plus token context windows on RAG.\n",
      "\n",
      "## References\n",
      "\n",
      "A curated list of academic papers, articles, and other resources for further reading on the topics discussed.\n"
     ]
    }
   ],
   "source": [
    "print(refined_outline.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0xB_dpR2GKH"
   },
   "source": [
    "# Generate Article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JalPzC72H10"
   },
   "source": [
    "Now it's time to generate the full article. We will first divide-and-conquer, so that each section can be tackled by an individual LLM. Then we will prompt the long-term LLLM to refine the finished article (since each section may use an inconsistent voice)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJdEdxu42WvX"
   },
   "source": [
    "## Create Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmwSCSRY2YZN"
   },
   "source": [
    "The research process uncovers a large number of reference documents that we may want to query during the final article-writing process.\n",
    "\n",
    "So we need to create a retriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1oZRBK6j2Blx"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "reference_docs = [\n",
    "    Document(page_content=v, metadata={'source': k})\n",
    "    for k, v in final_state['references'].items()\n",
    "]\n",
    "\n",
    "# This really does NOT need to be a vector store for this size of data.\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    reference_docs,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1734040381893,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "vboal9c53DYY",
    "outputId": "f169d86a-d41c-4e4a-daa5-63ab882d8f02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='cb2e27ef-857a-40dd-97be-f011d6f945ac', metadata={'source': 'https://github.com/Xnhyacinth/Awesome-LLM-Long-Context-Modeling'}, page_content='Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make your LLMs use External Data More Wisely. ... LongRoPE: Extending LLM ContextWindow Beyond 2 Million Tokens. Yiran Ding, Li Lyna Zhang, Chengruidong Zhang, Yuanyuan Xu, Ning Shang, Jiahang Xu, Fan Yang, Mao Yang. ... EasyAnimate: A High-Performance Long Video'),\n",
       " Document(id='3aed1356-cc96-4322-8172-899531e89524', metadata={'source': 'https://thesalt.substack.com/p/rag-and-long-context-llms-when-do'}, page_content='The study includes a large-scale evaluation of 50 RAG systems and 10 long-context LLMs. Key findings are: (1) SummHay is challenging for all systems, with performance below human levels, (2) trade-offs exist between RAG pipelines and long-context LLMs, with RAG improving citation quality but compromising insight coverage, (3) advanced RAG')]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is a long context LLM?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVSeWvg63PKP"
   },
   "source": [
    "## Generate Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQuzqsxu3RC8"
   },
   "source": [
    "Next we can generate the sections using the indexed documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdwoLA4S3GdV"
   },
   "outputs": [],
   "source": [
    "class SubSection(BaseModel):\n",
    "    subsection_title: str = Field(\n",
    "        ...,\n",
    "        title='Title of the subsection'\n",
    "    )\n",
    "    content: str = Field(\n",
    "        ...,\n",
    "        title='Fulll content of the subsection. Include [#] citations to the cited sources where rellevant.'\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"### {self.subsection_title}\\n\\n{self.content}\".strip()\n",
    "\n",
    "\n",
    "class WikiSection(BaseModel):\n",
    "    section_title: str = Field(\n",
    "        ...,\n",
    "        title=\"Title of the section\"\n",
    "    )\n",
    "    content: str = Field(\n",
    "        ...,\n",
    "        title=\"Full content of the section\"\n",
    "    )\n",
    "    subsections: Optional[List[SubSection]] = Field(\n",
    "        default=None,\n",
    "        title=\"Titles and descriptions for each subsection of the Wikipedia page.\",\n",
    "    )\n",
    "    citations: List[str] = Field(\n",
    "        default_factory=list\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        subsections = \"\\n\\n\".join(\n",
    "            subsection.as_str for subsection in self.subsections or []\n",
    "        )\n",
    "        citations = \"\\n\".join(\n",
    "            [f\" [{i}] {cit}\" for i, cit in enumerate(self.citations)]\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            f\"## {self.section_title}\\n\\n{self.content}\\n\\n{subsections}\".strip()\n",
    "            + f\"\\n\\n{citations}\".strip()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6JarSBA4wc_"
   },
   "outputs": [],
   "source": [
    "section_writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            \"\"\"You are an expert Wikipedia writer. Complete your assigned WikiSection from the following outlline\\n\\n:\n",
    "            {outline}\\n\\nCite your sources, using the following references:\\n\\n<Documents>\\n{docs}\\n</Documents>\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            'user',\n",
    "            \"Write the full WikiSection for the {section} section.\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "async def retrieve(inputs: dict):\n",
    "    docs = await retriever.ainvoke(inputs['topic'] + \": \" + inputs['section'])\n",
    "    formatted = \"\\n\".join(\n",
    "        [\n",
    "            f'<Document href=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "    return {'docs': formatted, **inputs}\n",
    "\n",
    "\n",
    "section_writer = (\n",
    "    retrieve\n",
    "    | section_writer_prompt\n",
    "    | long_context_llm.with_structured_output(WikiSection)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqdcvMiS5zoP"
   },
   "outputs": [],
   "source": [
    "section = await section_writer.ainvoke(\n",
    "    {\n",
    "        'outline': refined_outline.as_str,\n",
    "        'section': refined_outline.sections[1].section_title,\n",
    "        'topic': example_topic,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1734041184711,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "ljnO_qsI6EYD",
    "outputId": "95a51624-a164-4ba0-be23-5c9162f43960"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Understanding Context Windows\n",
      "\n",
      "Context windows are a foundational concept in language models, representing the span of text data that a model can consider at one time. They dictate the amount of preceding context a language model can use when generating text, which directly influences the coherence and relevance of its outputs. Traditional language models have operated with relatively limited context windows, often constrained to a few hundred tokens. However, recent advancements have seen the expansion of context windows to encompass millions of tokens, dramatically changing how these models process and generate language.\n",
      "\n",
      "### Evolution of Context Windows\n",
      "\n",
      "The evolution of context windows in language models has been marked by a steady increase in size, driven by the need for more coherent and contextually aware outputs. Initially, language models like GPT-2 and BERT utilized context windows limited to 512 tokens. This limitation posed significant challenges, especially in tasks requiring the understanding of longer texts or maintaining thematic continuity over extended narratives. With the advent of models like LongRoPE, context windows have expanded to accommodate over two million tokens, vastly enhancing the model's ability to maintain context over long sequences. This progression has been pivotal in enabling language models to tackle more complex tasks, such as summarizing lengthy documents or engaging in multi-turn dialogues with improved accuracy and relevance [1][2].[0] https://thesalt.substack.com/p/rag-and-long-context-llms-when-do\n",
      " [1] https://github.com/Xnhyacinth/Awesome-LLM-Long-Context-Modeling\n"
     ]
    }
   ],
   "source": [
    "print(section.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQxlEvNi6PG_"
   },
   "source": [
    "## Generate Final Article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhnwAl8i6S71"
   },
   "source": [
    "Now we can rewrite the draft to appropriately group all the citations and maintaiin a consistent voicce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENhyOl3K6Kje"
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            \"\"\"You are an expert Wikipedia author. Write the complete wiki article on {topic} using the following section drafts:\\n\\n\n",
    "            {draft}\\n\\nStrictlly follow Wikipedia format guidelines.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            'user',\n",
    "            \"\"\"Write the complete Wiki article using markdown format. Organize citations using footnotes like \"[1]\",\n",
    "            avoiding duplicates in the footer. Include URLs in the footer.\n",
    "            \"\"\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "writer = writer_prompt | long_context_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11041,
     "status": "ok",
     "timestamp": 1734041458116,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "8exbMF4P7A2y",
    "outputId": "8307fe18-861f-4400-8f10-8db431500994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Impact of Million-Plus Token Context Window Language Models on Retrieval-Augmented Generation (RAG)\n",
      "\n",
      "## Introduction\n",
      "\n",
      "In recent years, the field of natural language processing (NLP) has witnessed significant advancements, particularly in the development of language models with extended context windows. These advancements have profound implications for various applications, including Retrieval-Augmented Generation (RAG), where the ability to process and generate language with extensive context is crucial for improving the quality and relevance of outputs. This article explores the impact of million-plus token context window language models on RAG, highlighting the evolution of context windows and their significance in modern NLP applications.\n",
      "\n",
      "## Understanding Context Windows\n",
      "\n",
      "Context windows are a foundational concept in language models, representing the span of text data that a model can consider at one time. They dictate the amount of preceding context a language model can use when generating text, which directly influences the coherence and relevance of its outputs. Traditional language models have operated with relatively limited context windows, often constrained to a few hundred tokens. However, recent advancements have seen the expansion of context windows to encompass millions of tokens, dramatically changing how these models process and generate language.\n",
      "\n",
      "## Evolution of Context Windows\n",
      "\n",
      "The evolution of context windows in language models has been marked by a steady increase in size, driven by the need for more coherent and contextually aware outputs. Initially, language models like GPT-2 and BERT utilized context windows limited to 512 tokens. This limitation posed significant challenges, especially in tasks requiring the understanding of longer texts or maintaining thematic continuity over extended narratives. With the advent of models like LongRoPE, context windows have expanded to accommodate over two million tokens, vastly enhancing the model's ability to maintain context over long sequences. This progression has been pivotal in enabling language models to tackle more complex tasks, such as summarizing lengthy documents or engaging in multi-turn dialogues with improved accuracy and relevance.[1][2]\n",
      "\n",
      "## Impact on Retrieval-Augmented Generation (RAG)\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) leverages external information retrieval systems to enhance the capabilities of language models by incorporating additional context and knowledge into the generation process. The expansion of context windows in language models has a significant impact on RAG systems, enabling them to handle more extensive and complex queries and produce more informed and contextually relevant responses. With larger context windows, RAG models can seamlessly integrate retrieved documents, maintain thematic continuity across longer conversations, and generate coherent summaries of vast information sets.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "The development of language models with million-plus token context windows marks a critical milestone in the field of NLP. These advancements have not only improved the coherence and relevance of language model outputs but have also transformed the capabilities of Retrieval-Augmented Generation systems. As context windows continue to expand, language models are expected to offer even more sophisticated and nuanced language understanding, further enhancing their applicability across a wide range of tasks and industries.\n",
      "\n",
      "## References\n",
      "\n",
      "[1] https://thesalt.substack.com/p/rag-and-long-context-llms-when-do\n",
      "\n",
      "[2] https://github.com/Xnhyacinth/Awesome-LLM-Long-Context-Modeling"
     ]
    }
   ],
   "source": [
    "for tok in writer.stream(\n",
    "    {\n",
    "        'topic': example_topic,\n",
    "        'draft': section.as_str,\n",
    "    }\n",
    "):\n",
    "    print(tok, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhtTxbID7WeT"
   },
   "source": [
    "# Final Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qq6yTlwf7X9Y"
   },
   "source": [
    "Now we can string everything together. We will have 6 main stages in sequences:\n",
    "1. Generate the initial outline + perspectives\n",
    "2. Batch converse with each perspective to expand the content for the article\n",
    "3. Refine the outline based on the cconversations\n",
    "4. Index the reference docs from the conversations\n",
    "5. Write the indiviidual sections of the article\n",
    "6. Write the final Wikipage.\n",
    "\n",
    "We will also have the state to track the outputs of each stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1734044496355,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "f4qHfOjN7KoF"
   },
   "outputs": [],
   "source": [
    "class MainState(TypedDict):\n",
    "    topic: str\n",
    "    outline: Outline\n",
    "    editors: List[Editor]\n",
    "    interview_results: List[InterviewState]\n",
    "    # The final sections output\n",
    "    sections: List[WikiSection]\n",
    "    article: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "executionInfo": {
     "elapsed": 98,
     "status": "ok",
     "timestamp": 1734044499666,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "7FcaUmA28Kg8"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def initialize_research(state: MainState):\n",
    "    topic = state['topic']\n",
    "    coros = (\n",
    "        generate_outline_direct.ainvoke({'topic': topic}), # -> outline\n",
    "        survey_subjects.ainvoke(topic), # -> perspectives\n",
    "    )\n",
    "    results = await asyncio.gather(*coros)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        'outline': results[0],\n",
    "        'editors': results[1].editors,\n",
    "    }\n",
    "\n",
    "\n",
    "async def conduct_interviews(state: MainState):\n",
    "    topic = state['topic']\n",
    "    initial_states = [\n",
    "        {\n",
    "            'editor': editor,\n",
    "            'messages': [\n",
    "                AIMessage(\n",
    "                    content=f\"So you said you were writing an article on {topic}?\",\n",
    "                    name=\"Subject_Matter_Expert\",\n",
    "                )\n",
    "            ],\n",
    "        }\n",
    "        for editor in state['editors']\n",
    "    ]\n",
    "\n",
    "    # We call in to the sub-graph here to parallelize the interviews\n",
    "    interview_results = await interview_graph.abatch(initial_states)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        'interview_results': interview_results,\n",
    "    }\n",
    "\n",
    "\n",
    "def format_conversation(interview_state):\n",
    "    messages = interview_state['messages']\n",
    "\n",
    "    convo = \"\\n\".join(f\"{m.name}: {m.content}\" for m in messages)\n",
    "    return f\"Conversation with {interview_state['editor'].name}\\n\\n\" + convo\n",
    "\n",
    "\n",
    "async def refine_outline(state: MainState):\n",
    "    convos = \"\\n\\n\".join(\n",
    "        [\n",
    "            format_conversation(interview_state)\n",
    "            for interview_state in state['interview_results']\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    updated_outline = await refine_outline_chain.ainvoke(\n",
    "        {\n",
    "            'topic': state['topic'],\n",
    "            'old_outline': state['outline'].as_str,\n",
    "            'conversations': convos,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return {**state, 'outline': updated_outline}\n",
    "\n",
    "\n",
    "async def index_references(state: MainState):\n",
    "    all_docs = []\n",
    "    for interview_state in state['interview_results']:\n",
    "        reference_docs = [\n",
    "            Document(page_content=v, metadata={'source': k})\n",
    "            for k,v in interview_state['references'].items()\n",
    "        ]\n",
    "        all_docs.extend(reference_docs)\n",
    "\n",
    "    await vectorstore.aadd_documents(all_docs)\n",
    "    return state\n",
    "\n",
    "\n",
    "async def write_sections(state: MainState):\n",
    "    outline = state['outline']\n",
    "    sections = await section_writer.abatch(\n",
    "        [\n",
    "            {\n",
    "                'outline': outline.as_str,\n",
    "                'section': section.section_title,\n",
    "                'topic': state['topic'],\n",
    "            }\n",
    "            for section in outline.sections\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {**state, 'sections': sections}\n",
    "\n",
    "\n",
    "async def write_acticle(state: MainState):\n",
    "    topic = state['topic']\n",
    "    sections = state['sections']\n",
    "    draft = \"\\n\\n\".join([section.as_str for section in sections])\n",
    "    article = await writer.ainvoke(\n",
    "        {\n",
    "            'topic': topic,\n",
    "            'draft': draft,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return {**state, 'article': article}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSlv5FRa_tEY"
   },
   "source": [
    "## Create the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1734044503741,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "MGOTMJXd_sRB"
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "builder_of_storm = StateGraph(MainState)\n",
    "\n",
    "nodes = [\n",
    "    ('init_research', initialize_research),\n",
    "    ('conduct_interviews', conduct_interviews),\n",
    "    ('refine_outline', refine_outline),\n",
    "    ('index_references', index_references),\n",
    "    ('write_sections', write_sections),\n",
    "    ('write_acticle', write_acticle),\n",
    "]\n",
    "\n",
    "\n",
    "for i in range(len(nodes)):\n",
    "    name, node = nodes[i]\n",
    "    builder_of_storm.add_node(name, node, retry=RetryPolicy(max_attempts=3))\n",
    "    if i > 0:\n",
    "        builder_of_storm.add_edge(nodes[i-1][0], name)\n",
    "\n",
    "builder_of_storm.add_edge(START, nodes[0][0])\n",
    "builder_of_storm.add_edge(nodes[-1][0], END)\n",
    "\n",
    "storm = builder_of_storm.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 747
    },
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1734044505218,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "uyKwBYb9AZfL",
    "outputId": "b638309a-c2df-4b9f-e4db-c897a0a9785b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(storm.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 322418,
     "status": "ok",
     "timestamp": 1734044854727,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "7nAA-rihAeHo",
    "outputId": "a6d4882f-159f-4ae9-a137-0c9a726cde58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_research\n",
      "--  {'topic': 'Steph Curry, One-motion shooting, and Modern Basketball', 'outline': Outline(page_title='Steph Curry, One-motion shooting, and Modern Basketball', sections=[Section(section_title='Introduction', description='An overview of the significance of Steph Curry in modern basketball, focusing on \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/inspect.py:2412: RuntimeWarning: coroutine 'RunnableLambda.ainvoke' was never awaited\n",
      "  obj = unwrap(obj, stop=(lambda f: hasattr(f, \"__signature__\")\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/usr/lib/python3.10/inspect.py:2412: RuntimeWarning: coroutine 'RunnableSequence.ainvoke' was never awaited\n",
      "  obj = unwrap(obj, stop=(lambda f: hasattr(f, \"__signature__\")\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max number of turns\n",
      "Reached max number of turns\n",
      "Reached max number of turns\n",
      "Reached max number of turns\n",
      "Reached max number of turns\n",
      "Reached max number of turns\n",
      "conduct_interviews\n",
      "--  {'topic': 'Steph Curry, One-motion shooting, and Modern Basketball', 'outline': Outline(page_title='Steph Curry, One-motion shooting, and Modern Basketball', sections=[Section(section_title='Introduction', description='An overview of the significance of Steph Curry in modern basketball, focusing on \n",
      "refine_outline\n",
      "--  {'topic': 'Steph Curry, One-motion shooting, and Modern Basketball', 'outline': Outline(page_title='Steph Curry, One-motion Shooting, and Modern Basketball', sections=[Section(section_title='Introduction', description='An overview of the significance of Steph Curry in modern basketball, focusing on \n",
      "index_references\n",
      "--  {'topic': 'Steph Curry, One-motion shooting, and Modern Basketball', 'outline': Outline(page_title='Steph Curry, One-motion Shooting, and Modern Basketball', sections=[Section(section_title='Introduction', description='An overview of the significance of Steph Curry in modern basketball, focusing on \n",
      "write_sections\n",
      "--  {'topic': 'Steph Curry, One-motion shooting, and Modern Basketball', 'outline': Outline(page_title='Steph Curry, One-motion Shooting, and Modern Basketball', sections=[Section(section_title='Introduction', description='An overview of the significance of Steph Curry in modern basketball, focusing on \n",
      "write_acticle\n",
      "--  {'topic': 'Steph Curry, One-motion shooting, and Modern Basketball', 'outline': Outline(page_title='Steph Curry, One-motion Shooting, and Modern Basketball', sections=[Section(section_title='Introduction', description='An overview of the significance of Steph Curry in modern basketball, focusing on \n"
     ]
    }
   ],
   "source": [
    "config = {'configurable': {'thread_id': 'storm-thread-001'}}\n",
    "\n",
    "async for step in storm.astream(\n",
    "    {\n",
    "        'topic': \"Steph Curry, One-motion shooting, and Modern Basketball\",\n",
    "    },\n",
    "    config,\n",
    "):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(\"-- \", str(step[name])[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1734044858939,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "dt6XYuhwA0XZ"
   },
   "outputs": [],
   "source": [
    "checkpoint = storm.get_state(config)\n",
    "article = checkpoint.values['article']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EErx37mBP9S"
   },
   "source": [
    "# Render the Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1734044862967,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "iKunIqzhBR-z",
    "outputId": "6f25a2f2-f40b-41db-aa47-e9caafd85ce4"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Steph Curry, One-motion Shooting, and Modern Basketball\n",
       "\n",
       "## Introduction\n",
       "\n",
       "Stephen Curry, often regarded as one of the greatest shooters in basketball history, has significantly influenced the modern game with his unique shooting style and exceptional skill set. His rise to prominence in the National Basketball Association (NBA) has not only redefined offensive strategies but has also shifted the perception of what is possible in the sport. Central to Curry's success is his mastery of the one-motion shooting technique, which combines fluidity and efficiency, allowing him to shoot with precision from virtually any distance on the court. This technique has set a new standard for shooting in basketball, inspiring players at all levels to emulate his approach.\n",
       "\n",
       "Curry's impact extends beyond his individual achievements; he has revolutionized how teams approach the game. His influence is evident in the increasing emphasis on three-point shooting and the development of players who prioritize shooting accuracy and range. As teams adapt to this new style of play, defensive strategies have also evolved to contain the threat posed by prolific shooters like Curry.\n",
       "\n",
       "Moreover, Curry's influence transcends the basketball court, affecting cultural and social aspects of the game. His success has inspired a generation of young players, and his involvement in community and social initiatives has further solidified his status as a role model. As the game continues to evolve, Stephen Curry's contributions to basketball will remain pivotal in shaping its future. By examining his career and the rise of one-motion shooting, we gain insight into the transformative power of innovation in sports and its lasting impact on both players and fans worldwide.[1]\n",
       "\n",
       "## Steph Curry: A Brief Biography\n",
       "\n",
       "Stephen Curry, widely known as \"Steph,\" was born on March 14, 1988, in Akron, Ohio. He is the son of former NBA player Dell Curry and Sonya Curry, a former volleyball player at Virginia Tech. Raised in Charlotte, North Carolina, Steph was introduced to basketball at a young age and honed his skills under the guidance of his father.\n",
       "\n",
       "Curry attended Charlotte Christian School, where he quickly became a standout player, earning all-state honors and leading his team to three conference titles. Despite his high school success, Curry was considered too small and not heavily recruited by major college basketball programs. He eventually accepted a scholarship offer from Davidson College, a small liberal arts college in North Carolina.\n",
       "\n",
       "At Davidson, Curry made an immediate impact, leading the Wildcats to the NCAA Tournament in his freshman year. His breakout moment came during the 2008 NCAA Tournament, where he led Davidson to the Elite Eight, defeating powerhouses such as Gonzaga and Georgetown. Curry's exceptional shooting and scoring abilities gained him national attention, and he finished his college career as Davidson's all-time leading scorer.\n",
       "\n",
       "In 2009, Curry declared for the NBA Draft and was selected seventh overall by the Golden State Warriors. Over the years, he has developed into one of the most iconic players in NBA history. Known for his exceptional shooting ability, particularly from long distance, Curry has transformed the game of basketball, becoming a two-time NBA MVP and leading the Warriors to multiple NBA championships. His influence extends beyond the court, inspiring countless young players to emulate his playing style and work ethic.\n",
       "\n",
       "## One-motion Shooting Technique\n",
       "\n",
       "The one-motion shooting technique, as exemplified by Steph Curry, is a revolutionary approach in basketball shooting that emphasizes fluidity, efficiency, and range. This technique diverges from traditional shooting forms by integrating the entire body in a seamless motion, allowing players to achieve greater power and accuracy with less perceived effort.\n",
       "\n",
       "### Definition and Characteristics\n",
       "\n",
       "One-motion shooting is characterized by a continuous and fluid movement where the shooter's feet, hips, shoulders, and elbow work in harmony to produce a single, uninterrupted shot. Unlike the traditional two-motion shot, which involves a pause at the set point before the release, the one-motion shot eliminates this pause, resulting in a smoother and quicker release. This fluidity is key to generating power and range, as the energy flows from the lower body through the core and into the shooting hand in a cohesive manner. Steph Curry's shooting mechanics are a prime example of this technique, which has contributed significantly to his success as one of the greatest shooters in NBA history.[2][3]\n",
       "\n",
       "### Historical Context\n",
       "\n",
       "The evolution of shooting techniques in basketball has seen a gradual shift from set shots and two-motion shooting to more dynamic and efficient methods like the one-motion shot. Early basketball focused heavily on set shots, which were later supplemented by the two-motion jump shot as players sought more versatility and effectiveness. The introduction of the one-motion shot marks a significant advancement, combining elements of both previous techniques but streamlining them to maximize speed and efficiency. This evolution reflects broader changes in the game, where speed and adaptability have become crucial.[3]\n",
       "\n",
       "### Comparison with Other Shooting Techniques\n",
       "\n",
       "One-motion shooting stands in contrast to other prevalent techniques such as two-motion shooting and set shots. The two-motion shot involves a distinct pause between the jump and the release, allowing for additional calibration but often resulting in a slower release. Set shots, while stable, lack the dynamism needed in modern fast-paced games. The one-motion shot, by merging these phases into one fluid action, offers a quicker release, reducing the time defenders have to contest the shot. This makes it particularly valuable in the current basketball landscape, where speed and precision are essential.[2][3][1]\n",
       "\n",
       "## Steph Curry's Influence on One-motion Shooting\n",
       "\n",
       "Stephen Curry's influence on the one-motion shooting technique cannot be overstated. His ability to consistently deliver high-percentage shots from beyond the three-point line has not only redefined individual performance metrics but also revolutionized team strategies across the NBA. Curry's shooting style, characterized by its fluidity and efficiency, has become a benchmark for aspiring shooters around the world. As Curry rose to prominence, his success with the one-motion shooting method demonstrated its potential advantages over traditional shooting techniques, sparking widespread interest and adoption.\n",
       "\n",
       "### Key Games and Performances\n",
       "\n",
       "Throughout his career, Stephen Curry has had numerous standout performances that have highlighted the effectiveness of his one-motion shooting technique. One of the most notable instances was during the 2015-16 NBA season, where Curry set a new record for the most three-pointers made in a single season with 402. His ability to shoot from long distances with ease and precision was on full display in games against rivals such as the Oklahoma City Thunder and the Houston Rockets. In these matchups, Curry showcased his extraordinary range and the seamless execution of his shooting form, leaving a lasting impression on fans and analysts alike.[2]\n",
       "\n",
       "### Training and Development\n",
       "\n",
       "Curry's journey to mastering the one-motion shooting technique involved rigorous training and a meticulous focus on refining his skills. His training regimen includes a combination of shooting drills designed to enhance muscle memory, improve release speed, and maintain shooting accuracy even under pressure. Curry's emphasis on the fluidity of movement and the synchronization of his lower and upper body mechanics are critical components of his training philosophy. By perfecting these elements, Curry has been able to develop a shooting form that maximizes power and efficiency, enabling him to execute the one-motion shot with remarkable consistency.[2][1]\n",
       "\n",
       "## Impact on Modern Basketball\n",
       "\n",
       "Stephen Curry's influence on modern basketball is profound, reshaping the sport in multiple dimensions. His unique one-motion shooting style has transformed offensive strategies, inspired a new generation of players, and challenged traditional defensive approaches.\n",
       "\n",
       "### Changing the Game\n",
       "\n",
       "Curry's ability to shoot accurately from long range has significantly altered offensive strategies in the NBA. Teams now prioritize three-point shooting more than ever, with many adopting a space-and-pace style of play to maximize scoring opportunities from beyond the arc. This strategic shift has led to a more dynamic and high-scoring game, where players are encouraged to shoot from long distances, reflecting Curry's influence on the court. His success has shown that a strong perimeter game can be just as effective, if not more so, than traditional post play, redefining how teams approach offensive gameplay.[3][4]\n",
       "\n",
       "### Influence on Young Players\n",
       "\n",
       "Curry's success has inspired a new generation of players to adopt similar shooting techniques. Young athletes around the world look up to Curry as a role model, attempting to emulate his style by focusing on shooting accuracy, quick release, and range. This influence is evident in amateur and youth basketball, where players are increasingly developing their skills to become proficient shooters. Curry's impact extends beyond professional basketball, reaching grassroots levels and shaping the development of young talents who aspire to reach the NBA.[5][6]\n",
       "\n",
       "### Statistical Analysis\n",
       "\n",
       "The statistical impact of Curry's shooting style is evident in the increasing number of three-point attempts and makes across the league. Since Curry's rise to prominence, the NBA has seen a marked increase in the reliance on three-point shooting as a primary offensive weapon. Teams are now attempting more threes per game than ever before, leading to higher scoring averages and a faster pace of play. This shift is directly linked to Curry's influence, as his ability to score from long range has demonstrated the effectiveness of the three-point shot in modern basketball.[3][5]\n",
       "\n",
       "### Defensive Strategies\n",
       "\n",
       "Defensive strategies have had to evolve in response to Curry's shooting prowess. Opposing teams now employ more aggressive perimeter defenses, often double-teaming or trapping Curry beyond the arc to limit his scoring opportunities. This has led to the development of new defensive schemes designed to counteract teams with strong three-point shooters. Additionally, defenders are now required to have better lateral quickness and awareness to contest shots effectively, reflecting the broader impact of Curry's play on the defensive side of the game.[4][6]\n",
       "\n",
       "## Cultural and Social Impact\n",
       "\n",
       "Steph Curry's influence on basketball extends beyond the court, having a significant cultural and social impact. His style of play, characterized by his exceptional shooting ability and dynamic playmaking, has not only transformed the NBA but also inspired a cultural shift in how basketball is perceived and played at various levels.\n",
       "\n",
       "### Cultural Trends in Youth Basketball\n",
       "\n",
       "Curry's influence is palpable among young basketball players, who strive to emulate his shooting style and versatility. His ability to shoot from long distances with precision has become a standard that many young athletes aspire to achieve. This has led to a cultural trend where aspiring players focus on developing their shooting proficiency and ball-handling skills, often prioritizing these aspects over traditional post play or mid-range shooting. The emphasis on three-point shooting and agility reflects a shift towards a more dynamic and high-scoring style of play, which aligns with Curry's own approach to basketball. As a result, Curry has become a template for the new generation of players, who seek to adopt his techniques and mindset.[5][6]\n",
       "\n",
       "### Community and Social Initiatives\n",
       "\n",
       "Beyond his influence on the basketball court, Curry has leveraged his platform to engage in various community and social initiatives. He is known for his involvement in charitable activities and his commitment to giving back to the community. Through his foundation and partnerships, Curry has supported educational programs, youth sports, and initiatives aimed at fighting hunger and promoting health and wellness. His efforts have not only provided tangible benefits to communities but have also inspired his fans and followers to engage in social causes. Curry's off-court endeavors demonstrate his dedication to using his influence for positive change, further solidifying his role as a leader both in sports and in society.[5]\n",
       "\n",
       "## Criticism and Challenges\n",
       "\n",
       "While Steph Curry's influence on modern basketball through his one-motion shooting technique is undeniable, it has not been without its share of criticism and challenges. Some experts and analysts argue that the focus on shooting, particularly long-range shooting, may overshadow other essential skills in basketball such as defense, passing, and teamwork. Additionally, there are debates about the sustainability of the one-motion shooting technique in different game contexts and its effectiveness for all players.\n",
       "\n",
       "### Sustainability of One-motion Shooting\n",
       "\n",
       "The one-motion shooting technique, as popularized by Steph Curry, is praised for its fluidity and the ability to generate power and range efficiently. However, some skeptics question its long-term effectiveness, particularly for players who do not possess Curry's unique physical attributes, such as his hand-eye coordination, quick release, and overall shooting precision. Critics argue that while the one-motion style works exceptionally well for Curry, it may not be suitable for all players, who might struggle with consistency and accuracy when attempting to mimic this technique. The adaptability of one-motion shooting to various levels of play, from amateur leagues to professional basketball, also remains a topic of discussion.[2]\n",
       "\n",
       "### Overemphasis on Shooting\n",
       "\n",
       "Curry's success has led to an increased emphasis on shooting, particularly from beyond the three-point line, across all levels of basketball. While this has undeniably transformed the offensive aspect of the game, some purists argue that it has led to a decline in other fundamental basketball skills. There is a concern that young players, inspired by Curry, may focus excessively on developing their shooting abilities at the expense of other critical skills such as defense, rebounding, and passing. This shift could potentially lead to a more one-dimensional style of play, which may not be beneficial for the overall development of the sport. Coaches and trainers are thus challenged to find a balance between nurturing shooting prowess and maintaining a well-rounded skill set in their players.[2][1]\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Steph Curry's impact on modern basketball is undeniable. His mastery of the one-motion shooting technique has not only revolutionized the way the game is played but also reshaped the strategies employed by teams and coaches across the NBA. Curry's ability to shoot with remarkable accuracy from long range has made the three-point shot a central element of offensive play, influencing both current players and aspiring athletes to focus on developing similar skills.\n",
       "\n",
       "The ripple effects of Curry's influence extend beyond the court. Young players, inspired by his success, are increasingly adopting the one-motion shooting style, perpetuating its significance in the evolution of basketball. However, as the game continues to evolve, it is crucial to maintain a balance, ensuring that other fundamental aspects of basketball are not overshadowed by the emphasis on shooting.\n",
       "\n",
       "Despite some criticisms and challenges, such as concerns over the sustainability of one-motion shooting and the potential overemphasis on shooting skills, Curry's contributions have left a lasting legacy. His engagement in community and social initiatives further highlights his role not just as a sports icon but as a positive force for change.\n",
       "\n",
       "Looking to the future, Steph Curry's trailblazing approach to basketball will likely continue to inspire innovation and adaptation within the sport. As coaches, players, and fans alike embrace the changes he has introduced, the game of basketball is poised for an exciting era of creativity and dynamism.[1]\n",
       "\n",
       "## References\n",
       "\n",
       "[1] [Grit Basketball - One Motion vs Two Motion Shooting](https://gritbasketball.com/one-motion-vs-two/)\n",
       "\n",
       "[2] [Field Insider - Steph Curry Shooting: How to Shoot Like NBA Superstar](https://fieldinsider.com/steph-curry-shooting-how-to-shoot-like-nba-superstar/)\n",
       "\n",
       "[3] [Metro League - How Steph Curry Changed the Game of Basketball](https://www.metroleague.org/how-steph-curry-changed-the-game-of-basketball)\n",
       "\n",
       "[4] [Fan Arch - How Steph Curry Changed the Game of Basketball](https://fanarch.com/blogs/nba/how-steph-curry-changed-the-game-of-basketball)\n",
       "\n",
       "[5] [Grit Basketball - One Motion vs Two Motion Shooting](https://gritbasketball.com/one-motion-vs-two/)\n",
       "\n",
       "[6] [Metro League - How Steph Curry Changed the Game of Basketball](https://www.metroleague.org/how-steph-curry-changed-the-game-of-basketball)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "# We will down-header the sections to create less confusion in this notebook\n",
    "#Markdown(article.replace(\"\\n#\", \"\\n##\"))\n",
    "\n",
    "Markdown(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSNleZFwC8oZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMT2fUvfyrNTDA1l9R4zQUb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
