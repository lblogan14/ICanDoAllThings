{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CmNWnldYWr2U"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ts_gh5cBWuvD"
   },
   "source": [
    "# Best Practices for Generatrion with Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eBiAjBnWzrU"
   },
   "source": [
    "Efficient caching is crucial for optimizing the performance of models in various generative tasks and helps reduce computation time and improve response rates, especially in real-time or resource-intensive applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-_ivTZhXBMD"
   },
   "source": [
    "## What is Cache and why we should care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hW8kS1SYYNB"
   },
   "source": [
    "When we have a conversation with someone, it would be slow and inefficient if we have to start from scratch every time we respond. This is where **caching keys and values** come into play in the Transformer models. This is referred to as **KV Cache**.\n",
    "\n",
    "KV cache is needed to optimize the generation in autogressive models, where the model predicts text token by token. This process can be slow since the model can generate only one token at a time, and each new prediction is dependent on the previous context.\n",
    "\n",
    "Key-value cache acts as a memory bank for these generative models, where the model stores key-value pairs derived from self-attention layers for previously processed tokens. By storing this information, the model can avoid redundant computations and instead retrieve keys and values of previous tokens from the cache. This is only used in inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt5FxaIRZmq-"
   },
   "source": [
    "### How Cache Object Works in Attnetion Mechansim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyEN_r1dZyY4"
   },
   "source": [
    "The Attention module concatenates the current key-values with the past-values stored in the cache. This results in attention weights of shape `(new_tokens_length, past_kv_length + new_token_length)`. The past and current key-values are combined to compute attention scores, ensuring that the model considers both previous context and new input. The concatenated key-values are used to compute the attention scores resulting in attention weights of shape `(new_tokens_length, past_kv_length + new_tokens_length)`.\n",
    "\n",
    "Therefore, when iteratively calling `forward()` instead of the `generate()` method, it is crucial to ensure that the attention mask shape matches the combined length of past and current key-values. The attention mask should have the shape `(batch_size, past_kv_length + new_tokens_length)`.\n",
    "\n",
    "The example below shows how to implement our own generation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "15969b8a296642588d11159441e6e248",
      "c6d92e73f7bd496796419c7c6957d5f2",
      "3a068128f0904f0695ef6e676f4a1d4e",
      "3e105cd645a748fdbc99121dde7cdfaf",
      "1f00cc27d0694455bc89e94c20d6af58",
      "048d159c246e45edb5975ef9f5c4aeda",
      "3c3b7cfe3054417d88416dd9611cbcd8",
      "87402172c7aa4df88cedccef7c3fa1e2",
      "e50e4b4bef5f44ffaa537cadea122eec",
      "26fe917dc5b846f2b818342a4f75aa20",
      "66366a60923b409dad66a5e9caa5d6e5",
      "e919ee125fe045eca67c6a591853cd20",
      "145a6dd059d146b08421e149bf797d8c",
      "5defd45341a74d12ab1f5ec344e3a3e3",
      "92db8a9174f745758973616787d3d0e3",
      "8d872167177e48a9a5bb920674abb155",
      "5a11507c49e74f518cea1bc8b579094d",
      "8a7c3c7bddaf42c9ab1619307982465b",
      "d6c3f4a364fd4686be36180fe9e50d44",
      "540bba7fdd2641c5a3fd4a80b695e7f6",
      "08fb1eaa44a2455c9c0b27262141c85b",
      "773f8855bd184309a072469f30b8ecd6",
      "3880afa7ae754f0794655ff227d5a46e",
      "9ed98cce13934ab4bef19a504115f300",
      "6b7ddec0a1f644b09fa7918ebc5ee957",
      "f86e4433e485404a81c1f5bdf705068d",
      "8b8668228f11444aaf2e25aec0177d90",
      "95cd53c22d994b6aabd5365403116525",
      "d1bcbfea5db24c0b849718f71e32b542",
      "bbb622194e8948d4887ce760cddef42f",
      "868e3eccc84d4f8e9702049860f44f2a",
      "2243807bf88d42dfb89860724c5333c7"
     ]
    },
    "executionInfo": {
     "elapsed": 139,
     "status": "ok",
     "timestamp": 1731330943738,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "oj6Dg0-4XY6I",
    "outputId": "7b86a5e5-ef0c-445f-a85a-66e022372133"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UpFpVHQWmqH"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DynamicCache\n",
    "import torch\n",
    "\n",
    "checkpoint = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=torch.float16, device_map='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBj1-T4zWdmi"
   },
   "outputs": [],
   "source": [
    "past_key_values = DynamicCache()\n",
    "messages = [\n",
    "    {'role': 'user',\n",
    "     'content': \"Hello, what is your name?\"}\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors='pt',\n",
    "    return_dict=True,\n",
    ").to(device)\n",
    "\n",
    "generated_ids = inputs.input_ids\n",
    "cache_position = torch.arange(\n",
    "    inputs.inputs_ids.shape[1],\n",
    "    dtype=torch.int64,\n",
    "    device=device\n",
    ")\n",
    "max_new_tokens = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VS-b2wKrYPlr"
   },
   "outputs": [],
   "source": [
    "for _ in range(max_new_tokens):\n",
    "    outputs = model(\n",
    "        **inputs,\n",
    "        cache_position=cache_position,\n",
    "        past_key_values=past_key_values,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "    # Greedily sample one next token\n",
    "    next_token_ids = outputs.logits[:, -1:].argmax(-1)\n",
    "    generated_ids = torch.cat([generated_ids, next_token_ids], dim=-1)\n",
    "\n",
    "    # Prepare inputs for the next generation step by leaving unprocessed tokens,\n",
    "    # in our case we have only one new token and\n",
    "    # expanding attention mask for the new token, as explained above\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    attention_mask = torch.cat(\n",
    "        [attention_mask, attention_mask.new_ones((attention_mask.shape[0], 1))],\n",
    "        dim=-1,\n",
    "    )\n",
    "    inputs = {\n",
    "        'input_ids': next_token_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "    }\n",
    "    # add one more position for the next token\n",
    "    cache_position = cache_position[-1:] + 1\n",
    "\n",
    "print(tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-z8HxOgZfQtL"
   },
   "source": [
    "## Generate with Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvfA00DyfTW6"
   },
   "source": [
    "By default, all models in Transformers library generate with caching, with the `DynamicCache` class being the default cache for most models. It allows us to dynamically grow cache size, by saving more and more keys and values as we generate. If we do not want to use caches, we can pass `use_cache=False` into the `generate()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YbHqjuTjdGO"
   },
   "source": [
    "### Quantized Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx9r4hcXjfoD"
   },
   "source": [
    "The key and value cache can occupy a large portion of memory, becoming a bottleneck for long-context generation, especially for Large Language Models. Quantizing the cache when using `generate()` can significantly reduce memory requirements at the cost of speed.\n",
    "\n",
    "To enable quantization of the key-value cache, we need to incidate `cache_implementation=\"quantized\"` in the `generation_config`. Quantization related arguments should be passed to the `generation_config` either as a `dict` or an instance of a `QuantizedCacheConfig` class.\n",
    "\n",
    "Cache quantization can be detrimental in terms of latency if the context length is short and there is enough GPU VRAM available to run without cache quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqj39zFYfSOt"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "checkpoint = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=torch.float16).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "inputs = tokenizer(\"I like hip-pop music because\", return_tensors='pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lc3V24HGlqkN"
   },
   "outputs": [],
   "source": [
    "out = model.generate(\n",
    "    **inputs,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=20,\n",
    "    cache_implementation=\"quantized\",\n",
    "    cache_config={'nbits': 4,\n",
    "                  'backend': 'quanto'},\n",
    ")\n",
    "tokenizer.batch_decode(out, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3f2rOZ_5mI1u"
   },
   "outputs": [],
   "source": [
    "out = model.generate(\n",
    "    **inputs,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=20,\n",
    ")\n",
    "tokenizer.batch_decode(out, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-mHFt99mQh_"
   },
   "source": [
    "### Offloaded Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNtBfuUFn6DH"
   },
   "source": [
    "Similar to quantization, `OffloadedCache` aims to reduce GPU VRAM usage. It does so by moving the KV cache for most layers to the CPU. As the model's `forward()` method iterates over the layers, this strategy maintains the current layer cache on the GPU. At the same time it asynchronously prefetches the next layer cache as well as sending the previous layer cache back to the CPU.\n",
    "\n",
    "To enable KV cache offloading, pass `cache_implementation=\"offloaded\"` in the `genration_config` or directly to the `generate()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H8_1wzr4mR8H"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "checkpoint = 'microsoft/Phi3-mini-4k-instruct'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=torch.float16).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "inputs = tokenizer(\"Fun fact: The shortest\", return_tensors='pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7lz4wcho8Qc"
   },
   "outputs": [],
   "source": [
    "out = model.generate(\n",
    "    **inputs,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=20,\n",
    "    cache_implementation='offloaded',\n",
    ")\n",
    "tokenizer.batch_decode(out, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRMr02NMpGQ9"
   },
   "outputs": [],
   "source": [
    "out = model.generate(\n",
    "    **inputs,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=20,\n",
    ")\n",
    "tokenizer.batch_decode(out, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1IuZ6bspLjG"
   },
   "source": [
    "Cache offloading requires a GPU and can be slower than dynamic KV cache. Use it if we get CUDA out of memory errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLJLO1CCpWyU"
   },
   "source": [
    "The example below shows how KV cache offloading can be used as a fallback strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1AOadTMxpaen"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "\n",
    "def resilient_generate(model, *args, **kwargs):\n",
    "    oom = False\n",
    "\n",
    "    try:\n",
    "        return model.generate(*args, **kwargs)\n",
    "    except torch.cuda.OutOfMemoryError as e:\n",
    "        print(e)\n",
    "        print('retrying with `cache_implementation=\"offloaded\"`')\n",
    "        oom = True\n",
    "\n",
    "    if oom:\n",
    "        torch.cuda.empty_cache()\n",
    "        kwargs['cache_implementation'] = 'offloaded'\n",
    "        return model.generate(*args, **kwargs)\n",
    "\n",
    "\n",
    "checkpoint = 'microsoft/Phi3-mini-4k-instruct'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=torch.float16).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "prompt = ['okay'*1000 + 'Fun fact: the most']\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QMZ5G-RLp8iR"
   },
   "outputs": [],
   "source": [
    "beams = {\n",
    "    'num_beams': 40,\n",
    "    'num_beam_groups': 40,\n",
    "    'num_return_sequences': 40,\n",
    "    'diversity_penalty': 1.0,\n",
    "    'max_new_tokens': 20,\n",
    "    'early_stopping': True,\n",
    "}\n",
    "\n",
    "out = resilient_generate(model, **inputs, **beams)\n",
    "responses = tokenizer.batch_decode(out[:, -28:], skip_special_tokens=True)\n",
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1z2tXw2qZn_"
   },
   "source": [
    "### Static Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkeEfvUlvCwj"
   },
   "source": [
    "Since the `DynamicCache` dynamically grows with each generation step, it prevents use from taking advantage of JIT optimizations. The `StaticCache` pre-allocates a specific  maximum size for the keys and values, allowing us to generate up to the maximum length without having to modify cache size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CR1ya051qa_s"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "checkpoint = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=torch.float16).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "inputs = tokenizer('Hello, my name is', return_tensors='pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhBaPwPhvgTO"
   },
   "outputs": [],
   "source": [
    "out = model.generate(\n",
    "    **inputs,\n",
    "    do_sample=False,\n",
    "    max_new_tokens=20,\n",
    "    cache_implementation='static',\n",
    ")\n",
    "tokenizer.batch_decode(out, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tx_G4nxHv2uh"
   },
   "source": [
    "## Offloaded Static Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3CNXwtVRv4YU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOaDiQckqvuGVoq8sxsJ32u",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "048d159c246e45edb5975ef9f5c4aeda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d872167177e48a9a5bb920674abb155",
      "placeholder": "​",
      "style": "IPY_MODEL_5a11507c49e74f518cea1bc8b579094d",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "08fb1eaa44a2455c9c0b27262141c85b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b7ddec0a1f644b09fa7918ebc5ee957",
      "placeholder": "​",
      "style": "IPY_MODEL_f86e4433e485404a81c1f5bdf705068d",
      "value": "Token is valid (permission: fineGrained)."
     }
    },
    "145a6dd059d146b08421e149bf797d8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "15969b8a296642588d11159441e6e248": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_08fb1eaa44a2455c9c0b27262141c85b",
       "IPY_MODEL_773f8855bd184309a072469f30b8ecd6",
       "IPY_MODEL_3880afa7ae754f0794655ff227d5a46e",
       "IPY_MODEL_9ed98cce13934ab4bef19a504115f300"
      ],
      "layout": "IPY_MODEL_3c3b7cfe3054417d88416dd9611cbcd8"
     }
    },
    "1f00cc27d0694455bc89e94c20d6af58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_5defd45341a74d12ab1f5ec344e3a3e3",
      "style": "IPY_MODEL_92db8a9174f745758973616787d3d0e3",
      "tooltip": ""
     }
    },
    "2243807bf88d42dfb89860724c5333c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26fe917dc5b846f2b818342a4f75aa20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3880afa7ae754f0794655ff227d5a46e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1bcbfea5db24c0b849718f71e32b542",
      "placeholder": "​",
      "style": "IPY_MODEL_bbb622194e8948d4887ce760cddef42f",
      "value": "Your token has been saved to /root/.cache/huggingface/token"
     }
    },
    "3a068128f0904f0695ef6e676f4a1d4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_26fe917dc5b846f2b818342a4f75aa20",
      "placeholder": "​",
      "style": "IPY_MODEL_66366a60923b409dad66a5e9caa5d6e5",
      "value": ""
     }
    },
    "3c3b7cfe3054417d88416dd9611cbcd8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "3e105cd645a748fdbc99121dde7cdfaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_e919ee125fe045eca67c6a591853cd20",
      "style": "IPY_MODEL_145a6dd059d146b08421e149bf797d8c",
      "value": true
     }
    },
    "540bba7fdd2641c5a3fd4a80b695e7f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a11507c49e74f518cea1bc8b579094d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5defd45341a74d12ab1f5ec344e3a3e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66366a60923b409dad66a5e9caa5d6e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b7ddec0a1f644b09fa7918ebc5ee957": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "773f8855bd184309a072469f30b8ecd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b8668228f11444aaf2e25aec0177d90",
      "placeholder": "​",
      "style": "IPY_MODEL_95cd53c22d994b6aabd5365403116525",
      "value": "Your token has been saved in your configured git credential helpers (store)."
     }
    },
    "868e3eccc84d4f8e9702049860f44f2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87402172c7aa4df88cedccef7c3fa1e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a7c3c7bddaf42c9ab1619307982465b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6c3f4a364fd4686be36180fe9e50d44",
      "placeholder": "​",
      "style": "IPY_MODEL_540bba7fdd2641c5a3fd4a80b695e7f6",
      "value": "Connecting..."
     }
    },
    "8b8668228f11444aaf2e25aec0177d90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d872167177e48a9a5bb920674abb155": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92db8a9174f745758973616787d3d0e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "95cd53c22d994b6aabd5365403116525": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ed98cce13934ab4bef19a504115f300": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_868e3eccc84d4f8e9702049860f44f2a",
      "placeholder": "​",
      "style": "IPY_MODEL_2243807bf88d42dfb89860724c5333c7",
      "value": "Login successful"
     }
    },
    "bbb622194e8948d4887ce760cddef42f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6d92e73f7bd496796419c7c6957d5f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87402172c7aa4df88cedccef7c3fa1e2",
      "placeholder": "​",
      "style": "IPY_MODEL_e50e4b4bef5f44ffaa537cadea122eec",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "d1bcbfea5db24c0b849718f71e32b542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6c3f4a364fd4686be36180fe9e50d44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e50e4b4bef5f44ffaa537cadea122eec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e919ee125fe045eca67c6a591853cd20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f86e4433e485404a81c1f5bdf705068d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
