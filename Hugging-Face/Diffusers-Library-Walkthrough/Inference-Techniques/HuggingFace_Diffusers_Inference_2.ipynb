{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOs9AaszcX6t2foXk9ZT2DM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qkVUNwU8p-yF"},"outputs":[],"source":["!pip install -qU diffusers peft transformers huggingface_hub"]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","notebook_login()"],"metadata":{"id":"GIudHvK4qfSw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Merge LoRAs"],"metadata":{"id":"9S9t6bo4qgOh"}},{"cell_type":"markdown","source":["Load a Stable Diffusion XL (SDXL) checkpoint and the `KappaNeuro/studio-ghibli-style` and `Norod78/sdxl-chalkboarddrawing-lora` LoRAs.."],"metadata":{"id":"g6z_khXqqnGt"}},{"cell_type":"code","source":["from diffusers import DiffusionPipeline\n","import torch\n","\n","pipeline = DiffusionPipeline.from_pretrained(\n","    'stabilityai/stable-diffusion-xl-base-1.0',\n","    torch_dtype=torch.float16\n",").to('cuda')\n","\n","pipeline.load_lora_weights(\n","    'ostris/ikea-instructions-lora-sdxl',\n","    weight_name='ikea_instructions_xl_v1_5.safetensors',\n","    adapter_name='ikea'\n",")\n","\n","pipeline.load_lora_weights(\n","    'lordjia/by-feng-zikai',\n","    weight_name='fengzikai_v1.0_XL.safetensors',\n","    adapter_name='feng'\n",")"],"metadata":{"id":"MsiH7hhKqhWp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## `set_adapters`"],"metadata":{"id":"x2uDiLMjrSp7"}},{"cell_type":"markdown","source":["`set_adapters()` merges LoRA adapters by concatenating their weighted matrices."],"metadata":{"id":"udBJyw7xtN86"}},{"cell_type":"code","source":["pipeline.set_adapters(\n","    ['ikea', 'feng'],\n","    adapter_weights=[0.7, 0.8]\n",")\n","\n","generator = torch.manual_seed(111)\n","prompt = 'A bowl of ramen shaped like a cute kawaii bear, by Feng Zikai'\n","\n","image = pipeline(\n","    prompt,\n","    generator=generator,\n","    cross_attention_kwargs={'scale': 1.0}\n",").images[0]\n","image"],"metadata":{"id":"jtkQoIxgrUt2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = pipeline(\n","    prompt,\n","    generator=generator,\n","    cross_attention_kwargs={'scale': 0.6}\n",").images[0]\n","image"],"metadata":{"id":"jIjIHy86tr6B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipeline.set_adapters(\n","    ['ikea', 'feng'],\n","    adapter_weights=[0.8, 0.6]\n",")\n","\n","generator = torch.manual_seed(111)\n","prompt = 'A bowl of ramen shaped like a cute kawaii bear, by Feng Zikai'\n","\n","image = pipeline(\n","    prompt,\n","    generator=generator,\n","    cross_attention_kwargs={'scale': 1.0}\n",").images[0]\n","image"],"metadata":{"id":"kGvnwjo5tuB4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## `add_weighted_adapter`"],"metadata":{"id":"aqE8xZkvtws6"}},{"cell_type":"markdown","source":["`add_weighted_adapter()` provides access to more efficient merging method such as TIES and DARE.\n","\n","Make sure we have the latest stable version of Diffusers and PEFT installed.\n","\n","Three steps to merge LoRAs with the `add_weighted_adapter` method:\n","1. Create a `PeftModel` from the underlying model and LoRA checkpoint.\n","2. Load a base UNet model and the LoRA adapters.\n","3. Merge the adapters using the `add_weighted_adapter` and the merging method of our choice."],"metadata":{"id":"5hFnIHWzt0fy"}},{"cell_type":"markdown","source":["1. Load a UNet that corresponds to the UNet in the LoRA checkpoint. In our case, both LoRAs use the SDXL UNet as their base model."],"metadata":{"id":"XfEO8JIBuXaD"}},{"cell_type":"code","source":["from diffusers import UNet2DConditionModel\n","import torch\n","\n","unet = UNet2DConditionModel.from_pretrained(\n","    'stabilityai/stable-diffusion-xl-base-1.0',\n","    torch_dtype=torch.float16,\n","    use_safetensors=True,\n","    variant='fp16',\n","    subfolder='unet'\n",").to('cuda')"],"metadata":{"id":"-fD2nyNFtygv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load the SDXL pipeline and the LoRA checkpoints"],"metadata":{"id":"PVjQ-D2Guuij"}},{"cell_type":"code","source":["from diffusers import DiffusionPipeline\n","\n","pipeline = DiffusionPipeline.from_pretrained(\n","    'stabilityai/stable-diffusion-xl-base-1.0',\n","    torch_dtype=torch.float16,\n","    variant='fp16',\n","    unet=unet,\n",").to('cuda')\n","\n","pipeline.load_lora_weights(\n","    'ostris/ikea-instructions-lora-sdxl',\n","    weight_name='ikea_instructions_xl_v1_5.safetensors',\n","    adapter_name='ikea'\n",")"],"metadata":{"id":"7T0FXkONuxPJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we create a `PeftModel` from the loaded LoRA checkpoint by combining the SDXL UNet and the LoRA Unet from the pipeline."],"metadata":{"id":"ia2dogqNv4ii"}},{"cell_type":"code","source":["from peft import get_peft_model, LoraConfig\n","import copy\n","\n","sdxl_unet = copy.deepcopy(unet)\n","ikea_peft_model = get_peft_model(\n","    sdxl_unet,\n","    pipeline.unet.peft_config['ikea'],\n","    adapter_name='ikea'\n",")\n","\n","original_state_dict = {\n","    f\"base_model.model.{k}\": v\n","    for k,v in pipeline.unet.state_dict().items()\n","}\n","ikea_peft_model.load_state_dict(original_state_dict, strict=True)"],"metadata":{"id":"pCi1Saz50CT0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Repeat this process to create a `PeftModel` from the `lordjia/by-feng-zikai` LoRA:"],"metadata":{"id":"Umc2YfKb0ikp"}},{"cell_type":"code","source":["pipeline.detele_adapters('ikea')\n","sdxl_unet.delete_adapters('ikea')\n","\n","pipeline.load_lora_weights(\n","    'lorajia/by-feng-zikai',\n","    weight_name='fengzikai_v1.0_XL.safetensors',\n","    adapter_name='feng'\n",")\n","pipeline.set_adapters(adapter_names='feng')\n","\n","feng_peft_model = get_peft_model(\n","    sdxl_unet,\n","    pipeline.unet.peft_config['feng'],\n","    adapter_name='feng'\n",")\n","\n","original_state_dict = {\n","    f\"base_model.model.{k}\": v\n","    for k,v in pipeline.unet.state_dict().items()\n","}\n","\n","feng_peft_model.load_state_dict(original_state_dict, strict=True)"],"metadata":{"id":"0ZVduFnz0pZG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Load a base UNet model and then load the adapters onto it:"],"metadata":{"id":"c2yqpRtA1dQU"}},{"cell_type":"code","source":["from peft import PeftModel\n","\n","base_unet = UNet2DConditionModel.from_pretrained(\n","    'stabilityai/stable-diffusion-xl-base-1.0',\n","    torch_dtype=torch.float16,\n","    use_safetensors=True,\n","    variant='fp16',\n","    subfolder='unet'\n",").to('cuda')\n","\n","model = PeftModel.from_pretrained(\n","    base_unet,\n","    'stevhliu/ikea_peft_model',\n","    use_safetenosrs=True,\n","    subfolder='ikea',\n","    adapter_name='ikea'\n",")\n","model.load_adapter(\n","    'stevhliu/feng_peft_model',\n","    use_safetensors=True,\n","    subfolder='feng',\n","    adapter_name='feng'\n",")"],"metadata":{"id":"Bc4oKAwe1gNH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Merge the adapters using the `add_weighted_adapter` method and the merging method of our choice. In this example, we use the `\"dare_linear\"` method to merge the LoRAs.\n","\n","Note that **LoRAs need to have the same rank to be merged!**"],"metadata":{"id":"q0Nf6jXA196H"}},{"cell_type":"code","source":["model.add_weighted_adapter(\n","    adapters=['ikea', 'feng'],\n","    weights=[1.0, 1.0],\n","    combination_type='dare_linear',\n","    adapter_name='ikea-feng'\n",")\n","model.set_adapters('ikea-feng')"],"metadata":{"id":"ByqxHEAH2Lum"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we can generate an image with the merged LoRA"],"metadata":{"id":"59nQUIti2V3c"}},{"cell_type":"code","source":["model = model.to(dtype=torch.float16, device='cuda')\n","\n","pipeline = DiffusionPipeline.from_pretrained(\n","    'stabilityai/stable-diffusion-xl-base-1.0',\n","    unet=model,\n","    variant='fp16',\n","    torch_dtype=torch.float16,\n",").to('cuda')"],"metadata":{"id":"CgNSZpRT2fNL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = pipeline(\n","    'A bowl of ramen shaped like a cute kawaii bear, by Feng Zikai',\n","    generator=torch.manual_seed(111),\n",").images[0]\n","image"],"metadata":{"id":"TanHbk2T2qdo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## `fuse_lora`"],"metadata":{"id":"do5UnUWt2zvI"}},{"cell_type":"markdown","source":["Both `set_adapters()` and `add_weighted_adapter()` methods require loading the base model and the LoRA adapters separately which incurs some overhead.\n","\n","The `fuse_lora` methods allows us to fuse the LoRA weights directly with the original weights of the underlying model so we only load the model once which can increase inference and lower memory-usage.\n","\n","For example, if we have a base model and adapters loaded and set as active with the following adapter weights:"],"metadata":{"id":"kpy1hUvF3vqk"}},{"cell_type":"code","source":["from diffusers import DiffusionPipeline\n","import torch\n","\n","pipeline = DiffusionPipeline.from_pretrained(\n","    'stabilityai/stable-diffusion-xl-base-1.0',\n","    torch_dtype=torch.float16\n",").to('cuda')\n","pipeline.load_lora_weights(\n","    'ostris/ikea-instructions-lora-sdxl',\n","    weight_name='ikea_instructions_xl_v1_5.safetensors',\n","    adapter_name='ikea'\n",")\n","pipeline.load_lora_weights(\n","    \"lordjia/by-feng-zikai\",\n","    weight_name=\"fengzikai_v1.0_XL.safetensors\",\n","    adapter_name=\"feng\"\n",")\n","\n","pipeline.set_adapters(\n","    ['ikea', 'feng'],\n","    adapter_weights=[0.7, 0.8]\n",")"],"metadata":{"id":"OK2qfxr33vAh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipeline.fuse_lora(\n","    adapter_names=['ikea', 'feng'],\n","    lora_scale=1.0\n",")"],"metadata":{"id":"YyoL4YXp4rTD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`lora_scale` controls how much to scale the output by with the LoRA weights.\n","\n","We can now use `unload_lora_weights()` to unload the LoRA weights since they have already been fused with the underlying base model.\n","\n","Additionally, we can call `save_pretrained()` to save the fused pipeline locally."],"metadata":{"id":"zUYlBRQW4xBK"}},{"cell_type":"code","source":["pipline.unload_lora_weights()\n","\n","# save locally\n","pipeline.save_pretrained('fused_pipeline')\n","# save to the hub\n","pipeline.push_to_hub('fused-ikea-feng')"],"metadata":{"id":"5c0LfE-j5MWi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we can quickly load the fused pipeline and use it for inference without needing to separately load the LoRA adapters."],"metadata":{"id":"_B8m32z65UXm"}},{"cell_type":"code","source":["pipeline = DiffusionPipeline.from_pretrained(\n","    'fused_pipeline',\n","    torch_dtype=torch.float16\n",").to('cuda')"],"metadata":{"id":"9AYqlADK5aFC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = pipeline(\n","    \"A bowl of ramen shaped like a cute kawaii bear, by Feng Zikai\",\n","    generator=torch.manual_seed(0)\n",").images[0]\n","image"],"metadata":{"id":"pyTEiSw25h9Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can also call `unfuse_lora` to restore the original model's weights. However, this only works if we have only fused one LoRA adapter to the original model. If we have fused multiple LoRAs, we need to reload the model.\n","```python\n","pipeline.unfuse_lora()\n","```"],"metadata":{"id":"AQKiuG5E5mXN"}},{"cell_type":"markdown","source":["### `torch.compile`"],"metadata":{"id":"6eAM9bKl51rR"}},{"cell_type":"markdown","source":["`torch.compile` can speed up our pipeline even more, but the LoRA weights must be fused first and then unloaded. Typically, the UNet is compiled because it is such a computationally intensive component of the pipeline."],"metadata":{"id":"6y3d8KT8-qmv"}},{"cell_type":"code","source":["from diffusers import DiffusionPipeline\n","import torch\n","\n","pipeline = DiffusionPipeline.from_pretrained(\n","    'stabilityai/stable-diffusion-xl-base-1.0',\n","    torch_dtype=torch.float16\n",").to('cuda')\n","pipeline.load_lora_weights(\n","    'ostris/ikea-instructions-lora-sdxl',\n","    weight_name='ikea_instructions_xl_v1_5.safetensors',\n","    adapter_name='ikea'\n",")\n","pipeline.load_lora_weights(\n","    \"lordjia/by-feng-zikai\",\n","    weight_name=\"fengzikai_v1.0_XL.safetensors\",\n","    adapter_name=\"feng\"\n",")\n","\n","pipeline.set_adapters(\n","    ['ikea', 'feng'],\n","    adapter_weights=[0.7, 0.8]\n",")"],"metadata":{"id":"qEh_FEff53Eg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fuse LoRAs and unload weights\n","pipeline.fuse_lora(\n","    adapter_names=['ikea', 'feng'],\n","    lora_scale=1.0\n",")\n","pipeline.unload_lora_weights()\n","\n","# torch.compile\n","pipeline.unet.to(memory_format=torch.channels_last)\n","pipeline.unet = torch.compile(\n","    pipeline.unet,\n","    mode='reduce-overhead',\n","    fullgraph=True,\n",")"],"metadata":{"id":"xpxjI8Rc--RJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = pipeline(\n","    \"A bowl of ramen shaped like a cute kawaii bear, by Feng Zikai\",\n","    generator=torch.manual_seed(0)\n",").images[0]\n","image"],"metadata":{"id":"acrRhh_S_NQJ"},"execution_count":null,"outputs":[]}]}