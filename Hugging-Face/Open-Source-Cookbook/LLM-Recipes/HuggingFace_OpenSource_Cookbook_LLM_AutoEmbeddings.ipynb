{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNe0ca6QspheNygrLx4CTwK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# How to Use Inference Endpoints to Embed Documents"],"metadata":{"id":"b8mtw7chfsjG"}},{"cell_type":"markdown","source":["## Introduction"],"metadata":{"id":"j47uMLzjgLBX"}},{"cell_type":"markdown","source":["If we have a dataset that we want to embed for semantic search (or QA, RAG, etc), what would be the easiest way to embed this and put it in a new dataset?\n","\n","In this example, we will deploy the [`jinaai/jina-embeddings-v2-base-en`](https://huggingface.co/jinaai/jina-embeddings-v2-base-en) embedding model using the [Inference Endpoint](https://huggingface.co/inference-endpoints/dedicated) to save time and money."],"metadata":{"id":"OMTt26nqgMMA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XobGwjyrfaJT"},"outputs":[],"source":["!pip install -qU aiohttp==3.8.3 datasets==2.14.6 pandas==1.5.3 requests==2.31.0 tqdm==4.66.1 huggingface-hub>=0.20"]},{"cell_type":"markdown","source":["## Setups"],"metadata":{"id":"5-x5b3pCg-bs"}},{"cell_type":"code","source":["import asyncio\n","from getpass import getpass\n","import json\n","from pathlib import Path\n","import time\n","from typing import Optional\n","\n","from aiohttp import ClientSession, ClientTimeout\n","from datasets import load_dataset, Dataset, DatasetDict\n","from huggingface_hub import (\n","    notebook_login, create_inference_endpoint, list_inference_endpoints, whoami\n",")\n","import numpy as np\n","import pandas as pd\n","import requests\n","from tqdm.auto import tqdm"],"metadata":{"id":"5DD0klIHg_Hz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["notebook_login()"],"metadata":{"id":"lGWisMVah-FH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# config parameters\n","DATASET_IN = \"derek-thomas/dataset-creator-reddit-bestofredditorupdates\"\n","DATASET_OUT = \"processed-subset-bestofredditorupdates\"\n","ENDPOINT_NAME = \"boru-jina-embeddings-demo-ie\"\n","\n","# number of async workers to use\n","MAX_WORKERS = 5\n","# None to use all\n","ROW_COUNT = 100"],"metadata":{"id":"FnZ8jUhohYQa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`DATASET_IN` is where our text data is, and `DATASET_OUT` is where our embeddings will be stored.\n","\n","Inference Endpoints offers a number of GPUs that we can choose from."],"metadata":{"id":"ZDhCa2W_hkqe"}},{"cell_type":"code","source":["# GPU choice\n","VENDOR = 'aws'\n","REGION = 'us-east-1'\n","INSTANCE_SIZE = 'x1'\n","INSTANCE_TYPE = 'nvidia-a10g'"],"metadata":{"id":"0D3-6cUfh0xV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["who = whoami()\n","organization = getpass(\n","    prompt=\"What is your HuggingFace username or organization? (with an added payment method)\"\n",")\n","\n","namespace = organization or who[\"name\"]"],"metadata":{"id":"veXAtQ8IiEoz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Get dataset"],"metadata":{"id":"4ypD-F80iBSw"}},{"cell_type":"code","source":["dataset = load_dataset(DATASET_IN)\n","dataset"],"metadata":{"id":"c_pFIV4liIi9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset['train']"],"metadata":{"id":"16CGCusdiLcN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["documents = dataset['train'].to_pandas().to_dict('records')[:ROW_COUNT]\n","len(documents), documents[0]"],"metadata":{"id":"p0SUujt_iMc9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Inference Endpoints"],"metadata":{"id":"CsYUknWQiSwH"}},{"cell_type":"markdown","source":["### Create Inference Endpoint"],"metadata":{"id":"Hl4KF4fMiWII"}},{"cell_type":"markdown","source":["We will use the API to create an Inference Endpoint"],"metadata":{"id":"6UGqsgN_iZjj"}},{"cell_type":"code","source":["try:\n","    endpoint = create_inference_endpoint(\n","        ENDPOINT_NAME,\n","        repository='jinaai/jina-embeddings-v2-base-en',\n","        revision=\"7302ac470bed880590f9344bfeee32ff8722d0e5\",\n","        task='sentence-embeddings',\n","        framework='pytorch',\n","        accelerator='gpu',\n","        instance_size=INSTANCE_SIZE,\n","        instance_type=INSTANCE_TYPE,\n","        region=REGION,\n","        vendor=VENDOR,\n","        namespace=namespace,\n","        custom_image={\n","            'health_route': '/health',\n","            'env': {\n","                'MAX_BATCH_TOKENS': str(MAX_WORKERS * 2048),\n","                'MAX_CONCURRENT_REQUESTS': \"512\",\n","                'MODEL_ID': \"/repository\"\n","            },\n","            'url': 'ghcr.io/huggingface/text-embeddings-inference:0.5.0'\n","        },\n","        type='protected'\n","    )\n","except:\n","    endpoint = [\n","        ie for ie in list_inference_endpoints(namespace=namespace)\n","        if ie.name == ENDPOINT_NAME\n","    ][0]\n","    print(f\"Using existing endpoint {endpoint.name}\")"],"metadata":{"id":"exvq_nC3iVcH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note:\n","* We used `jinaai/jina-embeddings-v2-base-en` as our model. For reproducibility we pinned it to a specific version\n","* Most embedding models are based on BERT architecture.\n","* `MAX_BATCH_TOKENS` is chosen based on our number of workers and the context window of our embedding model.\n","* `type=\"protected\"` utilizes the security from Inference Endpoints\n","* We used 1x Nivida A10 GPU since `jina-embeddings-v2` is memory hungry"],"metadata":{"id":"48RtUSrIjNYv"}},{"cell_type":"code","source":["%%time\n","endpoint.wait()"],"metadata":{"id":"f8Sd-lhjjzX1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["When we use `endpoint.client.post` we get a bytes string back. We need to convert this to a `np.array`:"],"metadata":{"id":"UU_alr-rj45x"}},{"cell_type":"code","source":["response = endpoint.client.post(\n","    json={\n","        'inputs': \"This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music!\",\n","        'truncate': True\n","    },\n","    task='feature-extraction'\n",")\n","response = np.array(json.loads(response.decode()))\n","response[0]"],"metadata":{"id":"3WdY4p5okAqi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We may have inputs that exceed the context. In such scenarios, it is up to us to handle them. In this example, we would truncate rather than have an error:"],"metadata":{"id":"Sio4SDlBkMrB"}},{"cell_type":"code","source":["embedding_input = \"This input will get multiplied\" * 10000\n","print(f\"The length of the `embedding_input` is: {len(embedding_input)}\")\n","\n","response = endpoint.client.post(\n","    json={\n","        'inputs': embedding_input,\n","        'truncate': True\n","    },\n","    task='feature-extraction'\n",")\n","response = np.array(json.loads(response.decode()))\n","print(response[0])"],"metadata":{"id":"geDkWxNLl4m-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Get embeddings"],"metadata":{"id":"zD0Cpgi7mTap"}},{"cell_type":"code","source":["async def request(document, semaphore):\n","    # semaphore guard\n","    async with semaphore:\n","        result = await endpoint.async_client.post(\n","            json={\n","                'inputs': document['content'],\n","                'truncate': True\n","            },\n","            task='feature-extraction'\n","        )\n","        result = np.array(json.loads(result.decode()))\n","        document['embedding'] = result[0] # assume API's output can be directly assigned\n","        return document\n","\n","\n","async def main(documents):\n","    # Semaphore to limit concurrent requests\n","    semaphore = asyncio.BoundedSemaphore(MAX_WORKERS)\n","\n","    tasks = [request(document, semaphore) for document in documents]\n","\n","    for f in tqdm(asyncio.as_completed(tasks), total=len(documents)):\n","        await f"],"metadata":{"id":"ECGgL77imUXj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start = time.perf_counter()\n","\n","# get embeddings\n","await main(documents)\n","\n","# make sure we got it all\n","count = 0\n","for document in documents:\n","    if 'embedding' in document.keys() and len(document['embedding']) == 768:\n","        count += 1\n","print(f\"Embeddings = {count} documents = {len(documents)}\")\n","\n","\n","elapsed_time = time.perf_counter() - start\n","minutes, seconds = divmod(elapsed_time, 60)\n","print(f\"{int(minutes) min {seconds:.2f}} sec\")"],"metadata":{"id":"MwbkTMFPnBY9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Pause Inference Endpoint"],"metadata":{"id":"rpjObu-5KJUd"}},{"cell_type":"markdown","source":["If we finish running, we can pause the endpoint so we do not incur any extra charges and also analyze the cost:"],"metadata":{"id":"EI1-KjelKM9p"}},{"cell_type":"code","source":["endpoint = endpoint.pause()\n","print(f\"Endpint status: {endpoint.status}\")"],"metadata":{"id":"iCexLJNmKLx_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Push updated dataset to Hub"],"metadata":{"id":"kHLnoVbnKYRy"}},{"cell_type":"markdown","source":["We now have our documents updated with the embeddings we wanted. We need to first convert it back to a `Dataset` format:"],"metadata":{"id":"m-NnNZ3lKdMd"}},{"cell_type":"code","source":["df = pd.DataFrame(documents)\n","dataset = DatasetDict({'train': Dataset.from_pandas(df)})"],"metadata":{"id":"9YHWPlV3Kavf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset.push_to_hub(repo_id=DATASET_OUT)\n","print(f'Dataset is at https://huggingface.co/datasets/{who[\"name\"]}/{DATASET_OUT}')"],"metadata":{"id":"E-XmiYFxKsjf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Analyze usage"],"metadata":{"id":"h_sMjHVAKxXm"}},{"cell_type":"markdown","source":["Go to our `dashboard_url`"],"metadata":{"id":"kb7Ip3alK1FF"}},{"cell_type":"code","source":["dashboard_url = f\"https://ui.endpoints.huggingface.co/{namespace}/endpoints/{ENDPOINT_NAME}\"\n","print(dashboard_url)"],"metadata":{"id":"udbC1bvxKzCt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Deleta endpoint"],"metadata":{"id":"Itpzlk4GK94Y"}},{"cell_type":"markdown","source":["We can delete our endpoint if we do not need it anymore:"],"metadata":{"id":"F1k4Vw2rLAR7"}},{"cell_type":"code","source":["endpoint = endpoint.delete()\n","\n","if not endpoint:\n","    print(\"Endpoint deleted successfully\")\n","else:\n","    print(\"Delete endpoint manually\")"],"metadata":{"id":"whbTdEZtK_u2"},"execution_count":null,"outputs":[]}]}