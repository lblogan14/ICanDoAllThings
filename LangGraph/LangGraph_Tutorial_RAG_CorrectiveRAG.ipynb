{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62211,
     "status": "ok",
     "timestamp": 1732132227275,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "Otooo-_UejLB",
    "outputId": "65bac52d-d822-4a81-e111-e6e23409ca82"
   },
   "outputs": [],
   "source": [
    "! pip install -qU langchain_community tiktoken langchain-openai langchainhub chromadb langchain langgraph tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1732132227275,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "YuE7B0v0esOf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TAVILY_API_KEY'] = 'your_tavily_api_key'\n",
    "os.environ['OPENAI_API_KEY'] = 'your_openai_api_key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk2A8PFwew_E"
   },
   "source": [
    "# Corrective RAG (CRAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRVuCCPpezu8"
   },
   "source": [
    "Corrective-RAG (CRAG) is a strategy for RAG that incorporates self-reflection / self-grading on retrieved documents.\n",
    "\n",
    "In the original paper, a few steps are taken:\n",
    "* If at least one document exceeds the threshold for relevance, then it proceeds to generation\n",
    "* Before generation, it performs knowledge refinement\n",
    "* This partitions the document into \"knowledge strips\"\n",
    "* It grades each strip, and filters our irrelevant ones\n",
    "* If all documents fall below the relevance threshold or if the grader is unsure, then the framework seeks an additional datasource\n",
    "* It will use web search to supplement retrieval\n",
    "\n",
    "In our implementation:\n",
    "* We skip the knowledge refinement phase as a first pass. This can be added back as a node, if desired.\n",
    "* If any documents are irrelevant, we opt to supplement retreival with web search.\n",
    "* We use Tavily search for web search\n",
    "* We use query re-writing to optimize the query for web search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwMqlAziftAF"
   },
   "source": [
    "# Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18006,
     "status": "ok",
     "timestamp": 1732132245278,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "CN9mwtzbezKj",
    "outputId": "c14aa622-a540-46ba-d5bc-5aa6ef28c8e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKgA_h0NH214"
   },
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1732132511801,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "3NkqB3IWH2cD"
   },
   "outputs": [],
   "source": [
    "### Retrieval Grader\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Data Model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo-0125', temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"\n",
    "    You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
    "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "Give a binary score 'yes' or 'no' to indicate whether the document is relevant to the question.\n",
    "\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', system),\n",
    "        ('human', \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1285,
     "status": "ok",
     "timestamp": 1732132571416,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "wpJ1K1dkJJ6t",
    "outputId": "d845f3f0-53c7-46b3-bfdb-e2a0dd6b9002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "# Test the retrieval grader\n",
    "question = 'agent memory'\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(\n",
    "    retrieval_grader.invoke(\n",
    "        {'question': question, 'document': doc_txt}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1732132669245,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "6dUEbrDCJYN5",
    "outputId": "b37940b6-c926-4dfa-e995-85ddc14d7706"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull('rlm/rag-prompt')\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo-0125', temperature=0)\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1563,
     "status": "ok",
     "timestamp": 1732132719261,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "mnwHkwz9JwR6",
    "outputId": "64dbc186-690a-4825-9d01-294043b37486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The agent system overview includes components like planning, subgoal decomposition, reflection, and refinement. Generative agents combine LLM with memory, planning, and reflection mechanisms for behavior conditioned on past experiences. The memory stream module serves as a long-term memory database for recording agents' experiences.\n"
     ]
    }
   ],
   "source": [
    "# Test the generation\n",
    "generation = rag_chain.invoke(\n",
    "    {'context': docs, 'question': question}\n",
    ")\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1732132859869,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "jhpfQv-jJ8NS"
   },
   "outputs": [],
   "source": [
    "### Question Re-writer\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo-0125', temperature=0)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"\n",
    "    You are a question re-writer that converts an input question to a better version that is optimized \\n\n",
    "for web search. Look at the input and try to reason about the underlying semantic intent / meaning\n",
    "\"\"\"\n",
    "rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', system),\n",
    "        (\n",
    "            'human',\n",
    "            'Here is the initial question: \\n\\n {question} \\n Formulate an improved question.',\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = rewrite_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 736,
     "status": "ok",
     "timestamp": 1732132890337,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "rY-ufTz2Ke26",
    "outputId": "29c807ec-8d13-46e5-b2df-2f77640c3d51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal question: agent memory\n",
      "Re-written question: What is the role of memory in artificial intelligence agents?\n"
     ]
    }
   ],
   "source": [
    "print(f\"Orignal question: {question}\")\n",
    "print(f\"Re-written question: {question_rewriter.invoke({'question': question})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1wf36NSKoYJ"
   },
   "source": [
    "# Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1732132931925,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "E4Oj-cLrKmNa"
   },
   "outputs": [],
   "source": [
    "### Search\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBRu3Y4tKyKI"
   },
   "source": [
    "# Create Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOKUZ3rhK0Px"
   },
   "source": [
    "## Define Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1732133044273,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "fdPohJYxKwhQ"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"Represent the state of our graph\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 112,
     "status": "ok",
     "timestamp": 1732134303461,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "42rRQEKcLLfK"
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print('--- RETRIEVE ---')\n",
    "    question = state['question']\n",
    "\n",
    "    # Retrival\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\n",
    "        'documents': documents,\n",
    "        'question': question,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print('--- GENERATE ---')\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke(\n",
    "        {'context': documents, 'question': question}\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'documents': documents,\n",
    "        'question': question,\n",
    "        'generation': generation,\n",
    "    }\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"Determine whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Update document key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "    print('--- CHECK DOCUMENT RELEVANCE TO QUESTION ---')\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "\n",
    "    # Score each document\n",
    "    filtered_docs = []\n",
    "    web_search = 'no'\n",
    "    for doc in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {'question': question, 'document': doc.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == 'yes':\n",
    "            print('--- GRADE: DOCUMENT RELEVANT ---')\n",
    "            filtered_docs.append(doc)\n",
    "        else:\n",
    "            print('--- GRADE: DOCUMENT NOT RELEVANT ---')\n",
    "            web_search = 'yes'\n",
    "            continue\n",
    "\n",
    "    return {\n",
    "        'documents': filtered_docs,\n",
    "        'question': question,\n",
    "        'web_search': web_search,\n",
    "    }\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Update question key with re-written question\n",
    "    \"\"\"\n",
    "    print('--- TRANSFORM QUERY ---')\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({'question': question})\n",
    "\n",
    "    return {\n",
    "        'documents': documents,\n",
    "        'question': better_question,\n",
    "    }\n",
    "\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Update documents key with appended web results\n",
    "    \"\"\"\n",
    "    print('--- WEB SEARCH ---')\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.invoke({'query': question})\n",
    "    web_results = \"\\n\".join([doc['content'] for doc in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {\n",
    "        'documents': documents,\n",
    "        'question': question,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1732134304494,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "9YVx29cTNfOV"
   },
   "outputs": [],
   "source": [
    "### Edges\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"Determine whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: binary decision for next node to call\n",
    "    \"\"\"\n",
    "    print('--- ASSESS GRADED DOCUMENTS ---')\n",
    "    question = state['question']\n",
    "    web_search = state['web_search']\n",
    "    documents = state['documents']\n",
    "\n",
    "    if web_search == 'yes':\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"--- DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY ---\"\n",
    "        )\n",
    "        return 'transform_query'\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"--- DECISION: GENERATE ---\")\n",
    "        return 'generate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeEVU3KbOgUq"
   },
   "source": [
    "## Compile Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1732134304612,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "PWUt00lOOfrk"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node('retrieve', retrieve) # retrieve\n",
    "workflow.add_node('grade_documents', grade_documents) # check relevance\n",
    "workflow.add_node('transform_query', transform_query) # re-write query\n",
    "workflow.add_node('web_search_node', web_search) # web search\n",
    "workflow.add_node('generate', generate) # generate\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, 'retrieve')\n",
    "workflow.add_edge('retrieve', 'grade_documents')\n",
    "workflow.add_conditional_edges(\n",
    "    'grade_documents',\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        'transform_query': 'transform_query',\n",
    "        'generate': 'generate',\n",
    "    }\n",
    ")\n",
    "workflow.add_edge('transform_query', 'web_search_node')\n",
    "workflow.add_edge('web_search_node', 'generate')\n",
    "workflow.add_edge('generate', END)\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1732134305243,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "0dT0Bq41PPK8",
    "outputId": "cbdfc104-c292-4d01-96eb-47bf33a1b2f6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(\n",
    "    app.get_graph(xray=True).draw_mermaid_png()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHiMXa2HPcsz"
   },
   "source": [
    "# Use the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7731,
     "status": "ok",
     "timestamp": 1732134314585,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "F-AXHtt0PZmL",
    "outputId": "0503736a-d83f-4e15-f812-a85cc6ec023c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RETRIEVE ---\n",
      "\"Node 'retrieve':\"\n",
      "{ 'documents': [ Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'),\n",
      "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'),\n",
      "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'),\n",
      "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\")],\n",
      "  'question': 'what are the types of agent memory?'}\n",
      "'\\n---\\n'\n",
      "--- CHECK DOCUMENT RELEVANCE TO QUESTION ---\n",
      "--- GRADE: DOCUMENT NOT RELEVANT ---\n",
      "--- GRADE: DOCUMENT NOT RELEVANT ---\n",
      "--- GRADE: DOCUMENT RELEVANT ---\n",
      "--- GRADE: DOCUMENT RELEVANT ---\n",
      "--- ASSESS GRADED DOCUMENTS ---\n",
      "--- DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY ---\n",
      "\"Node 'grade_documents':\"\n",
      "{ 'documents': [ Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'),\n",
      "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\")],\n",
      "  'question': 'what are the types of agent memory?',\n",
      "  'web_search': 'yes'}\n",
      "'\\n---\\n'\n",
      "--- TRANSFORM QUERY ---\n",
      "\"Node 'transform_query':\"\n",
      "{ 'documents': [ Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'),\n",
      "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\")],\n",
      "  'question': 'What are the different types of memory in agents?'}\n",
      "'\\n---\\n'\n",
      "--- WEB SEARCH ---\n",
      "\"Node 'web_search_node':\"\n",
      "{ 'documents': [ Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'),\n",
      "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\"),\n",
      "                 Document(metadata={}, page_content=\"Memory for agents Memory for agents At Sequoia’s AI Ascent conference in March, I talked about three limitations for agents: planning, UX, and memory. But what even is memory? While the exact shape of memory that your agent has may differ by application, we do see different high level types of memory. Below is my rough, ELI5 explanation of each type and practical ways for how todays agents may use and update this memory type. Besides just thinking about the type of memory to update in their agents, we also see developers thinking about how to update agent memory. One way to update agent memory is “in the hot path”. Why do we care about memory for agents?\\nMemory Management In AI Agents Memory Management In AI Agents Explore memory management techniques in AI agents, focusing on efficiency and optimization for enhanced performance. Types of Memory in AI Agents Types of Memory in AI Agents ---------------------------- Memory management in AI agents incorporates short-term memory for context and long-term memory using external storage, such as vector databases, enabling efficient information retrieval and enhanced reasoning. Memory management in AI agents is crucial for optimizing performance and enhancing user interactions. By leveraging short-term, long-term, and contextual memory, agents can provide more personalized and efficient interactions, ultimately leading to better outcomes for users. This ongoing development aims to enhance memory management in AI agents, ensuring they can provide more coherent and contextually relevant interactions. Types of Memory in AI Agents\\nMemory: The agent's memory stores crucial information gathered during operation. This data can include past experiences, environmental details, and learned patterns, all of which are used to\\nIn the diagram presented at the beginning of the article I have hidden short-term memory as part of the agent core as it is continuously used in the reasoning loop to decide on the next set of actions to be taken in order to solve the provided human intent. Short-term memory is extremely important in Agentic applications as it represents additional context we are providing to the agent via a system prompt. This means that short term memory can be continuously enriched by sourcing information from different kinds of memories available to the agent that we will discuss in following chapters. This additional context is stored as part of the system prompt in short-term (working) memory and can be used by the agent to plan its next steps.\\nTypes of AI Agents. There are different types of AI agents that suit different needs: Simple Reflex Agents: These agents make decisions based on the current situation. They don't remember past events. They're like basic robots following the same path again and again. Model-Based Reflex Agents: These agents have a memory. They understand how\")],\n",
      "  'question': 'What are the different types of memory in agents?'}\n",
      "'\\n---\\n'\n",
      "--- GENERATE ---\n",
      "\"Node 'generate':\"\n",
      "{ 'documents': [ Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'),\n",
      "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\"),\n",
      "                 Document(metadata={}, page_content=\"Memory for agents Memory for agents At Sequoia’s AI Ascent conference in March, I talked about three limitations for agents: planning, UX, and memory. But what even is memory? While the exact shape of memory that your agent has may differ by application, we do see different high level types of memory. Below is my rough, ELI5 explanation of each type and practical ways for how todays agents may use and update this memory type. Besides just thinking about the type of memory to update in their agents, we also see developers thinking about how to update agent memory. One way to update agent memory is “in the hot path”. Why do we care about memory for agents?\\nMemory Management In AI Agents Memory Management In AI Agents Explore memory management techniques in AI agents, focusing on efficiency and optimization for enhanced performance. Types of Memory in AI Agents Types of Memory in AI Agents ---------------------------- Memory management in AI agents incorporates short-term memory for context and long-term memory using external storage, such as vector databases, enabling efficient information retrieval and enhanced reasoning. Memory management in AI agents is crucial for optimizing performance and enhancing user interactions. By leveraging short-term, long-term, and contextual memory, agents can provide more personalized and efficient interactions, ultimately leading to better outcomes for users. This ongoing development aims to enhance memory management in AI agents, ensuring they can provide more coherent and contextually relevant interactions. Types of Memory in AI Agents\\nMemory: The agent's memory stores crucial information gathered during operation. This data can include past experiences, environmental details, and learned patterns, all of which are used to\\nIn the diagram presented at the beginning of the article I have hidden short-term memory as part of the agent core as it is continuously used in the reasoning loop to decide on the next set of actions to be taken in order to solve the provided human intent. Short-term memory is extremely important in Agentic applications as it represents additional context we are providing to the agent via a system prompt. This means that short term memory can be continuously enriched by sourcing information from different kinds of memories available to the agent that we will discuss in following chapters. This additional context is stored as part of the system prompt in short-term (working) memory and can be used by the agent to plan its next steps.\\nTypes of AI Agents. There are different types of AI agents that suit different needs: Simple Reflex Agents: These agents make decisions based on the current situation. They don't remember past events. They're like basic robots following the same path again and again. Model-Based Reflex Agents: These agents have a memory. They understand how\")],\n",
      "  'generation': 'The different types of memory in agents are short-term memory '\n",
      "                'and long-term memory. Short-term memory is used for '\n",
      "                'in-context learning, while long-term memory allows agents to '\n",
      "                'retain and recall information over extended periods. Memory '\n",
      "                'management in AI agents is crucial for optimizing performance '\n",
      "                'and enhancing user interactions.',\n",
      "  'question': 'What are the different types of memory in agents?'}\n",
      "'\\n---\\n'\n",
      "('The different types of memory in agents are short-term memory and long-term '\n",
      " 'memory. Short-term memory is used for in-context learning, while long-term '\n",
      " 'memory allows agents to retain and recall information over extended periods. '\n",
      " 'Memory management in AI agents is crucial for optimizing performance and '\n",
      " 'enhancing user interactions.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Run\n",
    "inputs = {'question': \"what are the types of agent memory?\"}\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    for key, val in output.items():\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        pprint(val, indent=2, width=80, depth=None)\n",
    "    pprint('\\n---\\n')\n",
    "\n",
    "# Final generation\n",
    "pprint(val['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7874,
     "status": "ok",
     "timestamp": 1732134355569,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "2jAm0WmMP4Ij",
    "outputId": "9f0babaf-a066-4761-cc6a-ff9aacce9b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RETRIEVE ---\n",
      "\"Node 'retrieve':\"\n",
      "{ 'documents': [ Document(metadata={'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\"}, page_content='Fig. 12. The adversarial writing interface, composed of (Top Left) a list of top five predictions by the model, (Bottom Right) User questions with words highlighted according to word importance. (Image source: Wallace et al. 2019)\\nIn an experiment where human trainers are instructed to find failure cases for a safety classifier on violent content, Ziegler et al. (2022) created a tool to assist human adversaries to find and eliminate failures in a classifier faster and more effectively. Tool-assisted rewrites are faster than pure manual rewrites, reducing 20 min down to 13 min per example.\\nPrecisely, they introduced two features to assist human writers:'),\n",
      "                 Document(metadata={'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\"}, page_content='The above step 1-3 are repeated for a number of iterations.'),\n",
      "                 Document(metadata={'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\"}, page_content='Fig. 8. Illustration of where adversarial triggers are introduced. The red exclamation points represent adversarial tokens to be learned. (Image source: Zou et al. 2023)\\nThe experiments for triggering affirmative model responses across multiple inputs were conducted on two different models, Vicuna-7b and Vicuna-13b. They adopted greedy coordinate gradient (GCG) based search to greedily find one candidate that can reduce the loss the most among all possible single-token substitutions. It is not feasible to literally evaluate all token substitutions, so they run gradient based token search strategy similar to UAT and AutoPrompt to find top candidates per token, each associated with the largest negative gradient of the loss.'),\n",
      "                 Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Later, Shum et al. (2023) found that in their experiments CoT prompts with only complex examples can improve the accuracy of complex questions, but perform poorly in simple questions; evidence shown on GSM8k.\\n\\n\\nChanging Q: to Question: is found to be helpful. (Fu et al. 2023)\\n\\n\\nYe & Durrett (2022) found that the benefit of including explanations in the prompt is small to moderate for NLP tasks that involve reasoning over text (i.e. QA and NLI) and the effects vary by models. They observed that explanations are more likely to be nonfactual than be inconsistent (i.e. whether explanation entails prediction). Nonfactual explanations most likely lead to incorrect predictions.')],\n",
      "  'question': 'How does the AlphaCodium paper work?'}\n",
      "'\\n---\\n'\n",
      "--- CHECK DOCUMENT RELEVANCE TO QUESTION ---\n",
      "--- GRADE: DOCUMENT NOT RELEVANT ---\n",
      "--- GRADE: DOCUMENT NOT RELEVANT ---\n",
      "--- GRADE: DOCUMENT NOT RELEVANT ---\n",
      "--- GRADE: DOCUMENT NOT RELEVANT ---\n",
      "--- ASSESS GRADED DOCUMENTS ---\n",
      "--- DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY ---\n",
      "\"Node 'grade_documents':\"\n",
      "{ 'documents': [],\n",
      "  'question': 'How does the AlphaCodium paper work?',\n",
      "  'web_search': 'yes'}\n",
      "'\\n---\\n'\n",
      "--- TRANSFORM QUERY ---\n",
      "\"Node 'transform_query':\"\n",
      "{ 'documents': [],\n",
      "  'question': 'How does the AlphaCodium paper function and what are its key '\n",
      "              'mechanisms?'}\n",
      "'\\n---\\n'\n",
      "--- WEB SEARCH ---\n",
      "\"Node 'web_search_node':\"\n",
      "{ 'documents': [ Document(metadata={}, page_content='Its key mechanisms include generating additional data \\' \\'like problem reflection and test reasoning to aid the iterative process, as \\' \\'well as enriching the code generation process. AlphaCodium aims to improve \\' \\'the performance of Large Language Models on code problems by following a \\' \\'test-based, multi-stage approach.\\')\\ncs arXiv:2401.08500 Help | Advanced Search arXiv identifier arXiv author ID Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering In this work, we propose a new approach to code generation by LLMs, which we call AlphaCodium - a test-based, multi-stage, code-oriented iterative flow, that improves the performances of LLMs on code problems. We tested AlphaCodium on a challenging code generation dataset called CodeContests, which includes competitive programming problems from platforms such as Codeforces. Subjects:   Machine Learning (cs.LG); Computation and Language (cs.CL); Software Engineering (cs.SE) Cite as:    arXiv:2401.08500 [cs.LG] (or arXiv:2401.08500v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2401.08500 From: Tal Ridnik [view email] Access Paper: cs.LG cs References & Citations Bibliographic and Citation Tools Bibliographic Explorer Toggle Connected Papers Toggle Which authors of this paper are endorsers?\\nFor example:\\n- YAML Structured output: asking the model to generate an output in YAML format, equivalent to a given Pydantic class\\nSemantic reasoning via bullet points analysis: Bullet points analysis encourages an in-depth understanding of the problem, and forces the model to divide the output into logical semantic sections, leading to improved results\\nLLMs do better when generating a modular code: when asking the model to: divide the generated code into small sub-functions, with meaningful names and functionality, we observe a better-produced code, with fewer bugs, and higher success rates for the iterative fixing stages.\\n Solving the entire dataset\\nto solve the entire dataset with AlphaCodium, from the root folder run:\\nRunning the evaluation\\nOnce you generate a solution for the entire dataset (valid or test), you can evaluate it by running:\\nTechnical Q&A\\nAggregating some technical questions we received about this project:\\nQ: How much time did you spend on \"prompt engineering\" compared to \"flow engineering\"?\\n Installation\\nsetup a virtual environment and run: pip install -r requirements.txt\\nDuplicate the file alpha_codium/settings/.secrets_template.toml, rename it as .secrets.toml, and fill in your OpenAI API key:\\nDownload the processed CodeContest validation and test dataset from hugging face, extract the zip file, and placed the extracted folder in the root of the project.\\n Soft decisions with double validation: with a double validation process, we add an extra step where, given the generated output, the model is asked to re-generate the same output, but correct it if needed\\nLeave room for exploration: since the model can be wrong, it’s better to avoid irreversible decisions, and leave room for exploration and code iterations with different possible solutions\\nThe list above is partial. Paper |\\nDataset\\nOfficial Implementation:\\nTal Ridnik, Dedy Kredo, Itamar Friedman\\nAbstract\\nCode generation problems differ from common natural language problems - they require matching the exact syntax of the target language, identifying happy paths and edge cases, paying attention to numerous small details in the problem spec, and addressing other code-specific issues and requirements.\\nIn this work, we propose a new approach to code generation by LLMs, which we call AlphaCodium - a test-based, multi-stage, code-oriented iterative flow, that improves the performances of LLMs on code problems. We tested AlphaCodium on a challenging code generation dataset called CodeContests, which includes competitive programming problems from platforms such as Codeforces. The following sections in the configuration file: solve, self_reflection,possible_solutions,generate_ai_tests,initial_code_generation,public_tests, ai_tests To solve a custom problem with AlphaCodium, first create a json file that includes the CodeContest problem fields, and then from the root folder run: A: The test set of CodeContests dataset comprises problems published after September 2021, while the GPT-4 model variant we used (gpt-4-0613) has a data cutoff of September 2021. A: For code problems in CodeContests, the tests are a list of input-output pairs.\\nSolving a specific problem\\nTo solve a specific problem with AlphaCodium, from the root folder run:\\nExample problem (test set, problem number 12):\\n\\\\n\\nSolving the entire dataset\\nto solve the entire dataset with AlphaCodium, from the root folder run:\\nRunning the evaluation\\nOnce you generate a solution for the entire dataset (valid or test), you can evaluate it by running:\\nTechnical Q&A\\nAggregating some technical questions we received about this project:\\nQ: How much time did you spend on \\\\\"prompt engineering\\\\\" compared to \\\\\"flow engineering\\\\\"?\\\\nA: Structured output almost completely eliminates the need for simple prompt engineering.\\\\nWe estimate that ~95% of the time we did more high-level design, reasoning, and injecting data at the correct places, ..., a.k.a. \\\\\"flow engineering\\\\\".\\n Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\\nPaper |\\\\nDataset\\nOfficial Implementation\\nTal Ridnik, Dedy Kredo, Itamar Friedman\\nCodiumAI\\nTable of Contents\\nAbstract\\nCode generation problems differ from common natural language problems - they require matching the exact syntax of the target language, identifying happy paths and edge cases, paying attention to numerous small details in the problem spec, and addressing other code-specific issues and requirements. \\\\n\\nInstallation\\n(1) setup a virtual environment and run: pip install -r requirements.txt\\n(2) Duplicate the file alpha_codium/settings/.secrets_template.toml, rename it as .secrets.toml, and fill in your OpenAI API key:\\n(3) Download the processed CodeContest validation and test dataset from hugging face, extract the zip file, and placed the extracted folder in the root of the project.\\n In this section, we present an example for a full problem from CodeContests dataset (test-set, problem 1), in order to demonstrate the complexity of the problems in the dataset, and the challenges they pose to LLMs.\\n \\\\nA: We used models with a context window of 8192 tokens, and we did not encounter cases where it did not suffice.\\\\nHowever, we clearly observed that as the context we used in practice grows larger (let\\'s say, above 4000 tokens), the model starts to \\\\\"ignore\\\\\" some of the information in the context.')],\n",
      "  'question': 'How does the AlphaCodium paper function and what are its key '\n",
      "              'mechanisms?'}\n",
      "'\\n---\\n'\n",
      "--- GENERATE ---\n",
      "\"Node 'generate':\"\n",
      "{ 'documents': [ Document(metadata={}, page_content='Its key mechanisms include generating additional data \\' \\'like problem reflection and test reasoning to aid the iterative process, as \\' \\'well as enriching the code generation process. AlphaCodium aims to improve \\' \\'the performance of Large Language Models on code problems by following a \\' \\'test-based, multi-stage approach.\\')\\ncs arXiv:2401.08500 Help | Advanced Search arXiv identifier arXiv author ID Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering In this work, we propose a new approach to code generation by LLMs, which we call AlphaCodium - a test-based, multi-stage, code-oriented iterative flow, that improves the performances of LLMs on code problems. We tested AlphaCodium on a challenging code generation dataset called CodeContests, which includes competitive programming problems from platforms such as Codeforces. Subjects:   Machine Learning (cs.LG); Computation and Language (cs.CL); Software Engineering (cs.SE) Cite as:    arXiv:2401.08500 [cs.LG] (or arXiv:2401.08500v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2401.08500 From: Tal Ridnik [view email] Access Paper: cs.LG cs References & Citations Bibliographic and Citation Tools Bibliographic Explorer Toggle Connected Papers Toggle Which authors of this paper are endorsers?\\nFor example:\\n- YAML Structured output: asking the model to generate an output in YAML format, equivalent to a given Pydantic class\\nSemantic reasoning via bullet points analysis: Bullet points analysis encourages an in-depth understanding of the problem, and forces the model to divide the output into logical semantic sections, leading to improved results\\nLLMs do better when generating a modular code: when asking the model to: divide the generated code into small sub-functions, with meaningful names and functionality, we observe a better-produced code, with fewer bugs, and higher success rates for the iterative fixing stages.\\n Solving the entire dataset\\nto solve the entire dataset with AlphaCodium, from the root folder run:\\nRunning the evaluation\\nOnce you generate a solution for the entire dataset (valid or test), you can evaluate it by running:\\nTechnical Q&A\\nAggregating some technical questions we received about this project:\\nQ: How much time did you spend on \"prompt engineering\" compared to \"flow engineering\"?\\n Installation\\nsetup a virtual environment and run: pip install -r requirements.txt\\nDuplicate the file alpha_codium/settings/.secrets_template.toml, rename it as .secrets.toml, and fill in your OpenAI API key:\\nDownload the processed CodeContest validation and test dataset from hugging face, extract the zip file, and placed the extracted folder in the root of the project.\\n Soft decisions with double validation: with a double validation process, we add an extra step where, given the generated output, the model is asked to re-generate the same output, but correct it if needed\\nLeave room for exploration: since the model can be wrong, it’s better to avoid irreversible decisions, and leave room for exploration and code iterations with different possible solutions\\nThe list above is partial. Paper |\\nDataset\\nOfficial Implementation:\\nTal Ridnik, Dedy Kredo, Itamar Friedman\\nAbstract\\nCode generation problems differ from common natural language problems - they require matching the exact syntax of the target language, identifying happy paths and edge cases, paying attention to numerous small details in the problem spec, and addressing other code-specific issues and requirements.\\nIn this work, we propose a new approach to code generation by LLMs, which we call AlphaCodium - a test-based, multi-stage, code-oriented iterative flow, that improves the performances of LLMs on code problems. We tested AlphaCodium on a challenging code generation dataset called CodeContests, which includes competitive programming problems from platforms such as Codeforces. The following sections in the configuration file: solve, self_reflection,possible_solutions,generate_ai_tests,initial_code_generation,public_tests, ai_tests To solve a custom problem with AlphaCodium, first create a json file that includes the CodeContest problem fields, and then from the root folder run: A: The test set of CodeContests dataset comprises problems published after September 2021, while the GPT-4 model variant we used (gpt-4-0613) has a data cutoff of September 2021. A: For code problems in CodeContests, the tests are a list of input-output pairs.\\nSolving a specific problem\\nTo solve a specific problem with AlphaCodium, from the root folder run:\\nExample problem (test set, problem number 12):\\n\\\\n\\nSolving the entire dataset\\nto solve the entire dataset with AlphaCodium, from the root folder run:\\nRunning the evaluation\\nOnce you generate a solution for the entire dataset (valid or test), you can evaluate it by running:\\nTechnical Q&A\\nAggregating some technical questions we received about this project:\\nQ: How much time did you spend on \\\\\"prompt engineering\\\\\" compared to \\\\\"flow engineering\\\\\"?\\\\nA: Structured output almost completely eliminates the need for simple prompt engineering.\\\\nWe estimate that ~95% of the time we did more high-level design, reasoning, and injecting data at the correct places, ..., a.k.a. \\\\\"flow engineering\\\\\".\\n Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering\\nPaper |\\\\nDataset\\nOfficial Implementation\\nTal Ridnik, Dedy Kredo, Itamar Friedman\\nCodiumAI\\nTable of Contents\\nAbstract\\nCode generation problems differ from common natural language problems - they require matching the exact syntax of the target language, identifying happy paths and edge cases, paying attention to numerous small details in the problem spec, and addressing other code-specific issues and requirements. \\\\n\\nInstallation\\n(1) setup a virtual environment and run: pip install -r requirements.txt\\n(2) Duplicate the file alpha_codium/settings/.secrets_template.toml, rename it as .secrets.toml, and fill in your OpenAI API key:\\n(3) Download the processed CodeContest validation and test dataset from hugging face, extract the zip file, and placed the extracted folder in the root of the project.\\n In this section, we present an example for a full problem from CodeContests dataset (test-set, problem 1), in order to demonstrate the complexity of the problems in the dataset, and the challenges they pose to LLMs.\\n \\\\nA: We used models with a context window of 8192 tokens, and we did not encounter cases where it did not suffice.\\\\nHowever, we clearly observed that as the context we used in practice grows larger (let\\'s say, above 4000 tokens), the model starts to \\\\\"ignore\\\\\" some of the information in the context.')],\n",
      "  'generation': 'The AlphaCodium paper functions by using a test-based, '\n",
      "                'multi-stage approach to improve the performance of Large '\n",
      "                'Language Models on code problems. Its key mechanisms include '\n",
      "                'generating additional data like problem reflection and test '\n",
      "                'reasoning to aid the iterative process, as well as enriching '\n",
      "                'the code generation process. AlphaCodium aims to enhance code '\n",
      "                'generation by following a structured flow that divides the '\n",
      "                'output into logical semantic sections, leading to improved '\n",
      "                'results.',\n",
      "  'question': 'How does the AlphaCodium paper function and what are its key '\n",
      "              'mechanisms?'}\n",
      "'\\n---\\n'\n",
      "('The AlphaCodium paper functions by using a test-based, multi-stage approach '\n",
      " 'to improve the performance of Large Language Models on code problems. Its '\n",
      " 'key mechanisms include generating additional data like problem reflection '\n",
      " 'and test reasoning to aid the iterative process, as well as enriching the '\n",
      " 'code generation process. AlphaCodium aims to enhance code generation by '\n",
      " 'following a structured flow that divides the output into logical semantic '\n",
      " 'sections, leading to improved results.')\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "inputs = {'question': \"How does the AlphaCodium paper work?\"}\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    for key, val in output.items():\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        pprint(val, indent=2, width=80, depth=None)\n",
    "    pprint('\\n---\\n')\n",
    "\n",
    "# Final generation\n",
    "pprint(val['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9BvggPSQKMP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOe2lblMgL1xDi4k4687VoD",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
