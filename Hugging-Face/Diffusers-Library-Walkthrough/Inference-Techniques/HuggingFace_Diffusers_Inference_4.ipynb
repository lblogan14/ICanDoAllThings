{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPLYQbXe1OhvrxcFy2Plrbj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vb0z8acCdAV7"},"outputs":[],"source":["!pip install -qU diffusers transformers huggingface_hub"]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","notebook_login()"],"metadata":{"id":"H1D0HSMldEY8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Pipeline callbacks"],"metadata":{"id":"esVM0HlvdE1G"}},{"cell_type":"markdown","source":["The denoising loop of a pipeline can be modified with custom define functions using the `callback_on_step_end` parameter. The callback function is executed at the end of each step, and modifies the pipeline attributes and variables for the next step."],"metadata":{"id":"CoPCzpWjd15H"}},{"cell_type":"markdown","source":["## Official callbacks"],"metadata":{"id":"ZURGvZvxeLPi"}},{"cell_type":"markdown","source":["* `SDCFGCutoffCallback`: disables the CFG after a certain number of steps for all SD 1.5 pipelines, including text-to-image, image-to-image, inpaint, and controlnet\n","* `SDXLCFGCutoffCallback`: disables the CFG after a certain number of steps for all SDXL pipelines, including text-to-image, image-to-image, inpaint, and controlnet\n","* `IPAdapterScaleCutoffCallback`: disables the IP Adapter after a certain number of steps for all pipelines supporting IP-Adapter.\n","\n","To set up a callback, we need to specify the number of denoising steps after which the calllback comes into effect:\n","* `cutoff_step_ratio`: float number with the ratio of the steps\n","* `cutoff_step_index`: integer number with the exact number of the steps"],"metadata":{"id":"SFuikXVZfz5X"}},{"cell_type":"code","source":["import torch\n","from diffusers import DPMSolverMultistepScheduler, StableDiffusionXLPipeline\n","from diffusers.callbacks import SDXLCFGCutoffCallback\n","\n","callback = SDXLCFGCutoffCallback(cutoff_step_ratio=0.4)\n","# we can also use `cutoff_step_index`\n","#callback = SDXLCFGCutoffCallback(cutoff_step_ratio=None, cutoff_step_index=10)\n","\n","pipeline = StableDiffusionXLPipeline.from_pretrained(\n","    'stabilityai/stable-diffusion-xl-base-1.0',\n","    torch_dtype=torch.float16,\n","    variant='fp16'\n",").to('cuda')\n","pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n","    pipeline.scheduler.config,\n","    use_karras_sigmas=True\n",")"],"metadata":{"id":"RzxXwa_sdGGw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"a sports car at the road, best quality, high quality, high detail, 8k resolution\"\n","generator = torch.Generator(device=\"cpu\").manual_seed(111)\n","\n","image = pipeline(\n","    prompt=prompt,\n","    negative_prompt=\"\",\n","    guidance_scale=6.5,\n","    num_inference_steps=25,\n","    generator=generator,\n","    callback_on_step_end=callback, # add callback here\n",").images[0]\n","image"],"metadata":{"id":"8kqjlC63hWI_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = pipeline(\n","    prompt=prompt,\n","    negative_prompt=\"\",\n","    guidance_scale=6.5,\n","    num_inference_steps=25,\n","    generator=generator,\n","\n",").images[0]\n","image"],"metadata":{"id":"Z6RKM_W5hpUu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dynamic classifier-free guidance"],"metadata":{"id":"wihc__yIhrCr"}},{"cell_type":"markdown","source":["**Dynamic classifier-free guidance (CFG)** is a feature that allows us to disable CFG after a certain number of inference steps which can help us save compute with minimal cost to performance.\n","\n","The callback function should have the following\n","* `pipeline` provides access to important properties such as `num_timesteps` and `guidance_scale`\n","* `step_index` and `timestep` tell us where we are in the denoising loop\n","* `callback_kwargs` is a dictionary that contains tensor variables we can modify during the denoising loop.\n","\n","Example of callback function:"],"metadata":{"id":"e_aqakPXj_V4"}},{"cell_type":"code","source":["def callback_dynamic_cfg(pipeline, step_index, timestep, callback_kwargs):\n","    # adjust the batch_size of prompt_embeds according to guidance_scale\n","    if step_index == int(pipeline.num_timesteps * 0.4):\n","        # turn off CFG after reaching 40% of num_timesteps\n","        prompt_embeds = callback_kwargs['prompt_embeds']\n","        prompt_embeds = prompt_embeds.chunk(2)[-1]\n","        # update guidance_scale and prompt_embeds\n","        pipeline._guidance_scale = 0.0\n","        callback_kwargs['prompt_embeds'] = prompt_embeds\n","\n","    return callback_kwargs"],"metadata":{"id":"MwolD6t-htT7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we can pass the callback function to the `callback_on_step_end` parameter and the `prompt_embeds` to `callback_on_step_end_tensor_inputs`:"],"metadata":{"id":"TgvluO8ZlQZS"}},{"cell_type":"code","source":["from diffusers import StableDiffusionPipeline\n","import torch\n","\n","pipeline = StableDiffusionPipeline.from_pretrained(\n","    'stable-diffusion-v1-5/stable-diffusion-v1-5',\n","    torch_dtype=torch.float16\n",").to('cuda')"],"metadata":{"id":"JnkJK6vllbzt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"a photo of an astronaut riding a horse on mars\"\n","generator = torch.Generator('cuda').manual_seed(111)\n","\n","image = pipeline(\n","    prompt,\n","    generator=generator,\n","    callback_on_step_end=callback_dynamic_cfg,\n","    callback_on_step_end_tensor_inputs=['prompt_embeds']\n",").images[0]\n","image"],"metadata":{"id":"gYDsnlUTln_f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Interrupt the diffusion process"],"metadata":{"id":"qz8QwFLLl2Ed"}},{"cell_type":"markdown","source":["Stopping the diffusion process early is useful when building UIs that work with Diffusers because it allows users to stop the generation process if they are unhappy with the intermediate results.\n","\n","This callback function should take the following: `pipeline`, `i`, `t`, and `callback_kwargs`. Set the pipeline's `_interrupt` attribute to `True` to stop the diffusion process after a certain number of steps.\n","\n","Here, the diffusion process is stopped after 10 steps even though `num_inference_steps` is set to 50."],"metadata":{"id":"zaEV7ugLodYL"}},{"cell_type":"code","source":["from diffusers import StableDiffusionPipeline\n","\n","pipeline = StableDiffusionPipeline.from_pretrained(\"stable-diffusion-v1-5/stable-diffusion-v1-5\")\n","pipeline.enable_model_cpu_offload()\n","num_inference_steps = 50"],"metadata":{"id":"WWUEXU4xl31G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def interrupt_callback(pipeline, i, t, callback_kwargs):\n","    stop_idx = 10\n","\n","    if i == stop_idx:\n","        pipeline._interrupt = True\n","\n","    return callback_kwargs\n","\n","\n","image = pipeline(\n","    'A photo of a cat',\n","    num_inference_steps=num_inference_steps,\n","    callback_on_step_end=interrupt_callback\n",").images[0]\n","image"],"metadata":{"id":"S65VTVoTpYW5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Display image after each generation step"],"metadata":{"id":"MkypotZbpplj"}},{"cell_type":"markdown","source":["Display an image after each generation step by accessing and converting the latents after each step into an image. The latent space is compressed to 128x128, so the images are also 128x128 which is useful for a quick preview."],"metadata":{"id":"6WuWRYHOr1Yf"}},{"cell_type":"markdown","source":["1. Use the function below to convert the SDXL latents (4 channels) to RGB tensors (3 channels)"],"metadata":{"id":"RxqcWTh1r2ee"}},{"cell_type":"code","source":["import torch\n","from PIL import Image\n","\n","def latents_to_rgb(latents):\n","    weights = (\n","        (60, -60, 25, -70),\n","        (60,  -5, 15, -50),\n","        (60,  10, -5, -35),\n","    )\n","\n","    weights_tensor = torch.t(torch.tensor(weights, dtype=latents.dtype).to(latents.device))\n","    biases_tensor = torch.tensor((150, 140, 130), dtype=latents.dtype).to(latents.device)\n","\n","    rgb_tensor = torch.einsum(\"...lxy,lr -> ...rxy\", latents, weights_tensor) + biases_tensor.unsqueeze(-1).unsqueeze(-1)\n","    image_array = rgb_tensor.clamp(0, 255).byte().cpu().numpy().transpose(1,2,0)\n","\n","    return Image.fromarray(image_array)"],"metadata":{"id":"jyM9En9gruwU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Create a function to decode and save the latents into an image"],"metadata":{"id":"lmTeXBcD2zhT"}},{"cell_type":"code","source":["def decode_tensors(pipeline, step, timestep, callback_kwargs):\n","    latents = callback_kwargs['latents']\n","\n","    image = latents_to_rgb(latents[0])\n","    image.save(f\"step_{step}.png\")\n","\n","    return callback_kwargs"],"metadata":{"id":"_flfAjiq22yT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Pass the `decode_tensors` function to the `callback_on_step_end` parameter to decode the tensors after each step."],"metadata":{"id":"QA4XYcSM3COp"}},{"cell_type":"code","source":["from diffusers import AutoPipelineForText2Image\n","\n","pipeline = AutoPipelineForText2Image.from_pretrained(\n","    'stabilityai/stable-diffusion-xl-base-1.0',\n","    torch_dtype=torch.float16,\n","    variant='fp16',\n","    use_safetensors=True\n",").to('cuda')"],"metadata":{"id":"X_WgChDC3IuW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = pipeline(\n","    prompt=\"A croissant shaped like a cute bear\",\n","    negative_prompt=\"deformed, ugly, bad anatomy\",\n","    callback_on_step_end=decode_tensors,\n","    callback_on_step_end_tensor_inputs=['latents']\n",").images[0]"],"metadata":{"id":"le_d3MbD3VS6"},"execution_count":null,"outputs":[]}]}