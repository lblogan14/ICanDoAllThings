{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJPsE4sOaFH3NXqJanctqb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"729fbd9ed1e542f5b04476351a60d6e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba57efc9b57e428d92f343b0c97217c3","IPY_MODEL_8c8506c2829543ebb120bfd025efe644","IPY_MODEL_9885c8527d0a4aaf977a3ba4fcb62ad8"],"layout":"IPY_MODEL_a47c5447609f4f16acca3b8e82676c1d"}},"ba57efc9b57e428d92f343b0c97217c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f2bd745ee1f413aa2e7da896e948c89","placeholder":"​","style":"IPY_MODEL_f1c47fa7aaa246e2a76613cb19ed2ccf","value":"test.csv: 100%"}},"8c8506c2829543ebb120bfd025efe644":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0222a70ae27a4ab8bfc7d058cd2a8095","max":256156,"min":0,"orientation":"horizontal","style":"IPY_MODEL_499d7ab0824044bca290d50e015153fb","value":256156}},"9885c8527d0a4aaf977a3ba4fcb62ad8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5817d79846034b0c9ff9b102a7846398","placeholder":"​","style":"IPY_MODEL_a359c08dfbd547a2a4ba0c0eac451431","value":" 256k/256k [00:00&lt;00:00, 12.4MB/s]"}},"a47c5447609f4f16acca3b8e82676c1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f2bd745ee1f413aa2e7da896e948c89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1c47fa7aaa246e2a76613cb19ed2ccf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0222a70ae27a4ab8bfc7d058cd2a8095":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"499d7ab0824044bca290d50e015153fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5817d79846034b0c9ff9b102a7846398":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a359c08dfbd547a2a4ba0c0eac451431":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"681883f84c1f4df99eb8dec8deabf310":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93af1147408441738d1ed5bfcb461714","IPY_MODEL_634817cf14ce4d14ba0e822d64ee5f62","IPY_MODEL_78d0ce9ce2674a888f6eef6277092400"],"layout":"IPY_MODEL_4f9036597bd4489dbd1e49905a68a6a0"}},"93af1147408441738d1ed5bfcb461714":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1a02ceb95774e1b99205e31251232ec","placeholder":"​","style":"IPY_MODEL_1b8183e7d20d4a77859c3160139a5fc9","value":"Generating test split: "}},"634817cf14ce4d14ba0e822d64ee5f62":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_437b615ea20548a898051a3da0cce418","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_179083eab00b45dd99a30310b4cefbdd","value":1}},"78d0ce9ce2674a888f6eef6277092400":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdfbd1155a7f4c06898f21831ff17af1","placeholder":"​","style":"IPY_MODEL_de860336f7344ab79081d72f255a9a9a","value":" 678/0 [00:00&lt;00:00, 6601.20 examples/s]"}},"4f9036597bd4489dbd1e49905a68a6a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1a02ceb95774e1b99205e31251232ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b8183e7d20d4a77859c3160139a5fc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"437b615ea20548a898051a3da0cce418":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"179083eab00b45dd99a30310b4cefbdd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bdfbd1155a7f4c06898f21831ff17af1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de860336f7344ab79081d72f255a9a9a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Annotate Text Data Using Active Learning with Cleanlab"],"metadata":{"id":"Hw90z1LGReXC"}},{"cell_type":"markdown","source":["In this example, we will use active learning to improve a fune-tuned HuggingFace transformer for text classification, while keeping the total number of collected labels from human annotators low.\n","\n","When resource constraints prevent us from acquiring labels for the entirety of our data, active learning aims to save both time and money by selecting which examples data annotators should spend their effort labeling."],"metadata":{"id":"uE1Dxs1gRkWd"}},{"cell_type":"markdown","source":["## Active Learning"],"metadata":{"id":"4eKQkhLgS__x"}},{"cell_type":"markdown","source":["**Active learning** helps prioritize what data to label in order to maximize the performance of a supervised machine learning model trained on the labelled data.\n","\n","The learning process ususally happens iteratively. At each round, active learning tells us which examples we should collect additional annotations for to improve our current model the most under a limited labeling budget.\n","\n","[ActiveLab](https://arxiv.org/abs/2301.11856) is an active learning algorithm that is useful when the labels coming from human annotators are noisy and when we should collect one more annotation for a previously annotated example (whose label seems suspect) versus for a not-yet-annotated example. After collecting these new annotations for a batch of data to increase our training dataset, we re-train our model and evaluate its test accuracy."],"metadata":{"id":"WXXMGrPlTCKi"}},{"cell_type":"markdown","source":["## Setups"],"metadata":{"id":"hst8U-VoUBcy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dQojJf6aRcK8"},"outputs":[],"source":["!pip install -qU datasets transformers scikit-learn matplotlib cleanlab"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import random\n","import transformers\n","import datasets\n","import matplotlib.pyplot as plt\n","from transformers import (\n","    AutoTokenizer, AutoModel, AutoModelForSequenceClassification,\n","    TrainingArguments, Trainer\n",")\n","from datasets import load_dataset, Dataset, DatasetDict, ClassLabel\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import StratifiedKFold\n","from scipy.special import softmax\n","from datetime import datetime\n","\n","from cleanlab.multiannotator import(\n","    get_majority_vote_label,\n","    get_active_learning_scores,\n","    get_label_quality_multiannotator\n",")\n","\n","pd.set_option('max_colwidth', None)"],"metadata":{"id":"VDgvnZC4UEx3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Collect and organize data"],"metadata":{"id":"zu3y72iFUvlj"}},{"cell_type":"markdown","source":["We will use the [Standford Politeness corpus](https://huggingface.co/datasets/Cleanlab/stanford-politeness) as the dataset."],"metadata":{"id":"_gTDIhxNVJ6g"}},{"cell_type":"code","source":["labeled_data_file = {'labeled': 'X_labeled_full.csv'}\n","unlabeled_data_file = {'unlabeled': 'X_unlabeled.csv'}\n","test_data_file = {'test': 'test.csv'}\n","\n","X_labeled_full = load_dataset(\n","    'Cleanlab/stanford-politeness',\n","    split='labeled',\n","    data_files=labeled_data_file\n",")\n","X_unlabeded = load_dataset(\n","    'Cleanlab/stanford-politeness',\n","    split='unlabeled',\n","    data_files=unlabeled_data_file\n",")\n","test = load_dataset(\n","    'Cleanlab/stanford-politeness',\n","    split='test',\n","    data_files=test_data_file\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["729fbd9ed1e542f5b04476351a60d6e2","ba57efc9b57e428d92f343b0c97217c3","8c8506c2829543ebb120bfd025efe644","9885c8527d0a4aaf977a3ba4fcb62ad8","a47c5447609f4f16acca3b8e82676c1d","9f2bd745ee1f413aa2e7da896e948c89","f1c47fa7aaa246e2a76613cb19ed2ccf","0222a70ae27a4ab8bfc7d058cd2a8095","499d7ab0824044bca290d50e015153fb","5817d79846034b0c9ff9b102a7846398","a359c08dfbd547a2a4ba0c0eac451431","681883f84c1f4df99eb8dec8deabf310","93af1147408441738d1ed5bfcb461714","634817cf14ce4d14ba0e822d64ee5f62","78d0ce9ce2674a888f6eef6277092400","4f9036597bd4489dbd1e49905a68a6a0","c1a02ceb95774e1b99205e31251232ec","1b8183e7d20d4a77859c3160139a5fc9","437b615ea20548a898051a3da0cce418","179083eab00b45dd99a30310b4cefbdd","bdfbd1155a7f4c06898f21831ff17af1","de860336f7344ab79081d72f255a9a9a"]},"id":"inx3JOqVUxkq","executionInfo":{"status":"ok","timestamp":1744399690525,"user_tz":300,"elapsed":1462,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}},"outputId":"af7c3333-7c97-4f5f-8e56-8de31048acc6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["test.csv:   0%|          | 0.00/256k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"729fbd9ed1e542f5b04476351a60d6e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"681883f84c1f4df99eb8dec8deabf310"}},"metadata":{}}]},{"cell_type":"code","source":["!wget -nc -O 'extra_annotations.npy' 'https://huggingface.co/datasets/Cleanlab/stanford-politeness/resolve/main/extra_annotations.npy?download=true'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9IldiWyyUkIW","executionInfo":{"status":"ok","timestamp":1744399695891,"user_tz":300,"elapsed":518,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}},"outputId":"ac235c88-439f-4fa9-9007-15ac60483672"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-04-11 19:28:13--  https://huggingface.co/datasets/Cleanlab/stanford-politeness/resolve/main/extra_annotations.npy?download=true\n","Resolving huggingface.co (huggingface.co)... 3.168.73.106, 3.168.73.129, 3.168.73.111, ...\n","Connecting to huggingface.co (huggingface.co)|3.168.73.106|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cdn-lfs-us-1.hf.co/repos/3a/2f/3a2fc34cf625e69cabda6493d475e2b30302e6ccd28e9f3d398c1055528f129d/d89f555ae53ec9849439fd00fe71803462cf153175b29986958e47c0b4f8fd51?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27extra_annotations.npy%3B+filename%3D%22extra_annotations.npy%22%3B&Expires=1744403294&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDQwMzI5NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzNhLzJmLzNhMmZjMzRjZjYyNWU2OWNhYmRhNjQ5M2Q0NzVlMmIzMDMwMmU2Y2NkMjhlOWYzZDM5OGMxMDU1NTI4ZjEyOWQvZDg5ZjU1NWFlNTNlYzk4NDk0MzlmZDAwZmU3MTgwMzQ2MmNmMTUzMTc1YjI5OTg2OTU4ZTQ3YzBiNGY4ZmQ1MT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=V7Sq1W08bScOARU2pWftZ4hjYPd8si6%7ENoA9TmQWzYrqaoN07tn2nIkfompn2NgPJzI11GV8o0iHsYwziJPG-9kAit09l7DTiVPKUjkzqzkIeHahA4-UeSnG8UvaS5VKLv7SccuLFWUGrLqGqh3WsEM6LKnIbCkBM5P1B%7Ew8ZxWkuW-9FE9tNazQQPnQ5szKw0tVopjXYLdjLtbzoiwK2EIOKu97rKbIggFOMe0bngGQdOv6Bt9xJIihEZO1c4pQA1zkil2jKlGOQKvSFYyI7-gXPvn8PCfE%7EKGQyuQShkFUWgz%7E%7EK17UVmur-3OJVpSKCKLkC8W-XgM%7EJ0gxN87zw__&Key-Pair-Id=K24J24Z295AEI9 [following]\n","--2025-04-11 19:28:14--  https://cdn-lfs-us-1.hf.co/repos/3a/2f/3a2fc34cf625e69cabda6493d475e2b30302e6ccd28e9f3d398c1055528f129d/d89f555ae53ec9849439fd00fe71803462cf153175b29986958e47c0b4f8fd51?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27extra_annotations.npy%3B+filename%3D%22extra_annotations.npy%22%3B&Expires=1744403294&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDQwMzI5NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzNhLzJmLzNhMmZjMzRjZjYyNWU2OWNhYmRhNjQ5M2Q0NzVlMmIzMDMwMmU2Y2NkMjhlOWYzZDM5OGMxMDU1NTI4ZjEyOWQvZDg5ZjU1NWFlNTNlYzk4NDk0MzlmZDAwZmU3MTgwMzQ2MmNmMTUzMTc1YjI5OTg2OTU4ZTQ3YzBiNGY4ZmQ1MT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=V7Sq1W08bScOARU2pWftZ4hjYPd8si6%7ENoA9TmQWzYrqaoN07tn2nIkfompn2NgPJzI11GV8o0iHsYwziJPG-9kAit09l7DTiVPKUjkzqzkIeHahA4-UeSnG8UvaS5VKLv7SccuLFWUGrLqGqh3WsEM6LKnIbCkBM5P1B%7Ew8ZxWkuW-9FE9tNazQQPnQ5szKw0tVopjXYLdjLtbzoiwK2EIOKu97rKbIggFOMe0bngGQdOv6Bt9xJIihEZO1c4pQA1zkil2jKlGOQKvSFYyI7-gXPvn8PCfE%7EKGQyuQShkFUWgz%7E%7EK17UVmur-3OJVpSKCKLkC8W-XgM%7EJ0gxN87zw__&Key-Pair-Id=K24J24Z295AEI9\n","Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.164.124.68, 18.164.124.54, 18.164.124.3, ...\n","Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.164.124.68|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 296650 (290K) [binary/octet-stream]\n","Saving to: ‘extra_annotations.npy’\n","\n","extra_annotations.n 100%[===================>] 289.70K  --.-KB/s    in 0.03s   \n","\n","2025-04-11 19:28:14 (9.61 MB/s) - ‘extra_annotations.npy’ saved [296650/296650]\n","\n"]}]},{"cell_type":"code","source":["extra_annotations = np.load('extra_annotations.npy', allow_pickle=True).item()"],"metadata":{"id":"oSnK-IeVUpW_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_labeled_full = X_labeled_full.to_pandas()\n","X_labeled_full.set_index('id', inplace=True)\n","\n","X_unlabeded = X_unlabeded.to_pandas()\n","X_unlabeded.set_index('id', inplace=True)\n","\n","test = test.to_pandas()"],"metadata":{"id":"jmv2qnEwU1pg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Classify the politeness of text"],"metadata":{"id":"PwKvAhimVC6m"}},{"cell_type":"markdown","source":["The dataset is structured as a binary text classification task, to classify whether each phrase is polite or impolite.\n","\n","Human annotators are given a selected text phrase and they provide an (imperfect) annotation regarding its polintess: 0 for impolite and 1 for polite.\n","\n","To train a transformer classifer on the annotated data, we measure model accuracy over a set of held-out test examples, where we feel confident about their ground truth labels because they are derived from a consensus amongst 5 annotators who labeled each of these examples.\n","\n","As for the training data, we have\n","* `X_labeled_full`: our initial training set with just a small set of 100 text examples labeled with 2 annotations per example.\n","* `X_unlabeled`: large set of 1900 unlabeled text examples we can consider having annotators label.\n","* `extra_annotations`: pool of additional annotations we pull from when an annotation is requested for an example."],"metadata":{"id":"NUY6kcjbVQXe"}},{"cell_type":"markdown","source":["### Visualize data"],"metadata":{"id":"7YjtjCvpWDsr"}},{"cell_type":"code","source":["# multi-annotated data\n","X_labeled_full.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":405},"id":"9PXrfIQHVCGz","executionInfo":{"status":"ok","timestamp":1744400183297,"user_tz":300,"elapsed":66,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}},"outputId":"fd59a154-a4fd-4f7b-a11d-ea6729e614b5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                                                                                                                                                          text  \\\n","id                                                                                                                                                                                                               \n","450d326d                                                                                                                                                           <url>. Congrats, or should I say good luck?   \n","6a22f4ec                                                                                                                      Can I get some time to finish what I am doing without everything being deleted??   \n","823f1104                                              Ok. Thank you for clarifying. Could you be more specific as to what you are specifying as \"the claim\" so that I may find relevant information to refute?   \n","7677905a                                                      One wonders, of course, who \"Elliott of Macedon\" would have been. Probably something analogous to Brian of Nazareth but in a Macedonian phalanx?   \n","a1ce799b  So, let me make sure I understand this. You think that, if we remove an image as it does not meet the NFCC, you would then be able to upload the same image, only this time, it would meet the NFCC?   \n","\n","          a6  a12  a16  a19  a20  a22  a39  a42  a52  ...  a157  a158  a178  \\\n","id                                                    ...                     \n","450d326d NaN  NaN  1.0  NaN  NaN  0.0  NaN  NaN  NaN  ...   NaN   NaN   NaN   \n","6a22f4ec NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   NaN   \n","823f1104 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   NaN   \n","7677905a NaN  NaN  NaN  NaN  NaN  NaN  0.0  NaN  NaN  ...   NaN   NaN   NaN   \n","a1ce799b NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   NaN   NaN   NaN   \n","\n","          a180  a185  a193  a196  a197  a215  a216  \n","id                                                  \n","450d326d   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n","6a22f4ec   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n","823f1104   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n","7677905a   NaN   NaN   0.0   NaN   NaN   NaN   NaN  \n","a1ce799b   NaN   NaN   NaN   NaN   0.0   NaN   1.0  \n","\n","[5 rows x 34 columns]"],"text/html":["\n","  <div id=\"df-c8dbccad-1913-4571-a409-1b85547b1939\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>a6</th>\n","      <th>a12</th>\n","      <th>a16</th>\n","      <th>a19</th>\n","      <th>a20</th>\n","      <th>a22</th>\n","      <th>a39</th>\n","      <th>a42</th>\n","      <th>a52</th>\n","      <th>...</th>\n","      <th>a157</th>\n","      <th>a158</th>\n","      <th>a178</th>\n","      <th>a180</th>\n","      <th>a185</th>\n","      <th>a193</th>\n","      <th>a196</th>\n","      <th>a197</th>\n","      <th>a215</th>\n","      <th>a216</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>450d326d</th>\n","      <td>&lt;url&gt;. Congrats, or should I say good luck?</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6a22f4ec</th>\n","      <td>Can I get some time to finish what I am doing without everything being deleted??</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>823f1104</th>\n","      <td>Ok. Thank you for clarifying. Could you be more specific as to what you are specifying as \"the claim\" so that I may find relevant information to refute?</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7677905a</th>\n","      <td>One wonders, of course, who \"Elliott of Macedon\" would have been. Probably something analogous to Brian of Nazareth but in a Macedonian phalanx?</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>a1ce799b</th>\n","      <td>So, let me make sure I understand this. You think that, if we remove an image as it does not meet the NFCC, you would then be able to upload the same image, only this time, it would meet the NFCC?</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 34 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8dbccad-1913-4571-a409-1b85547b1939')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c8dbccad-1913-4571-a409-1b85547b1939 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c8dbccad-1913-4571-a409-1b85547b1939');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f8c66836-f0e7-4466-99d9-3a7f9ac4b7e9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f8c66836-f0e7-4466-99d9-3a7f9ac4b7e9')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f8c66836-f0e7-4466-99d9-3a7f9ac4b7e9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"X_labeled_full"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# unlabeled data\n","X_unlabeded.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"yx_Ek0XdWpQz","executionInfo":{"status":"ok","timestamp":1744400202756,"user_tz":300,"elapsed":42,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}},"outputId":"0969bee6-903a-4878-d38d-088b852e0fe8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                                                                                                                                   text\n","id                                                                                                                                                                                     \n","486aff36                                         The review has been up there for something like six weeks, I notice. Think you'll be able to take care of those last couple of things?\n","201d7655                                                                                                   How many other states follow the same pattern?  And do we really need it to?\n","c9125774                 You added the name Ken Taylor to the <url> page but there is no such person listed on the DOD website as having received that award. Who were you refering to?\n","593ac8fb                                                                                                               I found <url> whilst looking for something else. Any use to you?\n","d1fdcdba  If it were me I'd want to try and find out more about how/why this happened first before I continued to use that software. Have you asked at the talk page I mentioned above?"],"text/html":["\n","  <div id=\"df-03c46849-fa2d-4b8b-be8d-dc9e804281f8\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>486aff36</th>\n","      <td>The review has been up there for something like six weeks, I notice. Think you'll be able to take care of those last couple of things?</td>\n","    </tr>\n","    <tr>\n","      <th>201d7655</th>\n","      <td>How many other states follow the same pattern?  And do we really need it to?</td>\n","    </tr>\n","    <tr>\n","      <th>c9125774</th>\n","      <td>You added the name Ken Taylor to the &lt;url&gt; page but there is no such person listed on the DOD website as having received that award. Who were you refering to?</td>\n","    </tr>\n","    <tr>\n","      <th>593ac8fb</th>\n","      <td>I found &lt;url&gt; whilst looking for something else. Any use to you?</td>\n","    </tr>\n","    <tr>\n","      <th>d1fdcdba</th>\n","      <td>If it were me I'd want to try and find out more about how/why this happened first before I continued to use that software. Have you asked at the talk page I mentioned above?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03c46849-fa2d-4b8b-be8d-dc9e804281f8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-03c46849-fa2d-4b8b-be8d-dc9e804281f8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-03c46849-fa2d-4b8b-be8d-dc9e804281f8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-05927146-bb4b-40ba-8785-57c8835f3c46\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05927146-bb4b-40ba-8785-57c8835f3c46')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-05927146-bb4b-40ba-8785-57c8835f3c46 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"X_unlabeded","summary":"{\n  \"name\": \"X_unlabeded\",\n  \"rows\": 1400,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1400,\n        \"samples\": [\n          \"431df2fa\",\n          \"9f1f107e\",\n          \"b3d64e7e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1398,\n        \"samples\": [\n          \"Just a question about the maintenance categories that FemtoBot automatically creates each month: I've noticed that the bot is frequently forced to recreate old, long-deleted monthly categories in the <person> queue, because an article got reverted to an old version for one reason or another and resulted in the old category being temporarily repopulated again. I'm just putting this forward as an idea for discussion, and am certainly not wedded to it u2014 but just to keep things simpler for everyone, I wonder what you would think about the feasibility and/or desirability of recoding the bot so that when it encounters a repopulated old maintenance category, it would retag the article to the ''current'' month instead of recreating the old one?\",\n          \"Thanks!  What type of documentation do you want u2014 an explanation of using the notes feature?\",\n          \"The benefit of a version of the sentence is that it helps clarify the differences between Lavoisier and Priestley; however, we need to be careful that we don't convey the wrong impression to the reader. How best to do this?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# extra_annotaions contains the annotations that we will use\n","# when an additional annotation is requsted\n","extra_annotations\n","\n","# check the format for a random sample\n","{k: extra_annotations[k] for k in random.sample(list(extra_annotations.keys()), 5)}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S1oetmg4Wsgr","executionInfo":{"status":"ok","timestamp":1744400460048,"user_tz":300,"elapsed":7,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}},"outputId":"e6e9e528-b692-4eeb-884e-60dc11955b8e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'1fb3e07f': {'a16': 1.0, 'a22': 1.0, 'a61': 0.0, 'a160': 1.0, 'a175': 1.0},\n"," 'caae3ae6': {'a22': 1.0, 'a98': 0.0, 'a117': 0.0, 'a121': 0.0, 'a150': 0.0},\n"," '23e93d59': {'a61': 0.0, 'a76': 0.0, 'a99': 0.0, 'a145': 0.0, 'a185': 0.0},\n"," '59b1ff76': {'a22': 0.0, 'a49': 0.0, 'a100': 0.0, 'a113': 0.0, 'a166': 1.0},\n"," 'ff14ccc4': {'a16': 1.0, 'a61': 1.0, 'a73': 1.0, 'a174': 0.0, 'a205': 1.0}}"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# samples from test set\n","num_to_label = {0: 'Impolite', 1: 'Polite'}\n","\n","for i in range(2):\n","    print(f\"{num_to_label[i]} examples:\")\n","    subset = test[test.label == i][['text']].sample(n=3, random_state=111)\n","    print(subset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YzNpVurXXmcq","executionInfo":{"status":"ok","timestamp":1744400535054,"user_tz":300,"elapsed":17,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}},"outputId":"8a84ff8b-1c6d-4a6f-cec4-209284119e77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Impolite examples:\n","                                                     text\n","559             Huh? Is that a web address or a wikilink?\n","67                               <url>. Or is it just me?\n","231  So nearly a year later you change it all again. Why?\n","Polite examples:\n","                                                                                                                                                                                                                                                                  text\n","553                                                                                                         I tried to create a similar map for Canada but couldn't get a usable output from the site you used for the Australia map. Could you create a Canadian one?\n","44   There seems to have been something wrong with the pages you made on the V8 Supercar Championship Series - a glitch with the \"align\" tags in the beginning infobox made the text grotesquely overflow the margins. I've trimmed these down; mind checking my work?\n","87                                                                                                                                                                                                  Hope you had a good trip. Are you able to take a further look now?\n"]}]},{"cell_type":"markdown","source":["## Helper functions"],"metadata":{"id":"E6xSBJtTWX6Q"}},{"cell_type":"markdown","source":["`get_idx_to_label` is used in active learning scenarios when we deal with a mixture of labeled and unlabeled data. Its primary goal is to determine **which examples (from both labeled and unlabeled datasets) should be selected for additional annotations based on their active learning scores**."],"metadata":{"id":"1q5yNKKqYOXF"}},{"cell_type":"code","source":["# Get indices of examples with the lowest active learning score\n","# to collect more labels for\n","def get_idx_to_label(\n","        X_labeled_full,\n","        X_unlabeded,\n","        extra_annotations,\n","        batch_size_to_label,\n","        active_learning_scores,\n","        active_learning_scores_unlabeled=None\n","):\n","    if active_learning_scores_unlabeled is None:\n","        active_learning_scores_unlabeled = np.array([])\n","\n","    to_label_idx = []\n","    to_label_idx_unlabeled = []\n","\n","    num_labeled = len(active_learning_scores)\n","    active_learning_scores_combined = np.concatenate(\n","        (active_learning_scores, active_learning_scores_unlabeled)\n","    )\n","    to_label_idx_combined = np.argsort(active_learning_scores_combined)\n","\n","    # We want tot collect the n=batch_size best examples to collect another annotation for\n","    i = 0\n","    while (len(to_label_idx) + len(to_label_idx_unlabeled)) < batch_size_to_label:\n","        idx = to_label_idx_combined[i]\n","\n","        if idx < num_labeled:\n","            # We know this is an already annotated example.\n","            text_id = X_labeled_full.iloc[idx].name\n","            # make sure we have an annotation left to collect.\n","            if text_id in extra_annotations and extra_annotations[text_id]:\n","                to_label_idx.append(idx)\n","\n","        else:\n","            # We know this is an example that is currently not annotated\n","            # Subtract off offset to get back original index\n","            idx -= num_labeled\n","            text_id = X_unlabeded.iloc[idx].name\n","            # make sure we have an annotation left to collect\n","            if text_id in extra_annotations and extra_annotations[text_id]:\n","                to_label_idx_unlabeled.append(idx)\n","\n","        i += 1\n","\n","    to_label_idx = np.array(to_label_idx)\n","    to_label_idx_unlabeled = np.array(to_label_idx_unlabeled)\n","    return to_label_idx, to_label_idx_unlabeled"],"metadata":{"id":"ZdIrcVrOWZ4Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`get_idx_to_label_random` is used for an active learning context where the selection of data points for additional annotation is done randomly rather than based on a model's uncertainty or learning scores. This approach may be used as a baseline to compare against more sophisticated active learning strategies or in scenarios where it is unclear how to score examples."],"metadata":{"id":"yd5IOFgIr2Sw"}},{"cell_type":"code","source":["from shutil import which\n","# Get indices of random examples to collect more labels for\n","def get_idx_to_label_random(\n","        X_labeled_full,\n","        X_unlabeled,\n","        extra_annotations,\n","        batch_size_to_label\n","):\n","    to_label_idx = []\n","    to_label_idx_unlabeled = []\n","\n","    # Generate list of indices for both sets of examples\n","    labeled_idx = [(x, 'labeled') for x in range(len(X_labeled_full))]\n","    unlabeled_idx = []\n","    if X_unlabeded is not None:\n","        unlabeled_idx = [(x, 'unlabeled') for x in range(len(X_unlabeled))]\n","    combined_idx = labeled_idx + unlabeled_idx\n","\n","    # We want to collect the n=batch_size random examples to collect another annotation for\n","    while (len(to_label_idx) + len(to_label_idx_unlabeled)) < batch_size_to_label:\n","        # Random choice from indices\n","        # We time-seed to ensure randomness\n","        random.seed(datetime.now().timestamp())\n","        choice = random.choice(combined_idx)\n","        idx, which_subset = choice\n","\n","        if which_subset == 'labeled':\n","            # We know this is an already annotated example\n","            text_id = X_labeled_full.iloc[idx].name\n","            # Make sure we have an annotation left to collect\n","            if text_id in extra_annotations and extra_annotations[text_id]:\n","                to_label_idx.append(idx)\n","            combined_idx.remove(choice)\n","        else:\n","            # We know this is an example that is currently not annotated\n","            text_id = X_unlabeded.iloc[idx].name\n","            # Make sure we have an annotation left to collect\n","            if text_id in extra_annotations and extra_annotations[text_id]:\n","                to_label_idx_unlabeled.append(idx)\n","            combined_idx.remove(choice)\n","\n","    to_label_idx = np.array(to_label_idx)\n","    to_label_idx_unlabeled = np.array(to_label_idx_unlabeled)\n","    return to_label_idx, to_label_idx_unlabeled"],"metadata":{"id":"Uj6LORwysKg4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_std_dev(accuracy):\n","    \"\"\"Compute standard deviation across 2D array of accuracies.\"\"\"\n","    def compute_std_dev_ind(accs):\n","        mean = np.mean(accs)\n","        std_dev = np.std(accs)\n","        return np.array([mean - std_dev, mean + std_dev])\n","\n","    std_dev = np.apply_along_axis(compute_std_dev_ind, 0, accuracy)\n","    return std_dev\n","\n","def choose_existing(annotators, existing_annotators):\n","    \"\"\"Select which annotator we should collect another annotation from\"\"\"\n","    for annotator in annotators:\n","        # if we find one that has already given an annotation, we return it\n","        if annotator in existing_annotators:\n","            return annotator\n","\n","    # If we do not find an existing one, return a random one\n","    choice = random.choice(list(annotators.keys()))\n","    return choice\n","\n","def compute_metrics(p):\n","    \"\"\"compute_metrics function for Trainer\"\"\"\n","    logits, labels = p\n","    pred = np.argmax(logits, axis=1)\n","    pred_probs = softmax(logits, axis=1)\n","    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","    return {'logits': logits, 'pred_probs': pred_probs, 'accuracy': accuracy}\n","\n","def tokenize_function(examples):\n","    \"\"\"Tokenize text\"\"\"\n","    model_name = 'distilbert-base-uncased'\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    return tokenizer(\n","        examples['text'],\n","        padding='max_length',\n","        truncation=True,\n","    )\n","\n","def tokenize_data(data):\n","    \"\"\"Tokenize data\"\"\"\n","    dataset = Dataset.from_dict({'label': data['label'], 'text': data['text'].values})\n","    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","    tokenized_dataset = tokenized_dataset.cast_column('label', ClassLabel(names=['0', '1']))\n","    return tokenized_dataset"],"metadata":{"id":"XfIp7B29wW4q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`get_trainer` is to set up a training envrionment for a text classification task using DistilBERT, a distilled version of the BERT model."],"metadata":{"id":"lPJA85Tfx_4g"}},{"cell_type":"code","source":["def get_trainer(train_set, test_set):\n","    \"\"\"Get trainer for text classification\"\"\"\n","    model_name = 'distilbert-base-uncased'\n","    model_folder = 'model_training'\n","    max_training_steps = 300\n","    num_classes = 2\n","\n","    # Set training arguments\n","    training_args = TrainingArguments(\n","        output_dir=model_folder\n","        max_steps=max_training_steps,\n","        seed=int(datetime.now().timestamp())\n","    )\n","\n","    # Tokenize train/test set\n","    train_tokenized_dataset = tokenize_data(train_set)\n","    test_tokenized_dataset = tokenize_data(test_set)\n","\n","    # Initiate a pretrained model\n","    model = AutoModelForSequenceClassification.from_pretrained(\n","        model_name,\n","        num_labels=num_classes\n","    )\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        compute_metrics=compute_metrics,\n","        train_dataset=train_tokenized_dataset,\n","        eval_dataset=test_tokenized_dataset\n","    )\n","    return trainer"],"metadata":{"id":"WFj6zmc5yHzP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`get_pred_probs` is used to perform out-of-sample prediction probability computation for a given dataset using cross-validation, with additional handling for unlabeled data."],"metadata":{"id":"pGM-lLnn-4jE"}},{"cell_type":"code","source":["def get_pred_probs(X, X_unlabeled):\n","    \"\"\"Use cross-validation to get out-of-sample prediction probabilities\"\"\"\n","    # Generate cross-val splits\n","    n_splits = 3\n","    skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n","    skf_splits = [\n","        [train_index, test_index]\n","        for train_index, test_index in skf.split(X=X['test'], y=X['label'])\n","    ]\n","\n","    # Initiate empty array to store `pred_probs`\n","    num_examples, num_classes = len(X), len(X.label.value_counts())\n","    pred_probs = np.full((num_examples, num_classes), np.nan)\n","    pred_probs_unlabeled = None\n","\n","    # If we use up all examples from the initial unlabeled pool,\n","    # X_unlabeled will be None\n","    if X_unlabeled is not None:\n","        pred_probs_unlabeled = np.full((n_splits, len(X_unlabled), num_classes), np.nan)\n","\n","    # Iterate through cross-validation folds\n","    for split_num, split in enumerate(skf_splits):\n","        train_index, test_index = split\n","\n","        train_set = X.iloc[train_index]\n","        test_set = X.iloc[test_index]\n","\n","        # Get trainer with train/test subsets\n","        trainer = get_trainer(train_set, test_set)\n","        trainer.train()\n","        eval_metrics = trainer.evaluate()\n","\n","        # Get `pred_probs` and insert into dataframe\n","        pred_probs_fold = eval_metrics['eval_pred_probs']\n","        pred_probs[test_index] = pred_probs_fold\n","\n","        # Since we do not have labels for the unlabeled pool,\n","        # we compute `pred_probs` at each round of cross-val, and then\n","        # average the results at the end\n","        if X_unlabeled Is not None:\n","            dataset_unlabeled = Dataset.from_dict({'text': X_unlabeled['text'].values})\n","            unlabeled_tokenized_dataset = dataset_unlabeled.map(tokenize_function, batched=True)\n","            logits = trainer.predict(unlabeled_tokenized_dataset).predictions\n","            curr_pred_probs_unlabeled = softmax(logits, axis=1)\n","            pred_probs_unlabeled[split_num] = curr_pred_probs_unlabeled\n","\n","    # We average the `pred_probs` from each round of cross-val to get\n","    # `pred_probs` for the unlabeled pool\n","    if X_unlabeled is not None:\n","        pred_probs_unlabeled = np.mean(np.array(pred_probs_unlabeled), axis=0)\n","\n","    return pred_probs, pred_probs_unlabeled"],"metadata":{"id":"cdZfAFkH_aWY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`get_annotator` determines the most appropriate annotator to collect a new annotation from a specific example, based on a set of criteria while `get_annotation` focuses on collecting an actual annotation for a given example from a chosen annotator, and also deletes the collected annotation from the pool to prevent it from being selected again."],"metadata":{"id":"F3jXZu6FESV1"}},{"cell_type":"code","source":["def get_annotator(example_id):\n","    \"\"\"Determine which annotator to collect annotation from given example\"\"\"\n","    existing_annotators = set(X_labeled_full.drop('text', axis=1).columns)\n","    # Choose existing annotators first\n","    annotators = extra_annotations[example_id]\n","    chosen_annotator = choose_existing(annotators, existing_annotators)\n","    return chosen_annotator\n","\n","\n","def get_annotation(example_id, chosen_annotator):\n","    \"\"\"Collect an annotation for a given test example\"\"\"\n","    new_annotation = extra_annotations[example_id][chosen_annotator]\n","    del extra_annotations[example_id][chosen_annotator]\n","    return new_annotation"],"metadata":{"id":"UEn9Y7olEnrA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Methodology"],"metadata":{"id":"lRcywReEWbLK"}},{"cell_type":"markdown","source":["For each **active learning** round, we\n","1. Compute ActiveLab consensus labels for each training example derived from all annotations collected thus far\n","2. Train our transformer classification model on the current training set using these consensus labels\n","3. Evaluate test accuracy on the test set (which has high-quality ground truth labels)\n","4. Run cross-validation to get out-of-sample predicted class probabilities from our model for the entire training set and unlabeled set\n","5. Get ActiveLab active learning scores for each example in the training set and unlabeled set. These scores estimate how informative it would be to collect another annotation for each example\n","6. Select a subset (*n = batch_size*) of examples with the lowest active learning scores\n","7. Collect one additional annotation for each of the *n* selected examples\n","8. Add the new annotations (and new previously non-annotated examples if selected) to our training set for the next iteration\n","\n","Next, we compare models trained on data labeled via active leraning vs. data labeled via **random selection**. For each random selection round, we use majority vote consensus instead of ActiveLab consensus (in Step 1) and then randomly select the *n* examples to collect an additional label instead of using ActiveLab scores (in Step 6)."],"metadata":{"id":"WHTI5nUWFSfH"}},{"cell_type":"markdown","source":["### Model training and evaluation\n","\n","We will tokenize our train and test sets, and then initialize a pretrained DistilBert model. We will fine-tune DistilBert with 300 training steps. The model outputs predicted class probabilities which we convert to class predictions before evaluating their accuracy."],"metadata":{"id":"DJtiZXpkGYx8"}},{"cell_type":"markdown","source":["### Using active learning scores to decide what to label next\n","\n","During each round of active learning, we fit our transformer model vias 3-fold cross-validation on the current training set, which allows us to get out-of-sample predicted class probabilities for each example in the training set and we can also use the trained transformer to get out-of-sample predicted class probabilities for each example in the unlabeled pool. This is all done internally in the `get_pred_probs()` function. The use of out-of-sample predictions helps us avoid bias due to potential overfitting.\n","\n","Next, we pass the probabilistic predictions into the `get_active_learning_scores()` function from `cleanlab`. This method provides us with scores for all of our labeled and unlabeled data. Lower scores indicate data points for which collecting one additional label should be most informative for our current model (scores are directly comparable between labeled and unlabeled data).\n","\n","Using the `get_idx_to_label()` function, we will form a batch of examples with the lowest scores."],"metadata":{"id":"dSmJntXiG2pA"}},{"cell_type":"markdown","source":["### Adding new annotations\n","\n","The `combined_example_ids` are the ids of the test examples we want to collect an annotation for. For each of these, we use the `get_annotation` to collect a new annotation from an annotator. We will prioritize selecting annotations from annotators who have already annotated another example. If none of the annotators for the given example exist in the training set, we randomly select one. In this case, we add a new column to our training set which represents the new annotator. Finally, we add the newly collected annotation to the training set. If the corresponding example was previously non-annotated, we also add it to the training set and remove it from the unlabeled collection."],"metadata":{"id":"IRebuFT1H350"}},{"cell_type":"markdown","source":["### Implementation"],"metadata":{"id":"Wu2BjPmxIaax"}},{"cell_type":"code","source":["# For Active Learning demo, we add 25 additional annotations to the training set\n","# Each iteration for 25 rounds\n","num_rounds = 25\n","batch_size_to_label = 25\n","model_accuracy_arr = np.full(num_rounds, np.nan)\n","\n","# The `selection_method` determines if we use ActiveLab or random selection\n","# to choose the new annotation each round\n","selection_method = 'random'\n","# selection_method = 'active_learning'"],"metadata":{"id":"u3Qq5yogWc7C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# During each round, we\n","# - train our model\n","# - evaluate on unchanging test set\n","# - collect and add new annotations to training set\n","for i in range(num_rounds):\n","    # X_labeled_full is updated each iteration.\n","    # We drop the text column which leaves us with the annotations\n","    multiannotator_labels = X_labeled_full.drop('text', axis=1)\n","\n","    # Use majority vote when using random selection to select the consensus label for each example\n","    if i == 0 or selection_method == 'random':\n","        consensus_labels = get_majority_vote_label(multiannotator_labels)\n","\n","    # When using ActiveLab, use cleanlab's CrowdLab to select the consensus label for each example\n","    else:\n","        results = get_label_quality_multiannotator(\n","            multiannotator_labels,\n","            pred_probs_labeled,\n","            calibrate_probs=True\n","        )\n","        consensus_labels = results['label_quality']['consensus_label'].values\n","\n","    # We only need the text and label columns\n","    train_set = X_labeled_full[['text']]\n","    train_set['label'] = consensus_labels\n","    test_set = test[['text', 'label']]\n","\n","    # Train transformer model on the full set of labeled data\n","    # to evaluate model accuracy for the current round.\n","    # This is optional for demo, but\n","    # in practical applications, we may not have ground truth labels\n","    trainer = get_trainer(train_set, test_set)\n","    trainer.train()\n","    eval_metrics = trainer.evaluate()\n","    model_accuracy_arr[i] = eval_metrics['eval_accuracy']\n","\n","    # For ActiveLab, we need to run cross-validation to get out-of-sample predicted probabilities\n","    if selection_method == 'active_learning':\n","        pred_probs, pred_probs_unlabeled = get_pred_probs(train_set, X_unlabeled)\n","\n","        # Compute active learning scores\n","        active_learning_scores, active_learning_scores_unlabeled = get_active_learning_scores(\n","            multiannotator_labels,\n","            pred_probs,\n","            pred_probs_unlabeled\n","        )\n","\n","        # Get the indices of examples to collect more labels for\n","        chosen_examples_labeled, chosen_examples_unlabeled = get_idx_to_label(\n","            X_labeled_full,\n","            X_unlabeled,\n","            extra_annotations,\n","            batch_size_to_label,\n","            active_learning_scores,\n","            active_learning_scores_unlabeled\n","        )\n","\n","    # We do not need to run cross-validation,\n","    # just get random examples to collect annotations for\n","    if selection_method == 'random':\n","        chosen_examples_labeled, chosen_examples_unlabeled = get_idx_to_label_random(\n","            X_labeled_full,\n","            X_unlabeled,\n","            extra_annotations,\n","            batch_size_to_label\n","        )\n","\n","    unlabeled_example_ids = np.array([])\n","    # Check to see if we still have unlabeled examples left\n","    if X_unlabeled is not None:\n","        # Get unlabeled text examples we want to collect annotations for\n","        new_text = X_unlabeled.iloc[chosen_examples_unlabeled]\n","        unlabeled_example_ids = new_text.index.values\n","\n","        num_ex = len(new_text)\n","        num_annot = multiannotator_labels.shape[1]\n","        empty_annot = pd.DataFrame(\n","            data=np.full((num_ex, num_annot), np.nan),\n","            columns=multiannotator_labels.columns,\n","            index=unlabeled_example_ids\n","        )\n","        new_unlabeled_df = pd.concat([new_text, empty_annot], axis=1)\n","\n","        # Combine unlabeled text examples with existing, labeled examples\n","        X_labeled_full = pd.concat([X_labeled_full, new_unlabeled_df], axis=0)\n","\n","        # Remove examples from X_unlabeled and check if empty.\n","        # Once it is empty we set it to None to handle appropriately elsewhere.\n","        X_unlabeled = X_unlabeled.drop(new_text.index)\n","        if X_unlabeled.empty:\n","            X_unlabeled = None\n","\n","    if selection_method == 'active_learning':\n","        # Update `pred_prob` arrays with newly added examples if necessary\n","        if pred_probs_unlabeled is not None and len(chosen_examples_unlabeled) != 0:\n","            pred_probs_new = pred_probs_unlabeled[chosen_examples_unlabeled, :]\n","            pred_probs_labeled = np.concatenate((pred_probs, pred_probs_new))\n","            pred_probs_unlabeled = np.delete(pred_probs_unlabeled, chosen_examples_unlabeled, axis=0)\n","        else:\n","            # otherwise we have nothing to modify\n","            pred_probs_labeled = pred_probs\n","\n","    # Get combined list of text ID's to relabel\n","    labeled_example_ids = X_label_full.iloc[chosen_examples_labeled].index.values\n","    combined_example_ids = np.concatenate([labeled_example_ids, unlabeled_example_ids])\n","\n","    # We collect annotations for the selected examples\n","    for example_id in combined_example_ids:\n","        # choose which annotator to collect annotation from\n","        chosen_annotator = get_annotator(example_id)\n","        # collect new annotation\n","        new_annotation = get_annotation(example_id, chosen_annotator)\n","        # new annotator has been selected\n","        if chosen_annotator not in multiannotator_labels.columns.values:\n","            empty_col = np.full((len(X_labeled_full),), np.nan)\n","            X_labeled_full[chosen_annotator] = empty_col\n","\n","        # add selected annotation to the training set\n","        X_labeled_full.at[example_id, chosen_annotator] = new_annotation"],"metadata":{"id":"0IiaGIxlI1M9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Results"],"metadata":{"id":"7VmkRtkWWgn5"}},{"cell_type":"code","source":["# Get numpy array of results.\n","!wget -nc -O 'random_acc.npy' 'https://huggingface.co/datasets/Cleanlab/stanford-politeness/resolve/main/activelearn_acc.npy'\n","!wget -nc -O 'activelearn_acc.npy' 'https://huggingface.co/datasets/Cleanlab/stanford-politeness/resolve/main/random_acc.npy'"],"metadata":{"id":"0fK31w9BWhbi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_std_dev(accuracy):\n","    def compute_std_dev_ind(accs):\n","        mean = np.mean(accs)\n","        std_dev = np.std(accs)\n","        return np.array([mean - std_dev, mean + std_dev])\n","\n","    std_dev = np.apply_along_axis(compute_std_dev_ind, 0, accuracy)\n","    return std_dev"],"metadata":{"id":"ZEjC8BuHN0fU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["al_acc = np.load(\"activelearn_acc.npy\")\n","rand_acc = np.load(\"random_acc.npy\")\n","\n","rand_acc_std = compute_std_dev(rand_acc)\n","al_acc_std = compute_std_dev(al_acc)\n","\n","plt.plot(range(1, al_acc.shape[1] + 1), np.mean(al_acc, axis=0), label=\"active learning\", color=\"green\")\n","plt.fill_between(range(1, al_acc.shape[1] + 1), al_acc_std[0], al_acc_std[1], alpha=0.3, color=\"green\")\n","\n","plt.plot(range(1, rand_acc.shape[1] + 1), np.mean(rand_acc, axis=0), label=\"random\", color=\"red\")\n","plt.fill_between(range(1, rand_acc.shape[1] + 1), rand_acc_std[0], rand_acc_std[1], alpha=0.1, color=\"red\")\n","\n","plt.hlines(y=0.9, xmin=1.0, xmax=25.0, color=\"black\", linestyle=\"dotted\")\n","plt.legend()\n","plt.xlabel(\"Round Number\")\n","plt.ylabel(\"Test Accuracy\")\n","plt.title(\"ActiveLab vs Random Annotation Selection --- 5 Runs\")\n","plt.savefig(\"al-results.png\")\n","plt.show()"],"metadata":{"id":"xjU5FidtN3cN"},"execution_count":null,"outputs":[]}]}