{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPG55yWLI5sUYxQ8TgFNCo9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Semantic Reranking with ElasticSearch and HuggingFace"],"metadata":{"id":"RE0IeKXfPxwP"}},{"cell_type":"markdown","source":["In this example, we will implement semantic reranking in ElasticSearch by uploading a model from HuggingFace into an ElasticSearch cluster. We will use the `retriever` abstraction, a simpler ElasticSearch syntax for crafting queries and combining different search operations."],"metadata":{"id":"5Wnd-v8XP2x2"}},{"cell_type":"markdown","source":["Make sure you have `ELASTIC_CLOUD_ID` and `ELASTIC_DEPL_API_KEY` ready."],"metadata":{"id":"l5jISrmyQND8"}},{"cell_type":"markdown","source":["## Setups"],"metadata":{"id":"vgIfjRkIQUIT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TENqX_C9Ptne"},"outputs":[],"source":["!pip install -qU elasticsearch eland[pytorch]"]},{"cell_type":"code","source":["from elasticsearch import Elasticsearch, helpers"],"metadata":{"id":"ZJH_dc4FQaci"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Initialize Elasticsearch python client"],"metadata":{"id":"OxvYIz7xQd1m"}},{"cell_type":"code","source":["from google.colab import userdata\n","\n","ELASTIC_CLOUD_ID = userdata.get('ELASTIC_CLOUD_ID')\n","ELASTIC_DEPL_API_KEY = userdata.get('ELASTIC_DEPL_API_KEY')\n","\n","es = Elasticsearch(\n","    cloud_id=ELASTIC_CLOUD_ID,\n","    api_key=ELASTIC_DEPL_API_KEY,\n",")"],"metadata":{"id":"KpIZzF1WQhdB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(client.info())"],"metadata":{"id":"u1QBfZa5Qtxs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load data"],"metadata":{"id":"u6VvuSlmQ0ku"}},{"cell_type":"markdown","source":["In this example, we will load a small dataset of movies."],"metadata":{"id":"xJ4BgtjJLYx7"}},{"cell_type":"code","source":["from urllib.request import urlopen\n","import json\n","import time\n","\n","url = \"https://huggingface.co/datasets/leemthompo/small-movies/raw/main/small-movies.json\"\n","response = urlopen(url)\n","\n","data_json = json.loads(response.read())\n","\n","# Prepare the documents to be indexed\n","documents = []\n","for doc in data_json:\n","    documents.append({\n","        '_index': 'movies',\n","        '_source': doc\n","    })\n","\n","# Use helpers.bulk to index\n","helpers.bulk(client, documents)\n","print('Done indexing documents into `movies` index')\n","time.sleep(3)"],"metadata":{"id":"AAiO6TTmQ1c2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Upload HuggingFace model using Eland"],"metadata":{"id":"MtfooUkyROoz"}},{"cell_type":"markdown","source":["We will use Eland's `eland_import_hub_model` command to upload the model to ElasticSearch. In this example, we will upload the `cross-encoder/ms-macro-MiniLM-L-6-v2` text similarity model."],"metadata":{"id":"Lxs2__2VRR8Q"}},{"cell_type":"code","source":["!eland_import_hub_model \\\n","  --cloud-id $ELASTIC_CLOUD_ID \\\n","  --es-api-key $ELASTIC_API_KEY \\\n","  --hub-model-id cross-encoder/ms-marco-MiniLM-L-6-v2 \\\n","  --task-type text_similarity \\\n","  --clear-previous \\\n","  --start"],"metadata":{"id":"elKg7KxORRXG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create inference endpoint"],"metadata":{"id":"pPy_qrAnRkOl"}},{"cell_type":"markdown","source":["Next we will create an inference endpoint for the `rerank` task to deploy and manage our mdoel and, if necessary, spin up the necessary ML resources behind the scenes."],"metadata":{"id":"EuJWZmxWRl0G"}},{"cell_type":"code","source":["client.inference.put(\n","    task_type='rerank',\n","    inference_id='my-msmarco-minilm-model',\n","    inference_config={\n","        'service': 'elasticsearch',\n","        'service_settings': {\n","            'model_id': 'cross-encoder__ms-marco-minilm-l-6-v2',\n","            'num_allocations': 1,\n","            'num_threads': 1\n","        }\n","    }\n",")"],"metadata":{"id":"TuU0-1vqRlXz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["client.inference.get()"],"metadata":{"id":"UaNVks6FR83n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["When we deploy our model, we may need to sync our ML saved objects in the Kibana (or Serverless) UI."],"metadata":{"id":"klRGmw8ZR_wr"}},{"cell_type":"markdown","source":["## Lexical queries"],"metadata":{"id":"h1kPlfjOR-8N"}},{"cell_type":"markdown","source":["We will start with a `standard` retriever to test out some lexical (or full-text) searches and then we will compare the improvments when we layer in semantic reranking."],"metadata":{"id":"oWwzC_OXV168"}},{"cell_type":"markdown","source":["### Lexical match with `query_string` query"],"metadata":{"id":"0fvMCXt9V_ce"}},{"cell_type":"markdown","source":["Assuming that we vaguely remember that there is a famous movie about a killer who eats his victims and we pretend we have forgotten the word \"cannibal\".\n","\n","We can perform a query `query_string` to find the phrase `\"flesh-eating bad guy\"` in the `plot` field of our ElasticSearch documents:"],"metadata":{"id":"LxWQDhuLWGhe"}},{"cell_type":"code","source":["resp = client.search(\n","    index='movies',\n","    retriever={\n","        'standard': {\n","            'query': {\n","                'query_string': {\n","                    'query': 'flesh-eating bad guy',\n","                    'default_field': 'plot'\n","                }\n","            }\n","        }\n","    }\n",")\n","\n","if resp['hits']['hits']:\n","    for hit in resp['hits']['hits']:\n","        title = hit['_source']['title']\n","        plot = hit['_source']['plot']\n","        print(f\"Title: {title}\\nPlot: {plot}\\n\")\n","else:\n","    print('No search results found.')"],"metadata":{"id":"JDl2lUTpSHSW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Simple `multi_match` query"],"metadata":{"id":"CKHqXv_7L5a-"}},{"cell_type":"markdown","source":["This lexical query performs a standard keyword search for the term `\"crime\"` within the `\"plot\"` and `\"genre\"` fields of our ElasticSearch documents."],"metadata":{"id":"pdTGOXEQL-S5"}},{"cell_type":"code","source":["resp = client.search(\n","    index='movies',\n","    retriever={\n","        'standard': {\n","            'query': {\n","                'multi_match': {\n","                    'query': 'crime',\n","                    'fields': ['plot', 'genre']\n","                }\n","            }\n","        }\n","    }\n",")\n","\n","for hit in resp['hits']['hits']:\n","    title = hit['_source']['title']\n","    plot = hit['_source']['plot']\n","    print(f\"Title: {title}\\nPlot: {plot}\\n\")"],"metadata":{"id":"qdjVXb5FL8AJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note that the searched term is more broad instead of just \"flesh-eating bad guy\"."],"metadata":{"id":"vnJbAnT6M3YN"}},{"cell_type":"markdown","source":["## Semantic reranker"],"metadata":{"id":"zm-TqyVRMnmL"}},{"cell_type":"markdown","source":["Now we will wrap our standard query retriever in a `text_similarity_reranker`. This allows us to leverage the NLP model we deployed to ElasticSearch to rerank the results based on the phrase \"flesh-eating bad guy\"."],"metadata":{"id":"I8lJUH8qMp-G"}},{"cell_type":"code","source":["resp = client.search(\n","    index='movies',\n","    retriever={\n","        'text_similarity_reranker': {\n","            'retriever': {\n","                'standard': {\n","                    'query': {\n","                        'multi_match': {\n","                            'query': 'crime',\n","                            'fields': ['plot', 'genre']\n","                        }\n","                    }\n","                }\n","            },\n","            'field': 'plot',\n","            'inference_id': 'my-msmarco-minilm-model',\n","            'inference_text': 'flesh-eating bad guy'\n","        }\n","    }\n",")\n","\n","for hit in resp['hits']['hits']:\n","    title = hit['_source']['title']\n","    plot = hit['_source']['plot']\n","    print(f\"Title: {title}\\nPlot: {plot}\\n\")"],"metadata":{"id":"BJJ_gYnMMpQC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Semantic reranking helped us find the most relevant result by parsing a natural language query, overcoming the limitations of lexical search which relies more on exact matching. Semantic reranking enables semantic search in a few steps, without the need for generating and storing embeddings. Being able to use open source models hosted on Hugging Face natively in our Elasticsearch cluster is great for prototyping, testing, and building search experiences."],"metadata":{"id":"WdU7IG06NbLe"}},{"cell_type":"code","source":[],"metadata":{"id":"7T3fkoG9NfiD"},"execution_count":null,"outputs":[]}]}