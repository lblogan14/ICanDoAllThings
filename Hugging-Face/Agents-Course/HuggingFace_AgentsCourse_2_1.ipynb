{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The SmolAgents Framework"
      ],
      "metadata": {
        "id": "f3Z4mx9W1fxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to smolagents"
      ],
      "metadata": {
        "id": "HkeUstw12ebV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages of `smolagents`\n",
        "- **Simplicity**\n",
        "- **Flexible LLM Support**\n",
        "- **Code-First Approach**\n",
        "- **HF Hub Integration**\n",
        "\n",
        "Unlike other frameworks where agents write actions in JSON, `smolagents` **focuses on tool calls in code**, simplifying the execution process, because there is no need to parse the JSON in order to build code that calls the tools: the output can be exuceted directly.\n",
        "\n",
        "Agents in `smolagents` operate as **multi-step agents**. Each [`MultiStepAgent`](https://huggingface.co/docs/smolagents/main/en/reference/agents#smolagents.MultiStepAgent) performs:\n",
        "- one thought\n",
        "- one tool call and execution\n",
        "\n",
        "\n",
        "In addition to using [`CodeAgent`](https://huggingface.co/docs/smolagents/main/en/reference/agents#smolagents.CodeAgent) as the primary type of agent, `smolagents` also supports [`ToolCallingAgent`](https://huggingface.co/docs/smolagents/main/en/reference/agents#smolagents.ToolCallingAgent), which write tool calls in JSON.\n",
        "\n",
        "\n",
        "\n",
        "`smolagents` supports flexible LLM integration, allowing us to use any callable model that meets certain criteria. The framework provides several predefined classes to simplify model connections:\n",
        "- `TransformersModel` - implements a local `transformers` pipeline\n",
        "- `InferenceClientModel` - supports serverless inference calls through HuggingFace's infrastructure\n",
        "- `LiteLLMModel` - leverages [`LiteLLM`](https://www.litellm.ai/) for lightweight model interactions\n",
        "- `OpenAIServerModel` - connects to any service that offers an OpenAI API interface\n",
        "- `AzureOpenAIServerModel` - supports integration with any Azure OpenAI deployment"
      ],
      "metadata": {
        "id": "G8pQugRL2j1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Agents that Use Code"
      ],
      "metadata": {
        "id": "TEPxlfa84W6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code agents are the default agent type in `smolagents`. They generate Python tool calls to perform actions, achieving action representations that are efficient, expressive, and accurate.\n",
        "\n",
        "In a multi-step agent process, the LLM writes and executes actions, typically involving external tool calls. Traditional approaches use a JSON format to specify tool names and arguments as strings, which **the system must parse to determine which tool to execute.**\n",
        "\n",
        "However, research shows that **tool-calling LLMs work more effectively with code directly**. This is a core principle of `smolagents`. Writing actions in code rather than JSON offers several advantages:\n",
        "- **Composability** - easily combine and reuse actions\n",
        "- **Object management** - work directly with complex structures like images\n",
        "- **Generality** - express any computationally possible task\n",
        "- **Natural for LLMs** - high-quality code is already present in LLM training data\n",
        "\n",
        "\n",
        "\n",
        "A `CodeAgent` performs actions through a cycle of steps, with existing variables and knowledge being incorporated into the agent's context, which is kept in an execution log:\n",
        "- The system prompt is stored in a `SystemPromptStep`, and the user query is logged in a `TaskStep`.\n",
        "- Then the following while loop is exeucted:\n",
        "  - The `agent.write_memory_to_messages()` method writes the agent's logs into a list of LLM-readable chat messages.\n",
        "  - These messages are sent to a `Model`, which generates a completion.\n",
        "  - The completion is parsed to extract the action, which, in this case, should be a code snippet since we work with a `CodeAgent`.\n",
        "  - The action is executed.\n",
        "  - The results are logged into memory in an `ActionStep`.\n",
        "\n",
        "At the end of each step, if the agent includes any function calls (in `agent.step_callback`), they are executed."
      ],
      "metadata": {
        "id": "2WUliSGz4tBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example"
      ],
      "metadata": {
        "id": "82C0sRRr9Xx6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpONIvH31XUx"
      },
      "outputs": [],
      "source": [
        "!pip install -qU smolagents"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Selecting a playlist for the party using smolagents"
      ],
      "metadata": {
        "id": "lXEaBTBE9jiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can build an agent capable of searching the web using DuckDuckGo. For the model, we will rely on `InferenceClientModel`. The default model is `Qwen/Qwen2.5-Coder-32B-Instruct`."
      ],
      "metadata": {
        "id": "ZVJVtniQ9pP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import CodeAgent, DuckDuckGoSearchTool, InferenceClientModel\n",
        "\n",
        "agent = CodeAgent(\n",
        "    model=InferenceClientModel(),\n",
        "    tools=[DuckDuckGoSearchTool()]\n",
        ")"
      ],
      "metadata": {
        "id": "ZECTDorb9n8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "agent.run(\n",
        "    \"Search for the best music recomendations for a party at the Wayne's mansion.\"\n",
        ")"
      ],
      "metadata": {
        "id": "J8hEex2O-ac_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using a custom tool to prepare the menu"
      ],
      "metadata": {
        "id": "TA6_G-LU-kZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the `@tool` decorator to define a custom function that acts as a tool."
      ],
      "metadata": {
        "id": "mPt2cklA-oTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import CodeAgent, tool, InferenceClientModel\n",
        "\n",
        "# Tool to suggest a menu based on the occasion\n",
        "@tool\n",
        "def suggest_menu(occasion: str) -> str:\n",
        "    \"\"\"Suggests a menu based on the occasion.\n",
        "    Args:\n",
        "        occation (str): The type of occasion for the party. Allowed values are:\n",
        "                        - \"causal\": Menu for causal party.\n",
        "                        - \"formal\": Menu for formal party.\n",
        "                        - \"superhero\": Menu for superhero party.\n",
        "                        - \"custom\": Custom menu\n",
        "    \"\"\"\n",
        "    if occasion == \"causal\":\n",
        "        return \"Pizza, snacks, and drinks.\"\n",
        "    elif occasion == \"formal\":\n",
        "        return \"3-course dinner with wine and dessert.\"\n",
        "    elif occasion == \"superhero\":\n",
        "        return \"Buffet with high-energy and healthy food.\"\n",
        "    else:\n",
        "        return \"Custom menu for the butler.\"\n",
        "\n",
        "\n",
        "\n",
        "agent = CodeAgent(\n",
        "    model=InferenceClientModel(),\n",
        "    tools=[suggest_menu]\n",
        ")"
      ],
      "metadata": {
        "id": "_h8j0z_h-mi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\n",
        "    \"Prepare a formal menu for the party.\"\n",
        ")"
      ],
      "metadata": {
        "id": "tF3GDu0o-05O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using python imports inside the agent"
      ],
      "metadata": {
        "id": "JjrpftQG_ji8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the playlist and menu ready, our agent needs to calculate when everything would be ready if he starts preparing now.\n",
        "\n",
        "`smolagents` specializes in agents that write and execute Python code snippets, offering sandboxed execution for security.\n",
        "\n",
        "**Code execution has strict security measures** - imports outside a predefined safe list are blocked by default. However, we can authorize additional imports by passing them as strings in `additional_authorized_imports`:"
      ],
      "metadata": {
        "id": "VTNe5-9f_nTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import CodeAgent, InferenceClientModel\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "agent = CodeAgent(\n",
        "    model=InferenceClientModel(),\n",
        "    tools=[],\n",
        "    additional_authorized_imports=['datetime']\n",
        ")"
      ],
      "metadata": {
        "id": "ArRMteit_lnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\n",
        "    \"\"\"\n",
        "    Alfred needs to prepare for the party. Here are the tasks:\n",
        "    1. Prepare the drinks - 30 minutes\n",
        "    2. Decorate the mansion - 60 minutes\n",
        "    3. Set up the menu - 45 minutes\n",
        "    4. Prepare the music and playlist - 45 minutes\n",
        "\n",
        "    If we start right now, at what time will the party be ready?\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "bYfMjeMjCEch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sharing our custom party preparator aent to the Hub"
      ],
      "metadata": {
        "id": "p-5tIKU1CLGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.push_to_hub('<your_username>/AlfredAgent')"
      ],
      "metadata": {
        "id": "pOpKjwb-COJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alfred_agent = agent.from_hub('<your_username>/AlfredAgent', trust_remote_code=True)\n",
        "\n",
        "alfred_agent.run(\"Give me the best playlist for a party at Wayne's mansion. The party idea is a 'villain masquerade' theme\")"
      ],
      "metadata": {
        "id": "tK5OdvzNCbHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To complete and enpower the agent more, we have the following implementation"
      ],
      "metadata": {
        "id": "BqtwrQUKCxn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import CodeAgent, DuckDuckGoSearchTool, FinalAnswerTool, InferenceClientModel, Tool, tool, VisitWebpageTool\n",
        "\n",
        "@tool\n",
        "def suggest_menu(occasion: str) -> str:\n",
        "    \"\"\"\n",
        "    Suggests a menu based on the occasion.\n",
        "    Args:\n",
        "        occasion: The type of occasion for the party.\n",
        "    \"\"\"\n",
        "    if occasion == \"casual\":\n",
        "        return \"Pizza, snacks, and drinks.\"\n",
        "    elif occasion == \"formal\":\n",
        "        return \"3-course dinner with wine and dessert.\"\n",
        "    elif occasion == \"superhero\":\n",
        "        return \"Buffet with high-energy and healthy food.\"\n",
        "    else:\n",
        "        return \"Custom menu for the butler.\"\n",
        "\n",
        "@tool\n",
        "def catering_service_tool(query: str) -> str:\n",
        "    \"\"\"\n",
        "    This tool returns the highest-rated catering service in Gotham City.\n",
        "\n",
        "    Args:\n",
        "        query: A search term for finding catering services.\n",
        "    \"\"\"\n",
        "    # Example list of catering services and their ratings\n",
        "    services = {\n",
        "        \"Gotham Catering Co.\": 4.9,\n",
        "        \"Wayne Manor Catering\": 4.8,\n",
        "        \"Gotham City Events\": 4.7,\n",
        "    }\n",
        "\n",
        "    # Find the highest rated catering service (simulating search query filtering)\n",
        "    best_service = max(services, key=services.get)\n",
        "\n",
        "    return best_service\n",
        "\n",
        "\n",
        "class SuperheroPartyThemeTool(Tool):\n",
        "    name = \"superhero_party_theme_generator\"\n",
        "    description = \"\"\"\n",
        "    This tool suggests creative superhero-themed party ideas based on a category.\n",
        "    It returns a unique party theme idea.\"\"\"\n",
        "\n",
        "    inputs = {\n",
        "        \"category\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The type of superhero party (e.g., 'classic heroes', 'villain masquerade', 'futuristic Gotham').\",\n",
        "        }\n",
        "    }\n",
        "\n",
        "    output_type = \"string\"\n",
        "\n",
        "    def forward(self, category: str):\n",
        "        themes = {\n",
        "            \"classic heroes\": \"Justice League Gala: Guests come dressed as their favorite DC heroes with themed cocktails like 'The Kryptonite Punch'.\",\n",
        "            \"villain masquerade\": \"Gotham Rogues' Ball: A mysterious masquerade where guests dress as classic Batman villains.\",\n",
        "            \"futuristic Gotham\": \"Neo-Gotham Night: A cyberpunk-style party inspired by Batman Beyond, with neon decorations and futuristic gadgets.\"\n",
        "        }\n",
        "\n",
        "        return themes.get(category.lower(), \"Themed party idea not found. Try 'classic heroes', 'villain masquerade', or 'futuristic Gotham'.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "7-jtxuSsC95-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = CodeAgent(\n",
        "    model=InferenceClientModel(),\n",
        "    tools=[\n",
        "        DuckDuckGoSearchTool(),\n",
        "        VisitWebpageTool(),\n",
        "        suggest_menu,\n",
        "        catering_service_tool,\n",
        "        SuperheroPartyThemeTool(),\n",
        "        FinalAnswerTool()\n",
        "    ],\n",
        "    max_steps=10,\n",
        "    verbosity_level=2\n",
        ")"
      ],
      "metadata": {
        "id": "sumXGdlmDBe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\n",
        "    \"Give me the best playlist for a party at the Wayne's mansion. The party idea is a 'villain masquerade' theme\"\n",
        ")"
      ],
      "metadata": {
        "id": "Hp7SugfsDYLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inspecting our party preparator agent with OpenTelemetry and Langfuse"
      ],
      "metadata": {
        "id": "e1Z4pJfpDdi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-smolagents"
      ],
      "metadata": {
        "id": "cfLZBXGQDjkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the Party Preparator Agent is fine-tuned, this is difficult to inspect. We need robust traceability for future monitoring and analysis.\n",
        "\n",
        "`smolagents` embraces the [OpenTelemetry](https://opentelemetry.io/) standard for instrumenting agent runs, allowing seamless inspection and logging. With the help of [Langfuse](https://langfuse.com/) and the `SmolagentsInstrumentor`.\n",
        "\n",
        "Make sure to set up API keys in Langfuse."
      ],
      "metadata": {
        "id": "4Ndgzu61DkWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "from google.colab import userdata\n",
        "\n",
        "LANGFUSE_PUBLIC_KEY = userdata.get('LANGFUSE_PUBLIC_KEY')\n",
        "LANGFUSE_SECRET_KEY = userdata.get('LANGFUSE_SECRET_KEY')\n",
        "LANGFUSE_AUTH = base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
        "\n",
        "#os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://cloud.langfuse.com/api/public/otel\" # EU data region\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://us.cloud.langfuse.com/api/public/otel\" # US data region\n",
        "\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\""
      ],
      "metadata": {
        "id": "5LIQY7l2EnJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will initialize the `SmolagentsInstrumentor` and start tracking the agent's performance."
      ],
      "metadata": {
        "id": "-QZiyD0cFQx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from opentelemetry.sdk.trace import TracerProvider\n",
        "\n",
        "from openinference.instrumentation.smolagents import SmolagentsInstrumentor\n",
        "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
        "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
        "\n",
        "trace_provider = TracerProvider()\n",
        "trace_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))\n",
        "\n",
        "SmolagentsInstrumentor().instrument(tracer_provider=trace_provider)"
      ],
      "metadata": {
        "id": "9y61vTqhFWkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The agent is now connected and the runs from `smolagents` are being logged in Langfuse, giving full visibility into the agent's behavior."
      ],
      "metadata": {
        "id": "Wo3ptj4fFwb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import CodeAgent, InferenceClientModel\n",
        "\n",
        "agent = CodeAgent(\n",
        "    model=InferenceClientModel(),\n",
        "    tools=[],\n",
        ")"
      ],
      "metadata": {
        "id": "ymaM13LTF_aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alfred_agent = agent.from_hub('sergiopaniego/AlfredAgent', trust_remote_code=True)\n",
        "alfred_agent.run(\"Give me the best playlist for a party at Wayne's mansion. The party idea is a 'villain masquerade' theme\")"
      ],
      "metadata": {
        "id": "41x5jKFmGFQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can check the trace in Langfuse cloud."
      ],
      "metadata": {
        "id": "tEjkGKuqGYLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Writing Actions as Code Snippets or JSON Blobs"
      ],
      "metadata": {
        "id": "D3QqOSnTGdKN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tool Calling Agents are the second type of agent available in `smolagents`.\n",
        "\n",
        "Unlike Code Agents that use Python snippets, these agents **use the built-in tool-calling capabilities of LLM providers** to generate tool calls as **JSON structures**. This is the standard approach used by OpenAI, Anthropic, and many other providers.\n",
        "\n",
        "Suppose that we want to search for catering services and party ideas, a `CodeAgent` would generate and run Python code:\n",
        "\n",
        "```python\n",
        "for query in [\n",
        "    \"Best catering services in Gotham City\",\n",
        "    \"Party theme ideas for superheroes\"\n",
        "]:\n",
        "    print(web_search(f\"Search for: {query}\"))\n",
        "```\n",
        "\n",
        "A `ToolCallingAgent` would instead create a JSON structure:\n",
        "```json\n",
        "[\n",
        "    {\"name\": \"web_search\", \"arguments\": \"Best catering services in Gotham City\"},\n",
        "    {\"name\": \"web_search\", \"arguments\": \"Party theme ideas for superheroes\"}\n",
        "]\n",
        "```\n",
        "This JSON blob is then used to execute the tool calls.\n",
        "\n",
        "\n",
        "Tool Calling Agents follow the same multi-step workflow as Code Agents. The key difference is in **how they structure their actions**: instead of executable code, they **generate JSON objects that specify tool names and arguments**. The system then **parses these instructions** to execute the appropriate tools."
      ],
      "metadata": {
        "id": "4oCXLz6AI6I2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example"
      ],
      "metadata": {
        "id": "rUfK0RKMK70K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the party preparations, instead of using `CodeAgent`, we will use `ToolCallingAgent`:"
      ],
      "metadata": {
        "id": "BQNRIzFhLAcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import ToolCallingAgent, DuckDuckGoSearchTool, InferenceClientModel\n",
        "\n",
        "agent = ToolCallingAgent(\n",
        "    model=InferenceClientModel(),\n",
        "    tools=[DuckDuckGoSearchTool()]\n",
        ")"
      ],
      "metadata": {
        "id": "7_E8bDKWGk3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\n",
        "    \"Search for the best music recommendations for a party at the Wayne's mansion.\"\n",
        ")"
      ],
      "metadata": {
        "id": "HSRTJ68JLQKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The agent generates a structured tool call that the system processes to produce the output, rather than directly executing code like a `CodeAgent`."
      ],
      "metadata": {
        "id": "uVfHSlVnLUEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tools"
      ],
      "metadata": {
        "id": "j-Y6wQObLYyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In `smolagents`, tools are treated as **functions that an LLM can call within an agent system**.\n",
        "\n",
        "To interact with a tool, the LLM needs an **interface description** with\n",
        "- **Name** - what the tool is called\n",
        "- **Tool description** - what the tool does\n",
        "- **Input types and descriptions** - what arguments the tool accepts\n",
        "- **Output type** - what the tool returns\n",
        "\n",
        "For example, a simple search tool interface may have\n",
        "- **Name** - `web_search`\n",
        "- **Tool description** - Searches the web for specific queries\n",
        "- **Input**- `query (string): the search term to look up`\n",
        "- **Output** - string containing the search results"
      ],
      "metadata": {
        "id": "6lcq4jvhLa4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool Creation Methods\n",
        "\n",
        "In `smolagents`, tools can be defined in two ways:\n",
        "- Using the `@tool` decorator for simple function-based tools\n",
        "- Creating a subclass of `Tool` for more complex functionality"
      ],
      "metadata": {
        "id": "rTh6zd4Y-6Uu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The `@tool` decorator"
      ],
      "metadata": {
        "id": "mQ3kpORb_IAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the `@tool` decorator, `smolagents` will parse basic information about the function from Python. Using this approach, we define a function with\n",
        "- **a clear and descriptive function name** that helps the LLM understand its purpose.\n",
        "- **Type hints for both inputs and outputs** to ensure proper usage.\n",
        "- **A detailed description**, including `Args:` section where each argument is explicitly described. These description provide valuable context for the LLM."
      ],
      "metadata": {
        "id": "GD2DqMOW_Osg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use `@tool` decorator to implement a tool to search for the best catering services for a large number of guests."
      ],
      "metadata": {
        "id": "QY0__HXh_rU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import CodeAgent, InferenceClientModel, tool\n",
        "\n",
        "# Assume that we have a function that fetches the highest-rated catering services\n",
        "@tool\n",
        "def catering_service_tool(query: str) -> str:\n",
        "    \"\"\"This tool returns the highest-rated catering service in Gotham City.\n",
        "\n",
        "    Args:\n",
        "        query: A search term for finding catering services.\n",
        "    \"\"\"\n",
        "\n",
        "    # Example list of catering services and their ratings\n",
        "    services = {\n",
        "        \"Gotham Catering Co.\": 4.9,\n",
        "        \"Wayne Manor Catering\": 4.8,\n",
        "        \"Gotham City Events\": 4.7\n",
        "    }\n",
        "\n",
        "    # Find the highest rated catering service (simulating search query filtering)\n",
        "    best_service = max(services, key=services.get)\n",
        "\n",
        "    return best_service"
      ],
      "metadata": {
        "id": "h0VDEHnZLZzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = CodeAgent(\n",
        "    model=InferenceClientModel(),\n",
        "    tools=[catering_service_tool]\n",
        ")"
      ],
      "metadata": {
        "id": "TdswD2Ttbti2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the agent to find the best catering service\n",
        "result = agent.run(\n",
        "    \"Can you give me the name of the highest-rated catering service in Gotham City?\"\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "_DnuPEGtbwf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `Tool` class"
      ],
      "metadata": {
        "id": "oLLAoUTMb3_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For complex tool, we can implement a class instead of a Python function. The class wraps the function with metadata that helps the LLM understand how to use it effectively.\n",
        "\n",
        "In this class, we define\n",
        "- `name` - the tool's name\n",
        "- `description` - a description used to populate the agent's system prompt\n",
        "- `inputs` - a dictionary with keys `type` and `description`, providing information to help the Python interpreter process inputs\n",
        "- `output_type` - specifying the expected output type\n",
        "- `forward` - the method containing the inference logic to execute\n",
        "\n",
        "\n",
        "As an example, we will implement an agent that generates superhero-themed party ideas based on a given category."
      ],
      "metadata": {
        "id": "WBWlJgkLb-Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import Tool, CodeAgent, InferenceClientModel\n",
        "\n",
        "\n",
        "class SuperheroPartyThemeTool(Tool):\n",
        "    name = \"superhero_party_theme_generator\"\n",
        "    description = \"\"\"\n",
        "    This tool suggests creative superhero-themed party ideas based on a category.\n",
        "    It returns a unique party theme idea.\"\"\"\n",
        "\n",
        "    inputs = {\n",
        "        \"category\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The type of superhero party (e.g., 'classic heroes', 'villain masquerade', 'futuristic Gotham').\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    output_type = \"string\"\n",
        "\n",
        "    def forward(self, category: str):\n",
        "        themes = {\n",
        "            \"classic heroes\": \"Justice League Gala: Guests come dressed as their favorite DC heroes with themed cocktails like 'The Kryptonite Punch'.\",\n",
        "            \"villain masquerade\": \"Gotham Rogues' Ball: A mysterious masquerade where guests dress as classic Batman villains.\",\n",
        "            \"futuristic Gotham\": \"Neo-Gotham Night: A cyberpunk-style party inspired by Batman Beyond, with neon decorations and futuristic gadgets.\"\n",
        "        }\n",
        "\n",
        "        return themes.get(category.lower(), \"Themed party idea not found. Try 'classic heroes', 'villain masquerade', or 'futuristic Gotham'.\")"
      ],
      "metadata": {
        "id": "AnROlFkab8vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the tool\n",
        "party_theme_tool = SuperheroPartyThemeTool()\n",
        "\n",
        "agent = CodeAgent(\n",
        "    model=InferenceClientModel(),\n",
        "    tools=[party_theme_tool]\n",
        ")"
      ],
      "metadata": {
        "id": "VwMHeouCeWv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent.run(\n",
        "    \"What would be a good superhero party idea for a 'villain masquerade' theme?\"\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "59s04JfAechS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Default Toolbox"
      ],
      "metadata": {
        "id": "dET93BDQehWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`smolagents` comes with a set of pre-built tools that can be directly injected into our agent. The default toolbox includes\n",
        "- `PythonInterpreterTool`\n",
        "- `FinalAnswerTool`\n",
        "- `UserInputTool`\n",
        "- `DuckDuckGoSearchTool`\n",
        "- `GoogleSearchTool`\n",
        "- `VisitWebpageTool`"
      ],
      "metadata": {
        "id": "bcgy8hbSekgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sharing and Import Tools"
      ],
      "metadata": {
        "id": "9bTiELCQfBD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sharing a Tool to the Hub\n",
        "\n",
        "Sharing a custom tool with the community,"
      ],
      "metadata": {
        "id": "tPu9XDKHfFDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "party_theme_tool.push_to_hub(\"{your_username}/party_theme_tool\", token=\"<YOUR_HUGGINGFACEHUB_API_TOKEN>\")"
      ],
      "metadata": {
        "id": "B94EolxcekEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing a Tool from the Hub\n",
        "\n",
        "We can import tools created by other users using the `load_tool()` function."
      ],
      "metadata": {
        "id": "RH-6If4ifVyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import load_tool, CodeAgent, InferenceClientModel\n",
        "\n",
        "image_generation_tool = load_tool(\n",
        "    'm-ric/text-to-image',\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "agent = CodeAgent(\n",
        "    model=InferenceClientModel(),\n",
        "    tools=[image_generation_tool]\n",
        ")"
      ],
      "metadata": {
        "id": "-LJr24IzfZw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\n",
        "    \"Generate an image of a luxurious superhero-themed party at Wayne Manor with made-up superheros.\"\n",
        ")"
      ],
      "metadata": {
        "id": "k0YI6ROQfwFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing a HuggingFace Space as a Tool\n",
        "\n",
        "We can also import a HF Space as a tool using `Tool.from_space()`. The tool will connect with the spaces Gradio backend using the `gradio_client`."
      ],
      "metadata": {
        "id": "Qaxh7tFLfzcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import Tool, CodeAgent, InferenceClientModel\n",
        "\n",
        "image_generation_tool = Tool.from_space(\n",
        "    'black-forest-labs/FLUX.1-schnell',\n",
        "    name='image_generator',\n",
        "    description=\"Generate an image from a prompt\"\n",
        ")\n",
        "\n",
        "model = InferenceClientModel(\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
        "\n",
        "agent = CodeAgent(\n",
        "    model=model,\n",
        "    tools=[image_generation_tool]\n",
        ")"
      ],
      "metadata": {
        "id": "Ts_-xDDjf8cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\n",
        "    \"Improve this prompt, then generate an image of it.\"\n",
        "    additional_args={\n",
        "        \"user_prompt\": \"A grand superhero-themed party at Wayne Manor, with Alfred overseeing a luxurious gala.\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "BfdUhDQagRZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing a LangChain Tool\n",
        "\n",
        "We can load LangChain tools using the `Tool.from_langchain()` method"
      ],
      "metadata": {
        "id": "hK-bU43Hgjbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from smolagents import CodeAgent, InferenceClientModel, Tool\n",
        "\n",
        "search_tool = Tool.from_langchain(\n",
        "    load_tools(['serpapi'][0])\n",
        ")\n",
        "\n",
        "model = InferenceClientModel(\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
        "\n",
        "agent = CodeAgent(\n",
        "    model=model,\n",
        "    tools=[search_tool]\n",
        ")"
      ],
      "metadata": {
        "id": "_L3NQwqAjAI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\n",
        "    \"Search for luxury entertainment ideas for a superhero-themed event, such as live performances and interactive experiences.\"\n",
        ")"
      ],
      "metadata": {
        "id": "ZfvpjRsxjSWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing a tool collection from any MCP server\n",
        "\n",
        "`smolagents` also allows importing tools from the MCP servers available on [glama.ai](https://glama.ai/mcp/servers) and [smithery.ai](https://smithery.ai/).\n",
        "\n",
        "We first need to install the `mcp` integration for `smolagents`."
      ],
      "metadata": {
        "id": "xoQH5y7HjUTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU smolagents[mcp]"
      ],
      "metadata": {
        "id": "28Yo9sCmjpKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from smolagents import ToolCollection, CodeAgent, InferenceClientModel\n",
        "from mcp import StdioServerParameters\n",
        "\n",
        "model = InferenceClientModel(\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
        "\n",
        "# set up mcp server\n",
        "server_parameters = StdioServerParameters(\n",
        "    command='uvx',\n",
        "    args=['--quiet', 'pubmedmcp@0.1.3'],\n",
        "    env={\"UV_PYTHON\": \"3.12\", **os.environ}\n",
        ")"
      ],
      "metadata": {
        "id": "oFcF7Hthjr2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with ToolCollection.from_mcp(server_parameters, trust_remote_code=True) as tool_collection:\n",
        "    agent = CodeAgent(\n",
        "        model=model,\n",
        "        tools=[*tool_collection.tools],\n",
        "        add_base_tools=True\n",
        "    )\n",
        "\n",
        "    agent.run(\"Please find a remedy for hangover.\")"
      ],
      "metadata": {
        "id": "RZ-lmwoPkE81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieval Agents"
      ],
      "metadata": {
        "id": "2mJShUe6kVuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieval Augmented Generation (RAG) systems combine the capabilities of data retrieval and generation models to provide context-aware responses. Agentic RAG extends traditional RAG systems by **combining autonomous agents with dynamic knowledge retrieval**.\n",
        "\n",
        "While traditional RAG systems use an LLM to answer queries based on retrieved data, **agentic RAG enables intelligent control of both retrieval and generation processes**, improving efficiency and accuracy.\n",
        "\n",
        "Traditional RAG systems face key limitations, such as relying on a single retrieval step and focusing on direct semantic similarity with the user query. **Agentic RAG address these issues by allowing the agent to autonomously formulate search queries, critique retrieved results, and conduct multiple retrieval steps for a more tailored and comprehensive output."
      ],
      "metadata": {
        "id": "swVaqAlTkZJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Retrieval with DuckDuckGo"
      ],
      "metadata": {
        "id": "ALymZ544md9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will implement an agent to retrieve information and sythesize responses to answer queries. With Agentic RAG, the agent can\n",
        "- Search for latest information\n",
        "- Refine results to include more keywords\n",
        "- Synthesize information into a complete answer"
      ],
      "metadata": {
        "id": "PrlWPpeAmhsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import CodeAgent, DuckDuckGoSearchTool, InferenceClientModel\n",
        "\n",
        "# Initialize a search tool\n",
        "search_tool = DuckDuckGoSearchTool()\n",
        "\n",
        "# Initialize the model\n",
        "model = InferenceClientModel()\n",
        "\n",
        "agent = CodeAgent(\n",
        "    model=model,\n",
        "    tools=[search_tool]\n",
        ")"
      ],
      "metadata": {
        "id": "QRyNks4wkYn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.run(\n",
        "    \"Search for luxury superhero-themed party ideas, including decorations, entertainment, and catering.\"\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "PXmSr1AxnCVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The agent will\n",
        "- **Analyze the request** - identify the key elements of the query\n",
        "- **Perform retrieval** - leverage DuckDuckGo to search for the most relevant and up-to-date information, ensuring it aligns with the user query\n",
        "- **Synthesizes information** - after gathering the results, process them into a cohesive, actionable response\n",
        "- **Store for future reference** - store the retrieved information for easy access"
      ],
      "metadata": {
        "id": "8w2_gfiLnEhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Knowledge Base Tool"
      ],
      "metadata": {
        "id": "WS_Xqtk6nvUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A vector database stores numerical representation (embeddings) of text or other data, created by ML models. It enables semantic search by identifying similar meanings in high-dimensional space.\n",
        "\n",
        "We will create a tool that retrieves relevant information from a custom knowledge base. We will use a BM25 retriever to search the knowledge base and return the top results, and a `RecursiveCharacterTextSplitter` to split the documents into smaller chunks for more efficient search."
      ],
      "metadata": {
        "id": "zo0_E4-an0gP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "from smolagents import Tool, CodeAgent, InferenceClientModel\n",
        "\n",
        "\n",
        "class PartyPlanningRetrieverTool(Tool):\n",
        "    name: \"party_planning_retriever\"\n",
        "    description = \"Uses semantic search to retrieve relevant party planning ideas for Alfredâ€™s superhero-themed party at Wayne Manor.\"\n",
        "    inputs = {\n",
        "        \"query\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The query to perform. This should be a query related to party planning or superhero themes.\",\n",
        "        }\n",
        "    }\n",
        "    output_types = \"string\"\n",
        "\n",
        "    def __init__(self, docs, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.retriever = BM25Retriever.from_documents(\n",
        "            docs,\n",
        "            k=5, # retrieve the top 5 documents\n",
        "        )\n",
        "\n",
        "    def forward(self, query: str) -> str:\n",
        "        assert isinstance(query, str), \"Your search query must be a string\"\n",
        "\n",
        "        docs = self.retriever.invoke(query)\n",
        "\n",
        "        return \"\\nRetrieved ideas:\\n\" + \"\".join(\n",
        "            [\n",
        "                f\"\\n\\n===== Idea {str(i)} =====\\n\" + doc.page_content\n",
        "                for i, doc in enumerate(docs)\n",
        "            ]\n",
        "        )"
      ],
      "metadata": {
        "id": "ahXGyrD9nusf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate a knowledge base about party planning\n",
        "party_ideas = [\n",
        "    {\"text\": \"A superhero-themed masquerade ball with luxury decor, including gold accents and velvet curtains.\", \"source\": \"Party Ideas 1\"},\n",
        "    {\"text\": \"Hire a professional DJ who can play themed music for superheroes like Batman and Wonder Woman.\", \"source\": \"Entertainment Ideas\"},\n",
        "    {\"text\": \"For catering, serve dishes named after superheroes, like 'The Hulk's Green Smoothie' and 'Iron Man's Power Steak.'\", \"source\": \"Catering Ideas\"},\n",
        "    {\"text\": \"Decorate with iconic superhero logos and projections of Gotham and other superhero cities around the venue.\", \"source\": \"Decoration Ideas\"},\n",
        "    {\"text\": \"Interactive experiences with VR where guests can engage in superhero simulations or compete in themed games.\", \"source\": \"Entertainment Ideas\"}\n",
        "]\n",
        "\n",
        "source_docs = [\n",
        "    Document(page_content=doc['text'], metadata={'source': doc['source']})\n",
        "    for doc in party_ideas\n",
        "]\n",
        "\n",
        "# Split the documents into smaller chunks for more efficient search\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50,\n",
        "    add_start_index=True,\n",
        "    strip_whitespace=True,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
        ")\n",
        "docs_processed = text_splitter.split_documents(source_docs)\n",
        "\n",
        "# Create the retriever tool\n",
        "party_planning_retriever = PartyPlanningRetrieverTool(docs=docs_processed)"
      ],
      "metadata": {
        "id": "cBqloxVrpWjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = CodeAgent(\n",
        "    model=InferenceClientModel(),\n",
        "    tools=[party_planning_retriever]\n",
        ")"
      ],
      "metadata": {
        "id": "aJPqo-fAp3aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.run(\n",
        "    \"Find ideas for a luxury superhero-themed party, including entertainment, catering, and decoration options.\"\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "uAV0Abi-p5o8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When building agentic RAG systems, the agent can employ sophisticated strategies like\n",
        "- **Query reformulation** - Instead of using the raw user query, the agent can craft optimized search terms that better match the target documents.\n",
        "- **Multi-step retrieval** - The agent can perform multiple searches, using initial results to inform subsequent queries.\n",
        "- **Source integration** - Information can be combined from multiple sources like web search and local documentation.\n",
        "- **Result validation** - Retrieved content can be analyzed for relevance and accuracy before being included in responses.\n",
        "\n",
        "\n",
        "\n",
        "Effective agentic RAG systems require careful consideration of several key aspects. The agent should select between available tools based on the query type and context. Memory systems help maintain conversation history and avoid repetitive retrievals. Having fallback strategies ensures the system can still provide value even when primary retrieval methods fail. Additionally, implementing validation steps helps ensure the accuracy and relevance of retrieved information."
      ],
      "metadata": {
        "id": "OVOh534bp_a-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Agent Systems"
      ],
      "metadata": {
        "id": "wlxjQOZkqzSv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Multi-agent systems* enable **specialized agents to collaborate on complex tasks**, improving modularity, scalability, and robustness. Instead of relying on a single agent, tasks are distributed among agents with distinct capabilities.\n",
        "\n",
        "In `smolagents`, different agents can be combined to generate Python code, call external tools, perform web searches, and more. A typical orchestration might include\n",
        "- a **Manager Agent** for task delegation\n",
        "- a **Code Interpreter Agent** for code execution\n",
        "- a **Web Search Agent** for information retrieval\n",
        "\n",
        "\n",
        "A multi-agent system consists of multiple specialized agents working together under the coordination of an **Orchestrator Agent**. This approach enables complex workflows by distributing tasks among agents with distinct roles."
      ],
      "metadata": {
        "id": "PBhUhyq0tSHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solving a Complex Task with a Multi-aAgent Hierarchy"
      ],
      "metadata": {
        "id": "yqZb0gXhuJw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU smolagents[litellm] plotly geopandas shapely kaleido"
      ],
      "metadata": {
        "id": "EpmsF84wqjCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from typing import Optional, Tuple\n",
        "from smolagents import tool\n",
        "\n",
        "\n",
        "@tool\n",
        "def calculate_cargo_travel_time(\n",
        "        origin_coords: Tuple[float, float],\n",
        "        destination_coords: Tuple[float, float],\n",
        "        cruising_speed_kmh: Optional[float] = 750., # average speed for cargo planes\n",
        ") -> float:\n",
        "    \"\"\"Calculate the travel time for a cargo plane between two points on Earch using great-circle distance.\n",
        "\n",
        "    Args:\n",
        "        origin_coords: Tuple of (latitude, longitude) for the starting point\n",
        "        destination_coords: Tuple of (latitude, longitude) for the destination\n",
        "        cruising_speed_kmh: Optional cruising speed in km/h (defaults to 750 km/h for typical cargo planes)\n",
        "\n",
        "    Returns:\n",
        "        float: The estimated travel time in hours\n",
        "\n",
        "    Example:\n",
        "        >>> # Chicago (41.8781Â° N, 87.6298Â° W) to Sydney (33.8688Â° S, 151.2093Â° E)\n",
        "        >>> result = calculate_cargo_travel_time((41.8781, -87.6298), (-33.8688, 151.2093))\n",
        "    \"\"\"\n",
        "\n",
        "    def to_radians(degrees: float) -> float:\n",
        "        return degrees * (math.pi / 180)\n",
        "\n",
        "    # Extract coordinates\n",
        "    lat1, lon1 = map(to_radians, origin_coords)\n",
        "    lat2, lon2 = map(to_radians, destination_coords)\n",
        "\n",
        "    # Earth's radius in kilometers\n",
        "    EARTH_RADIUS_KM = 6371.\n",
        "\n",
        "    # Calculate great-circle distance using the haversine formula\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "\n",
        "    a = (\n",
        "        math.sin(dlat / 2) ** 2\n",
        "        + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
        "    )\n",
        "    c = 2 * math.asin(math.sqrt(a))\n",
        "    distance = EARTH_RADIUS_KM * c\n",
        "\n",
        "    # Add 10% to account for non-direct routes and air traffic controls\n",
        "    actual_distance = distance * 1.1\n",
        "\n",
        "    # Calculate flight time\n",
        "    # Add 1 hour for takeoff and landing procedures\n",
        "    flight_time = (actual_distance / cruising_speed_kmh) + 1.0\n",
        "\n",
        "    # Format the results\n",
        "    return round(flight_time, 2)\n",
        "\n",
        "\n",
        "# test\n",
        "print(calculate_cargo_travel_time((41.8781, -87.6298), (-33.8688, 151.2093)))"
      ],
      "metadata": {
        "id": "-EHP_Us7udDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the model provider, we will use Together AI. The `GoogleSearchTool` uses the Serper API to search the web, so this requires either having setup ENV variable `SERPER_API_KEY` and passing `provider=\"serper\"`.\n",
        "\n",
        "If we do not have any `SERPER_API_KEY`,  we can use `DuckDuckGoSearchTool` but it has a rate limit."
      ],
      "metadata": {
        "id": "o0UtHWB7vyM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from smolagents import CodeAgent, GoogleSearchTool, VisitWebpageTool, InferenceClientModel\n",
        "\n",
        "model = InferenceClientModel(\n",
        "    model_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
        "    provider='together'\n",
        ")"
      ],
      "metadata": {
        "id": "crcxHbO3wWHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = CodeAgent(\n",
        "    model=model,\n",
        "    tools=[\n",
        "        GoogleSearchTool('serper'),\n",
        "        VisitWebpageTool(),\n",
        "        calculate_cargo_travel_time\n",
        "    ],\n",
        "    additional_authorized_imports=['pandas'],\n",
        "    max_steps=20\n",
        ")"
      ],
      "metadata": {
        "id": "PpRBkOp_wmcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"\"\"Find all Batman filming locations in the world, calculate the time to transfer via cargo plane to here (we're in Gotham, 40.7128Â° N, 74.0060Â° W), and return them to me as a pandas dataframe.\n",
        "Also give me some supercar factories with the same cargo plane transfer time.\"\"\"\n",
        "\n",
        "result = agent.run(task)"
      ],
      "metadata": {
        "id": "ItzuHG9qw0HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "id": "LCLgec9aydCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could improve this by throwing a dedicated planning step and adding more prompting.\n",
        "\n",
        "Planning step allows the agent to think ahead and plan its next steps, which can be useful for more complex tasks."
      ],
      "metadata": {
        "id": "HTT9ZQoYw5h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.planning_interval = 4\n",
        "\n",
        "detailed_report = agent.run(\n",
        "f\"\"\"\n",
        "You're an expert analyst. You make comprehensive reports after visiting many websites.\n",
        "Don't hesitate to search for many queries at once in a for loop.\n",
        "For each data point that you find, visit the source url to confirm numbers.\n",
        "\n",
        "{task}\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "38aLS9HpxFLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(detailed_report)"
      ],
      "metadata": {
        "id": "JAJQipJNyeD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-agent structures allow to separate memories between different sub-tasks:\n",
        "- Each agent is more focused on its core task, thus more performant\n",
        "- Separating memories reduces the count of input tokens at each step, thus reducing latency and cost.\n",
        "\n",
        "We will create a team with a dedicated web search agent, managed by another agent."
      ],
      "metadata": {
        "id": "cXQ7OvP-ymDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Web search agent\n",
        "\n",
        "model = InferenceClientModel(\n",
        "    model_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
        "    provider='together',\n",
        "    max_tokens=8096\n",
        ")\n",
        "\n",
        "web_agent = CodeAgent(\n",
        "    model=model,\n",
        "    tools=[\n",
        "        GoogleSearchTool(provider='serper'),\n",
        "        VisitWebpageTool(),\n",
        "        calculate_cargo_travel_time\n",
        "    ],\n",
        "    name='web_agent',\n",
        "    description='Browses the web to find information',\n",
        "    verbosity_level=0,\n",
        "    max_steps=10\n",
        ")"
      ],
      "metadata": {
        "id": "HoBP8j78y7vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The manager agent should have plotting capabilities to write its final report. Since the manager agent will do the heavy lifting, we will give it a stronger model [`DeepSeek-R1`](https://huggingface.co/deepseek-ai/DeepSeek-R1), and add a `planning_interval`."
      ],
      "metadata": {
        "id": "WmPmlcMjzWbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents.utils import encode_image_base64, make_image_url\n",
        "from smolagents import OpenAIServerModel\n",
        "\n",
        "\n",
        "def check_reasoning_and_plot(final_answer, agent_memory):\n",
        "    multimodal_model = OpenAIServerModel(\n",
        "        'gpt-4o',\n",
        "        max_tokens=8096\n",
        "    )\n",
        "    filepath = \"saved_map.png\"\n",
        "    assert os.path.exists(filepath), \"Make sure to save the plot under saved_map.png!\"\n",
        "\n",
        "    image = Image.open(filepath)\n",
        "    prompt = (\n",
        "        f\"Here is a user-given task and the agent steps: {agent_memory.get_succinct_steps()}. Now here is the plot that was made.\"\n",
        "        \"Please check that the reasoning process and plot are correct: do they correctly answer the given task?\"\n",
        "        \"First list reasons why yes/no, then write your final decision: PASS in caps lock if it is satisfactory, FAIL if it is not.\"\n",
        "        \"Don't be harsh: if the plot mostly solves the task, it should pass.\"\n",
        "        \"To pass, a plot should be made using px.scatter_map and not any other method (scatter_map looks nicer).\"\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            'role', 'user',\n",
        "            'content': [\n",
        "                {\n",
        "                    'type': 'text',\n",
        "                    'text': prompt\n",
        "                },\n",
        "                {\n",
        "                    'type': 'image_url',\n",
        "                    'image_url': {'url': make_image_url(encode_image_base64(image))}\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "    output = multimodal_model(messages).content\n",
        "    print(\"Feedback: \", output)\n",
        "    if 'FAIL' in output:\n",
        "        raise Exception(output)\n",
        "    return True"
      ],
      "metadata": {
        "id": "-iXZ-zhUznND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manager Agent\n",
        "manager_model = InferenceClientModel(\n",
        "    'deepseek-ai/DeepSeek-R1',\n",
        "    provider='together',\n",
        "    max_tokens=8096\n",
        ")\n",
        "\n",
        "manager_agent = CodeAgent(\n",
        "    model=manager_model,\n",
        "    tools=[calculate_cargo_travel_time],\n",
        "    managed_agents=[web_agent],\n",
        "    additional_authrozed_imports=[\n",
        "        'geopandas',\n",
        "        'plotly',\n",
        "        'shapely',\n",
        "        'json',\n",
        "        'pandas',\n",
        "        'numpy'\n",
        "    ],\n",
        "    planning_interval=5,\n",
        "    verbosity_level=2,\n",
        "    final_answer_checks=[check_reasoning_and_plot],\n",
        "    max_steps=15\n",
        ")"
      ],
      "metadata": {
        "id": "Ge4yRAiX01dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can inspect and visualize what this team looks like"
      ],
      "metadata": {
        "id": "oXEKHqjx1p8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "manager_agent.visualize()"
      ],
      "metadata": {
        "id": "ZJoHbVMA1tC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manager_agent.run(\"\"\"\n",
        "Find all Batman filming locations in the world, calculate the time to transfer via cargo plane to here (we're in Gotham, 40.7128Â° N, 74.0060Â° W).\n",
        "Also give me some supercar factories with the same cargo plane transfer time. You need at least 6 points in total.\n",
        "Represent this as spatial map of the world, with the locations represented as scatter points with a color that depends on the travel time, and save it to saved_map.png!\n",
        "\n",
        "Here's an example of how to plot and return a map:\n",
        "import plotly.express as px\n",
        "df = px.data.carshare()\n",
        "fig = px.scatter_map(df, lat=\"centroid_lat\", lon=\"centroid_lon\", text=\"name\", color=\"peak_hour\", size=100,\n",
        "     color_continuous_scale=px.colors.sequential.Magma, size_max=15, zoom=1)\n",
        "fig.show()\n",
        "fig.write_image(\"saved_image.png\")\n",
        "final_answer(fig)\n",
        "\n",
        "Never try to process strings using code: when you have a string to read, just print it and you'll see it.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "TamaWr101x-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manager_agent.python_executor.state[\"fig\"]"
      ],
      "metadata": {
        "id": "bNXCmdcB11bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vision and Browser Agents"
      ],
      "metadata": {
        "id": "BlzbG25U14cg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empowering agents with visual capabilities is crucial for solving tasks that go beyond text processing.\n",
        "\n",
        "`smolagents` provides built-in support for Vision-Language Models (VLMs), enabling agents to process and interpret images effectively.\n",
        "\n",
        "In this approach, images are passed to the agent at the start and stored as `task_images` alongside the task prompt. The agent then processes these images throughout its execution."
      ],
      "metadata": {
        "id": "P92hsU3n17yS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "image_urls = [\n",
        "    \"https://upload.wikimedia.org/wikipedia/commons/e/e8/The_Joker_at_Wax_Museum_Plus.jpg\", # Joker image\n",
        "    \"https://upload.wikimedia.org/wikipedia/en/9/98/Joker_%28DC_Comics_character%29.jpg\" # Joker image\n",
        "]\n",
        "\n",
        "images = []\n",
        "for url in image_urls:\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "    image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "    images.append(image)"
      ],
      "metadata": {
        "id": "35zQTPqz17Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the images, the agent will process the user query with images."
      ],
      "metadata": {
        "id": "dQv1bNcQ3xiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import CodeAgent, OpenAIServerModel\n",
        "\n",
        "model = OpenAIServerModel('gpt-4o')\n",
        "\n",
        "agent = CodeAgent(\n",
        "    model=model,\n",
        "    tools=[],\n",
        "    max_steps=20,\n",
        "    verbosity_level=2\n",
        ")"
      ],
      "metadata": {
        "id": "dSwzxCPm32o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.run(\n",
        "    \"\"\"\n",
        "    Describe the costume and makeup that the comic character in these photos is wearing and return the description.\n",
        "    Tell me if the guest is The Joker or Wonder Woman.\n",
        "    \"\"\",\n",
        "    images=images\n",
        ")"
      ],
      "metadata": {
        "id": "tZVtW-RY4AUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "V58Rh56r4B1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Providing Images with Dynamic Retrieval"
      ],
      "metadata": {
        "id": "2kLpfCkB4EgR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this approach, images are dynamically added to the agent's memory during execution. Agents in `smolagents` are based on the `MultiStepAgent` class, which is an abstraction of the ReAct framework. This class operates in a structured cycle where various variables and knowledge are logged at different stages:\n",
        "- **SystemPromptStep** - stores the system prompt\n",
        "- **TaskStep** - logs the user query and any provided input\n",
        "- **ActionStep** - captures logs from the agent's actions and results\n",
        "\n",
        "This structured approach allows agents to incorporate visual information dynamically and respond adaptively to evolving tasks. When browsing the webpage, the agent can take screenshots and save them as `observation_images` in the `ActionStep`."
      ],
      "metadata": {
        "id": "oSjC72nM4MC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU smolagents[all] helium selenium python-dotenv"
      ],
      "metadata": {
        "id": "C--vfocU4H59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will need a set of agent tools specifically designed for browsing, such as `search_item_ctrl_f`, `go_back`, and `close_popups` to act like a person navigating the web."
      ],
      "metadata": {
        "id": "vwmi67N246Nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import helium\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys"
      ],
      "metadata": {
        "id": "j1HYh_sN5siB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_driver():\n",
        "    \"\"\"Initialize the Selenium WebDriver.\"\"\"\n",
        "    chrome_options = webdriver.ChromeOptions()\n",
        "    chrome_options.add_argument(\"--force-device-scale-factor=1\")\n",
        "    chrome_options.add_argument(\"--window-size=1000,1350\")\n",
        "    chrome_options.add_argument(\"--disable-pdf-viewer\")\n",
        "    chrome_options.add_argument(\"--window-position=0,0\")\n",
        "    return helium.start_chrome(headless=False, options=chrome_options)\n",
        "\n",
        "driver = initialize_driver()"
      ],
      "metadata": {
        "id": "r38NvPho5C8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def search_item_ctrl_f(text: str, nth_result: int = 1) -> str:\n",
        "    \"\"\"Searches for text on the current page via Ctrl + F and jumps to the nth occurrence.\n",
        "\n",
        "    Args:\n",
        "        text: The text to search for\n",
        "        nth_result: Which occurrence to jump to (default: 1)\n",
        "    \"\"\"\n",
        "    elements = driver.find_elements(By.XPATH, f\"//*[contains(text(), '{text}')]\")\n",
        "    if nth_result > len(elements):\n",
        "        raise Exception(f\"Match nÂ°{nth_result} not found (only {len(elements)} matches found)\")\n",
        "    result = f\"Found {len(elements)} matches for '{text}'.\"\n",
        "    elem = elements[nth_result - 1]\n",
        "    driver.execute_script(\"arguments[0].scrollIntoView(true);\", elem)\n",
        "    result += f\"Focused on element {nth_result} of {len(elements)}\"\n",
        "    return result\n",
        "\n",
        "@tool\n",
        "def go_back() -> None:\n",
        "    \"\"\"Goes back to previous page.\"\"\"\n",
        "    driver.back()\n",
        "\n",
        "\n",
        "@tool\n",
        "def close_popups() -> str:\n",
        "    \"\"\"\n",
        "    Closes any visible modal or pop-up on the page. Use this to dismiss pop-up windows! This does not work on cookie consent banners.\n",
        "    \"\"\"\n",
        "    webdriver.ActionChains(driver).send_keys(Keys.ESCAPE).perform()"
      ],
      "metadata": {
        "id": "JmLy1flM5jnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also need function to save screenshots, as this will be an essential part of what our VLM agent uses to complete the task."
      ],
      "metadata": {
        "id": "lI67II0m591q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from smolagents import CodeAgent, DuckDuckGoSearchTool, tool\n",
        "from smolagents.agents import ActionStep\n",
        "\n",
        "def save_screenshot(step_log: ActionStep, agent: CodeAgent) -> None:\n",
        "    # Let JavaScript animations happen before taking the screenshot\n",
        "    sleep(1.0)\n",
        "    driver = helium.get_driver()\n",
        "    current_step = step_log.step_number\n",
        "    if driver is not None:\n",
        "        for step_logs in agent.logs:  # Remove previous screenshots from logs for lean processing\n",
        "            if isinstance(step_log, ActionStep) and step_log.step_number <= current_step - 2:\n",
        "                step_logs.observations_images = None\n",
        "        png_bytes = driver.get_screenshot_as_png()\n",
        "        image = Image.open(BytesIO(png_bytes))\n",
        "        print(f\"Captured a browser screenshot: {image.size} pixels\")\n",
        "        step_log.observations_images = [image.copy()]  # Create a copy to ensure it persists, important!\n",
        "\n",
        "    # Update observations with current URL\n",
        "    url_info = f\"Current url: {driver.current_url}\"\n",
        "    step_log.observations = url_info if step_logs.observations is None else step_log.observations + \"\\n\" + url_info\n",
        "    return"
      ],
      "metadata": {
        "id": "aFK14b_m6ERf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function will be passed tothe agent as `step_callback`, as it is triggered at the end of each step during the agent's execution. This allows the agent to dynamically capture and store screenshots throughout its process.\n",
        "\n",
        "Next, we can generate our vision agent for browsing the web, providing it with the tools we created, along with the `DuckDuckGoSearchTool` to explore the web."
      ],
      "metadata": {
        "id": "8jLTiIcf7LsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = OpenAIServerModel('gpt-4o')\n",
        "\n",
        "agent = CodeAgent(\n",
        "    model=model,\n",
        "    tools=[\n",
        "        DuckDuckGoSearchTool(),\n",
        "        go_back,\n",
        "        close_popups,\n",
        "        search_item_ctrl_f\n",
        "    ],\n",
        "    additional_authorized_imports=['helium'],\n",
        "    step_callback=[save_screenshot],\n",
        "    max_steps=20,\n",
        "    verbosity_level=2\n",
        ")"
      ],
      "metadata": {
        "id": "kbCW_AGi7dBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "helium_instructions = \"\"\"\n",
        "Use your web_search tool when you want to get Google search results.\n",
        "Then you can use helium to access websites. Don't use helium for Google search, only for navigating websites!\n",
        "Don't bother about the helium driver, it's already managed.\n",
        "We've already ran \"from helium import *\"\n",
        "Then you can go to pages!\n",
        "Code:\n",
        "```py\n",
        "go_to('github.com/trending')\n",
        "```<end_code>\n",
        "You can directly click clickable elements by inputting the text that appears on them.\n",
        "Code:\n",
        "```py\n",
        "click(\"Top products\")\n",
        "```<end_code>\n",
        "If it's a link:\n",
        "Code:\n",
        "```py\n",
        "click(Link(\"Top products\"))\n",
        "```<end_code>\n",
        "If you try to interact with an element and it's not found, you'll get a LookupError.\n",
        "In general stop your action after each button click to see what happens on your screenshot.\n",
        "Never try to login in a page.\n",
        "To scroll up or down, use scroll_down or scroll_up with as an argument the number of pixels to scroll from.\n",
        "Code:\n",
        "```py\n",
        "scroll_down(num_pixels=1200) # This will scroll one viewport down\n",
        "```<end_code>\n",
        "When you have pop-ups with a cross icon to close, don't try to click the close icon by finding its element or targeting an 'X' element (this most often fails).\n",
        "Just use your built-in tool `close_popups` to close them:\n",
        "Code:\n",
        "```py\n",
        "close_popups()\n",
        "```<end_code>\n",
        "You can use .exists() to check for the existence of an element. For example:\n",
        "Code:\n",
        "```py\n",
        "if Text('Accept cookies?').exists():\n",
        "    click('I accept')\n",
        "```<end_code>\n",
        "Proceed in several steps rather than trying to solve the task in one shot.\n",
        "And at the end, only when you have your answer, return your final answer.\n",
        "Code:\n",
        "```py\n",
        "final_answer(\"YOUR_ANSWER_HERE\")\n",
        "```<end_code>\n",
        "If pages seem stuck on loading, you might have to wait, for instance `import time` and run `time.sleep(5.0)`. But don't overuse this!\n",
        "To list elements on page, DO NOT try code-based element searches like 'contributors = find_all(S(\"ol > li\"))': just look at the latest screenshot you have and read it visually, or use your tool search_item_ctrl_f.\n",
        "Of course, you can act on buttons like a user would do when navigating.\n",
        "After each code blob you write, you will be automatically provided with an updated screenshot of the browser and the current browser url.\n",
        "But beware that the screenshot will only be taken at the end of the whole action, it won't see intermediate states.\n",
        "Don't kill the browser.\n",
        "When you have modals or cookie banners on screen, you should get rid of them before you can click anything else.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jK5LpYZs7vEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent.run(\"\"\"\n",
        "I am Alfred, the butler of Wayne Manor, responsible for verifying the identity of guests at party. A superhero has arrived at the entrance claiming to be Wonder Woman, but I need to confirm if she is who she says she is.\n",
        "\n",
        "Please search for images of Wonder Woman and generate a detailed visual description based on those images. Additionally, navigate to Wikipedia to gather key details about her appearance. With this information, I can determine whether to grant her access to the event.\n",
        "\"\"\" + helium_instructions)"
      ],
      "metadata": {
        "id": "UAnWzrsr7rqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "id": "xW2x9_2V7xKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "All available scripts in this Session are under [HERE](https://huggingface.co/agents-course/notebooks/tree/main/unit2/smolagents)."
      ],
      "metadata": {
        "id": "2e8DCenl8EF9"
      }
    }
  ]
}