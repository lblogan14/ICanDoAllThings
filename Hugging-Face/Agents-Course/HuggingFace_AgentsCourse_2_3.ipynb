{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The LangGraph Framework"
      ],
      "metadata": {
        "id": "oVeRc96pBKiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to LangGraph"
      ],
      "metadata": {
        "id": "URILIAi9BSiC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`LangGraph` is a framework that allows us to build production-ready applications by giving us control tools over the flow of our agents. `LangGraph` is a framework developed by `LangChain` to **manage the control flow of applications that integrate an LLM.**\n",
        "- LangChain provides a standard interface to interact with models and other components, useful for retrieval, LLM calls, and tool calls.\n",
        "\n",
        "`CodeAgent` in `smolagents` are very free. They can call multiple tools in a single action step, create their own tools, etc. However, this behavior can make them less predictable and less controllable than a regular Agent workfing with JSON.\n",
        "\n",
        "`LangGraph` is preferred if we need \"control\" on the execution of our agent.\n",
        "\n",
        "Key benefits from `LangGraph`:\n",
        "- Multi-step reasoning processes that need explicit control on the flow\n",
        "- Applications requiring persistence of state between steps\n",
        "- Systems that combine deterministic logic with AI capabilities\n",
        "- Workflows that need human-in-the-loop interventions\n",
        "- Complex agent architectures with multiple components working together\n",
        "\n",
        "\n",
        "At its core, `LangGraph` uses a directed graph structure to deine the flow of our application\n",
        "- **Nodes** represent individiual processing step (like calling an LLM, using a tool, or making a decision)\n",
        "- **Edges** define the possible transitions between steps\n",
        "- **State** is user-defined and maintained and passed between nodes during execution. When deciding which node to target next, this is the current state that we look at.\n"
      ],
      "metadata": {
        "id": "joEHwD6uBYLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Blocks of LangGraph"
      ],
      "metadata": {
        "id": "A48Z7zKFDZZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### State"
      ],
      "metadata": {
        "id": "HJ7zMjWeDeU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**State** is the central concept in LangGraph. It represents all the information that flows through our application."
      ],
      "metadata": {
        "id": "9LGo5q4ODfk8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7RAUz--BIjd"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "\n",
        "class State(TypedDict):\n",
        "    graph_state: str"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The state is **user-defined**, hence the fields should be carefully crafted to contain all data needed for decision-making process.\n",
        "\n",
        "\n",
        "We need to think carefully about what information our application needs to track between steps."
      ],
      "metadata": {
        "id": "h3Y5eLY7Dq8u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nodes"
      ],
      "metadata": {
        "id": "4K5JFvckD6I4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nodes** are Python functions. Each node\n",
        "- takes the state as input\n",
        "- performs some operation\n",
        "- returns updates to the state"
      ],
      "metadata": {
        "id": "y_Nxrf03D8P-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def node_1(state):\n",
        "    print('---Node 1---')\n",
        "    return {'graph_state': state['graph_state'] + \" I am\"}\n",
        "\n",
        "def node_2(state):\n",
        "    print('---Node 2---')\n",
        "    return {'graph_state': state['graph_state'] + \" happy!\"}\n",
        "\n",
        "def node_3(state):\n",
        "    print('---Node 3---')\n",
        "    return {'graph_state': state['graph_state'] + \" sad!\"}"
      ],
      "metadata": {
        "id": "hyWzMN1fD5jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nodes can contain\n",
        "- LLM calls: generate text or make decisions\n",
        "- tool calls: interact with external systems\n",
        "- conditional logic: determine next steps\n",
        "- human intervention: get input from users"
      ],
      "metadata": {
        "id": "5x6MxFyOERaC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Edges"
      ],
      "metadata": {
        "id": "0ZYYFcSCEeJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Edges** connect nodes and define the possible paths through our graph."
      ],
      "metadata": {
        "id": "cuzR2W9MEf5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from typing import Literal\n",
        "\n",
        "\n",
        "def decide_mood(state) -> Literal[\"node_2\", \"node_3\"]:\n",
        "    # We will use state to decide on the next node to visit\n",
        "    user_input = state['graph_state']\n",
        "\n",
        "    # here, we do a 50/50 split between node 2 and node 3\n",
        "    if random.random() < 0.5:\n",
        "        return \"node_2\"\n",
        "    else:\n",
        "        return \"node_3\""
      ],
      "metadata": {
        "id": "Ws4cKkByEdpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edges can be\n",
        "- direct: always go from node A to node B\n",
        "- conditional: choose the next node based on the current state"
      ],
      "metadata": {
        "id": "Ezt2ceKSE1W9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### StateGraph"
      ],
      "metadata": {
        "id": "ZlvK671lE7Qn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **StateGraph** is the container that holds our entire agent workflow."
      ],
      "metadata": {
        "id": "ZTw01A6lE8tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "\n",
        "# Build graph\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(\"node_1\", node_1)\n",
        "builder.add_node(\"node_2\", node_2)\n",
        "builder.add_node(\"node_3\", node_3)\n",
        "\n",
        "# Logic\n",
        "builder.add_edge(START, \"node_1\")\n",
        "builder.add_conditional_edges('node_1', decide_mood)\n",
        "builder.add_edge(\"node_2\", END)\n",
        "builder.add_edge(\"node_3\", END)\n",
        "\n",
        "# Build graph\n",
        "graph = builder.compile()"
      ],
      "metadata": {
        "id": "Bf-8BTxEE648"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "yt-tS0CiFZzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the graph now:"
      ],
      "metadata": {
        "id": "FTI0L_D6FcFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph.invoke(\n",
        "    {'graph_state': \"Hi, this is Bin.\"}\n",
        ")"
      ],
      "metadata": {
        "id": "Ko4CVG9WFdvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Our First LangGraph"
      ],
      "metadata": {
        "id": "wER103YAFjJN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will implement an email processing agent to\n",
        "- read incoming emails\n",
        "- classify them as spam or legitimate\n",
        "- draft a prelimiary response for legitimate emails\n",
        "- send information to a specific receipent when legitimate"
      ],
      "metadata": {
        "id": "RGE7Q248JiSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langgraph langchain_openai langchain_huggingface"
      ],
      "metadata": {
        "id": "BaVwzWu9Fk5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import TypedDict, List, Dict, Any, Optional\n",
        "import langgraph.graph import StateGraph, START, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "8LNixbWNKBoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the State"
      ],
      "metadata": {
        "id": "K4lquvGCKWYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will define what information the agent needs to track during the email processing workflow:"
      ],
      "metadata": {
        "id": "Di1JL-SpKaJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmailState(TypedDict):\n",
        "    # The email being processed\n",
        "    email: Dict[str, Any] # contains subject, sender, body, etc.\n",
        "\n",
        "    # Category of the email (inquery, complaint, etc.)\n",
        "    email_category: Optional[str]\n",
        "\n",
        "    # Reason why the email was marked as spam\n",
        "    spam_reason: Optional[str]\n",
        "\n",
        "    # Analysis and decisions\n",
        "    is_pam: Optional[bool]\n",
        "\n",
        "    # Response generation\n",
        "    draft_response: Optional[str]\n",
        "\n",
        "    # Processing metadata\n",
        "    messages: List[Dict[str, Any]] # track conversation with LLM for analysis"
      ],
      "metadata": {
        "id": "fkOTEuG2KZhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to make our state comphrehensive enough to track all the important information, but avoid bloating it with unnecessary details."
      ],
      "metadata": {
        "id": "W0uUNUg2LHeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the Nodes"
      ],
      "metadata": {
        "id": "dwPxK9LyLRXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the LLM\n",
        "model = ChatOpenAI(model='gpt-4o', temperature=0)\n",
        "\n",
        "\n",
        "def read_email(state: EmailState):\n",
        "    \"\"\"Read and log the incoming emails\"\"\"\n",
        "    email = state['email']\n",
        "\n",
        "    # we might do some initial processing\n",
        "    print(f\"Agent is processing an email from {email['sender']} with subject: {email['subject']}\")\n",
        "\n",
        "    # No state changes needed here\n",
        "    return {}\n",
        "\n",
        "\n",
        "def classify_email(state: EmailState):\n",
        "    \"\"\"Use an LLM to determine if the email is spam or legitimate\"\"\"\n",
        "    email = state['email']\n",
        "\n",
        "    # Prepare prompt for the LLM\n",
        "    prompt = f\"\"\"\n",
        "    As AI assistant, analyze this email and determine if it is spam or legitimate.\n",
        "\n",
        "    Email:\n",
        "    From: {email['sender']}\n",
        "    Subject: {email['subject']}\n",
        "    Body: {email['body']}\n",
        "\n",
        "    First, determine if this email is spam. If it is spam, explain why.\n",
        "    If it is legitimate, categorize it (inquiry, complaint, thank you, etc.).\"\"\"\n",
        "\n",
        "    # Call the LLM\n",
        "    messages = [HumanMessage(content=prompt)]\n",
        "    response = model.invoke(messages)\n",
        "\n",
        "    # Simple logic to parse the response\n",
        "    response_text = response.content.lower()\n",
        "    is_spam = 'spam' in response_text and 'ham' not in response_text\n",
        "\n",
        "    # Extract a reason if it is spam\n",
        "    spam_reason = None\n",
        "    if is_spam and \"reason:\" in response_text:\n",
        "        spam_reason = response_text.split(\"reason:\")[1].strip()\n",
        "\n",
        "    # Determine category if legitimate\n",
        "    email_category = None\n",
        "    if not is_spam:\n",
        "        categories = ['inquiry', 'complaint', 'thank you', 'request', 'information']\n",
        "        for category in categories:\n",
        "            if category in response_text:\n",
        "                email_category = category\n",
        "                break\n",
        "\n",
        "    # Update messages for tracking\n",
        "    new_messages = state.get('messages', []) + [\n",
        "        {'role': 'user', 'content': prompt},\n",
        "        {'role': 'assistant', 'content': response.content}\n",
        "    ]\n",
        "\n",
        "    # Return state updates\n",
        "    return {\n",
        "        'is_spam': is_spam,\n",
        "        'spam_reason': spam_reason,\n",
        "        'email_category': email_category,\n",
        "        'messages': new_messages\n",
        "    }\n",
        "\n",
        "\n",
        "def handle_spam(state: EmailState):\n",
        "    \"\"\"Discard spam email with a note\"\"\"\n",
        "    print(f\"Agent has marked the email as spam. Reason: {state['spam_reason']}\")\n",
        "    print(\"The email has been moved to the spam folder.\")\n",
        "\n",
        "    return {}\n",
        "\n",
        "\n",
        "def draft_response(state: EmailState):\n",
        "    \"\"\"Draft a preliminary response for legitimate emails\"\"\"\n",
        "    email = state['email']\n",
        "    category = state['email_category'] or \"general\"\n",
        "\n",
        "    # Prepare prompt for the LLM\n",
        "    prompt = f\"\"\"\n",
        "    As AI assistant, draft a polite preliminary response to this email.\n",
        "\n",
        "    Email:\n",
        "    From: {email['sender']}\n",
        "    Subject: {email['subject']}\n",
        "    Body: {email['body']}\n",
        "\n",
        "    This email has been categorized as: {category}\n",
        "\n",
        "    Draft a brief, professional response that Mr. Hugg can review and personalize before sending.\"\"\"\n",
        "\n",
        "    # Call the LLM\n",
        "    messages = [HumanMessage(content=prompt)]\n",
        "    response = model.invoke(messages)\n",
        "\n",
        "    # Update messages for tracking\n",
        "    new_messages = state.get('messages', []) + [\n",
        "        {'role': 'user', 'content': prompt},\n",
        "        {'role': 'assistant', 'content': response.content}\n",
        "    ]\n",
        "\n",
        "    # Return state updates\n",
        "    return {\n",
        "        'draft_response': response.content,\n",
        "        'messages': new_messages\n",
        "    }\n",
        "\n",
        "\n",
        "def notify_mr_wayne(state: EmailState):\n",
        "    \"\"\"Notify Mr. Wayne about the email and presents the draft response\"\"\"\n",
        "    email = state['email']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Sir, you've received an email from {email['sender']}.\")\n",
        "    print(f\"Subject: {email['subject']}\")\n",
        "    print(f\"Category: {state['email_category']}\")\n",
        "    print(\"\\nI've prepared a draft response for your review:\")\n",
        "    print(\"-\"*50)\n",
        "    print(state[\"email_draft\"])\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "    return {}"
      ],
      "metadata": {
        "id": "10J_y38fLQtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Routing Logic"
      ],
      "metadata": {
        "id": "jqooSjpFOylU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need a function to determine which path to take after classification."
      ],
      "metadata": {
        "id": "cd9M_Fv8O0ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def route_email(state: EmailState) -> str:\n",
        "    \"\"\"Determine the next step based on spam classification\"\"\"\n",
        "    if state['is_spam']:\n",
        "        return \"spam\"\n",
        "    else:\n",
        "        return 'legitimate'"
      ],
      "metadata": {
        "id": "2rn-2LkgOz8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This routing function is called by LangGraph to determine which edge to follow after the classification node. The return value must match one of the keys in our conditional edges mapping."
      ],
      "metadata": {
        "id": "moK7PWmfPDKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the StateGraph and Define Edges"
      ],
      "metadata": {
        "id": "6L9xfd-tPLgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the graph\n",
        "email_graph = StateGraph(EmailState)\n",
        "\n",
        "# Add nodes\n",
        "email_graph.add_node('read_email', read_email)\n",
        "email_graph.add_node('classify_email', classify_email)\n",
        "email_graph.add_node('handle_spam', handle_spam)\n",
        "email_graph.add_node('draft_response', draft_response)\n",
        "email_graph.add_node('notify_mr_wayne', notify_mr_wayne)\n",
        "\n",
        "# Start the edge\n",
        "email_graph.add_edge(START, 'read_email')\n",
        "# Add edges - defining the flow\n",
        "email_graph.add_edge('read_email', 'classify_email')\n",
        "# Add conditional branching from `classify_email`\n",
        "email_graph.add_conditional_edges(\n",
        "    'classify_email',\n",
        "    route_email,\n",
        "    {\n",
        "        'spam': 'handle_spam',\n",
        "        'legitimate': 'draft_response'\n",
        "    }\n",
        ")\n",
        "\n",
        "# Add the final edges\n",
        "email_graph.add_edge('handle_spam', END)\n",
        "email_graph.add_edge('draft_response', 'notify_mr_wayne')\n",
        "email_graph.add_edge('notify_mr_wayne', END)\n",
        "\n",
        "# Compile the graph\n",
        "email_graph = email_graph.compile()"
      ],
      "metadata": {
        "id": "hCrUsji4PK2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(compiled_graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "piLGUdqTQAC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the App"
      ],
      "metadata": {
        "id": "Vriq4AhfQCLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example legitimate email\n",
        "legitimate_email = {\n",
        "    \"sender\": \"john.smith@example.com\",\n",
        "    \"subject\": \"Question about your services\",\n",
        "    \"body\": \"Dear Mr. Hugg, I was referred to you by a colleague and I'm interested in learning more about your consulting services. Could we schedule a call next week? Best regards, John Smith\"\n",
        "}\n",
        "\n",
        "# Example spam email\n",
        "spam_email = {\n",
        "    \"sender\": \"winner@lottery-intl.com\",\n",
        "    \"subject\": \"YOU HAVE WON $5,000,000!!!\",\n",
        "    \"body\": \"CONGRATULATIONS! You have been selected as the winner of our international lottery! To claim your $5,000,000 prize, please send us your bank details and a processing fee of $100.\"\n",
        "}\n",
        "\n",
        "# Process the legitimate email\n",
        "print(\"\\nProcessing legitimate email...\")\n",
        "legitimate_result = compiled_graph.invoke({\n",
        "    \"email\": legitimate_email,\n",
        "    \"is_spam\": None,\n",
        "    \"spam_reason\": None,\n",
        "    \"email_category\": None,\n",
        "    \"email_draft\": None,\n",
        "    \"messages\": []\n",
        "})\n",
        "\n",
        "# Process the spam email\n",
        "print(\"\\nProcessing spam email...\")\n",
        "spam_result = compiled_graph.invoke({\n",
        "    \"email\": spam_email,\n",
        "    \"is_spam\": None,\n",
        "    \"spam_reason\": None,\n",
        "    \"email_category\": None,\n",
        "    \"email_draft\": None,\n",
        "    \"messages\": []\n",
        "})"
      ],
      "metadata": {
        "id": "FEZ2UneHQDdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect Agent with Langfuse"
      ],
      "metadata": {
        "id": "vkrWj46eQIPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langfuse langchain"
      ],
      "metadata": {
        "id": "MzOne6_oQTJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = userdata.get('LANGFUSE_PUBLIC_KEY')\n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = userdata.get('LANGFUSE_SECRET_KEY')\n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # ðŸ‡ºðŸ‡¸ US region"
      ],
      "metadata": {
        "id": "3xKUBg1uQL0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse.callback import CallbackHandler\n",
        "\n",
        "# Initialize Langfuse CallbackHandler for LangGraph/Langchain (tracing)\n",
        "langfuse_handler = CallbackHandler()\n",
        "\n",
        "# Process legitimate email\n",
        "legitimate_result = compiled_graph.invoke(\n",
        "    input={\"email\": legitimate_email, \"is_spam\": None, \"spam_reason\": None, \"email_category\": None, \"draft_response\": None, \"messages\": []},\n",
        "    config={\"callbacks\": [langfuse_handler]}\n",
        ")"
      ],
      "metadata": {
        "id": "3dbwxymkQhSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Analysis Graph"
      ],
      "metadata": {
        "id": "tPCpil1mQkpG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will implement a document analysis agent using LangGraph. The agent can\n",
        "- process images document\n",
        "- extract text using vision models\n",
        "- perform calculations when needed\n",
        "- analyze content and provide concise summaries\n",
        "- execute specific instructions related to documents"
      ],
      "metadata": {
        "id": "P74tFVTXQok4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain_openai langchain_core langgraph"
      ],
      "metadata": {
        "id": "u5IyuVByQmm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "xkVFAPIzRA_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from typing import List, TypedDict, Annotated, Optional\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.graph improt START, END, StateGraph\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from IPython.display import Image, display"
      ],
      "metadata": {
        "id": "nXt02twZREpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Agent's State"
      ],
      "metadata": {
        "id": "p_M3mo2JTqQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`AnyMessage` is a class from LangChain taht defines messages, and `add_messages` is an operator that adds the latest message rather than overwriting it with the latest state.\n",
        "\n",
        "In the agent's state, we can add operators in our state to define the way they should interact together."
      ],
      "metadata": {
        "id": "Flm47Qo2TtAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    # The document provided\n",
        "    input_file: Optional[str] # contains file path (PDF/PNG)\n",
        "    messages: Annotated[list[AnyMessage], add_messages]"
      ],
      "metadata": {
        "id": "QD6mkLFUTsR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Tools"
      ],
      "metadata": {
        "id": "_2fpkSbLUMdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vision_llm = ChatOpenAI(model='gpt-4o')\n",
        "\n",
        "\n",
        "def extract_text(img_path: str) -> str:\n",
        "    \"\"\"Extract text from an image file using a multimodal model.\"\"\"\n",
        "    all_text = \"\"\n",
        "    try:\n",
        "        # Read image and encode as base64\n",
        "        with open(img_path, 'rb') as image_file:\n",
        "            image_bytes = image_file.read()\n",
        "\n",
        "        image_base64 = base64.b64encode(image_bytes).decode('utf-8')\n",
        "\n",
        "        # Prepare the prompt including the base64 image data\n",
        "        message = [\n",
        "            HumanMessage(\n",
        "                content=[\n",
        "                    {\n",
        "                        'type': 'text',\n",
        "                        'text': \"Extract all the text from this image. Return only the extracted text, no explanations.\"\n",
        "                    },\n",
        "                    {\n",
        "                        'type': 'image_url':\n",
        "                        'image_url': {'url': f'data:image/png;base64,{image_base64}'}\n",
        "                    }\n",
        "                ]\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Call the vision-capable model\n",
        "        response = vision_llm.invoke(message)\n",
        "\n",
        "        # Append extracted text\n",
        "        all_text += response.content + '\\n\\n'\n",
        "\n",
        "        return all_text.strip()\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error extracting text: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "ckNIOdMoUOdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model='gpt-4o')\n",
        "\n",
        "def divide(a: int, b: int) -> float:\n",
        "    \"\"\"Divide a and b\"\"\"\n",
        "    return a / b"
      ],
      "metadata": {
        "id": "vVwU6iY4VR7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Equip tools\n",
        "tools = [\n",
        "    divide,\n",
        "    extract_text\n",
        "]\n",
        "\n",
        "llm_with_tools = llm.bind_tools(\n",
        "    tools,\n",
        "    parallel_tool_calls=False\n",
        ")"
      ],
      "metadata": {
        "id": "rz5f1IxiVaYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Nodes"
      ],
      "metadata": {
        "id": "pAmKJHeMVidW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assistant(state: AgentState):\n",
        "    # System message\n",
        "    textual_description_of_tool = \"\"\"\n",
        "    extract_text(img_path: str) -> str:\n",
        "        Extract text from an image file using a multimodal model.\n",
        "\n",
        "        Args:\n",
        "            img_path: A local image file path (strings).\n",
        "\n",
        "        Returns:\n",
        "            A single string containing the concatenated text extracted from each image.\n",
        "    divide(a: int, b: int) -> float:\n",
        "        Divide a and b\"\"\"\n",
        "\n",
        "    image = state['input_file']\n",
        "    sys_msg = SystemMessage(\n",
        "        content=f\"\"\"You are a helpful butler named Alfred that serves Mr. Wayne and Batman.\n",
        "        You can analyse documents and run computations with provided tools:\\n{textual_description_of_tool} \\n\n",
        "        You have access to some optional images. Currently the loaded image is: {image}\"\"\"\n",
        "    )\n",
        "\n",
        "    response = llm_with_tools.invoke([sys_msg] + state['messages'])\n",
        "\n",
        "    return {\n",
        "        'messages': [response],\n",
        "        'input_file': state['input_file']\n",
        "    }"
      ],
      "metadata": {
        "id": "MAKKZsrdVjrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### the ReAct Pattern"
      ],
      "metadata": {
        "id": "pCF0Q0EfXEpW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The agent follows the ReAct pattern (Reason-Act-Observe)\n",
        "- **Reason** about the documents and requests\n",
        "- **Act** by using appropriate tools\n",
        "- **Observe** the results\n",
        "- **Repeat** as necessary until the task is completed"
      ],
      "metadata": {
        "id": "Trv_uu97XHx-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0vIpBEawXde0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The graph\n",
        "builder = StateGraph(AgentState)\n",
        "\n",
        "# Define nodes\n",
        "builder.add_node('assistant', assistant)\n",
        "builder.add_node('tools', ToolNode(tools)) # tool node\n",
        "\n",
        "# Define edges\n",
        "builder.add_edge(START, 'assistant')\n",
        "builder.add_conditional_edges(\n",
        "    'assistant',\n",
        "    # If the latest message requires a tool, route to tools\n",
        "    # Otherwise, provide a direct response\n",
        "    tools_condition\n",
        ")\n",
        "\n",
        "builder.add_edge('tools', 'assistant')\n",
        "react_graph = builder.compile()\n",
        "\n",
        "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "K5tHpUehXHCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a `tools` node with our list of tools. The `assistant` node is just our model with bound tools. We create a graph with `assistant` and `tools` nodes.\n",
        "\n",
        "We also add `tools_condition` edge, which routes to `END` or to `tools` based on whether the `assistant` calls a tool."
      ],
      "metadata": {
        "id": "N34JOjZ9Yazb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "9QEe6FMuY12k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"Divide 6790 by 5\")]\n",
        "messages = react_graph.invoke({\"messages\": messages, \"input_file\": None})\n",
        "\n",
        "# Show the messages\n",
        "for m in messages['messages']:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "id": "VXQC02WdY3IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"According to the note provided by Mr. Wayne in the provided images. What's the list of items I should buy for the dinner menu?\")]\n",
        "messages = react_graph.invoke({\"messages\": messages, \"input_file\": \"Batman_training_and_meals.png\"})"
      ],
      "metadata": {
        "id": "8TJ-VFbcY5TU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}