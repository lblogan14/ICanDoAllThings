{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7WCtphd0UdxzFO6g7PJBq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7T9OIl8RkeLu"},"outputs":[],"source":["!pip install -qU diffusers transformers accelerate trimesh"]},{"cell_type":"markdown","source":["# Shap-E"],"metadata":{"id":"hrjdSOt5kuiV"}},{"cell_type":"markdown","source":["**Shap-E** is a conditional model for generating 3D assets which could be used for video game development, interior design, and architecture. It is trained on a large dataset of 3D assets, and post-processed to render more views of each object and produce 16K instead of 4K point clouds.\n","\n","The Shap-E model is trained in two steps:\n","1. an encoder accepts the point clouds and rendered views of a 3D asset and outputs the parameters of implicit functions that represent the asset\n","2. a diffusion model is trained on the latents produced by the encoder to generate either neural radience fields (NeRFs) or a textured 3D mesh, making it easier to render and use the 3D asset in downstream applications."],"metadata":{"id":"x3dekc8nkv_G"}},{"cell_type":"markdown","source":["## Text-to-3D"],"metadata":{"id":"q9J3vXkil0Wd"}},{"cell_type":"code","source":["from diffusers import ShapEPipeline\n","import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","pipe = ShapEPipeline.from_pretrained(\n","    'openai/shap-e',\n","    torch_dtype=torch.float16,\n","    variant='fp16',\n",").to(device)"],"metadata":{"id":"oaflJPsVkvc9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = [\n","    'a firecracker',\n","    'a birthday cupcake'\n","]\n","guidance_scale = 15.0\n","\n","images = pipe(\n","    prompt,\n","    guidance_scale=guidance_scale,\n","    num_inference_steps=64,\n","    frame_size=256,\n",").images"],"metadata":{"id":"h6FLMGFGmVGK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from diffusers.utils import export_to_gif\n","\n","export_to_gif(images[0], 'firecracker_3d.gif')\n","export_to_gif(images[1], 'cake_3d.gif')"],"metadata":{"id":"aR-p4H6NmguR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Image-to-3D"],"metadata":{"id":"HNBJSFQ1mqA9"}},{"cell_type":"code","source":["# We will use Kandinsky 2.1 to generate an image first\n","\n","from diffusers import DiffusionPipeline\n","import torch\n","\n","prior_pipeline = DiffusionPipeline.from_pretrained(\n","    'kandinsky-community/kandinsky-2-1-prior',\n","    torch_dtype=torch.float16,\n","    use_safetensors=True,\n",").to('cuda')\n","\n","pipeline = DiffusionPipeline.from_pretrained(\n","    'kandinsky-community/kandinsky-2-1',\n","    torch_dtype=torch.float16,\n","    use_safetensors=True,\n",").to('cuda')"],"metadata":{"id":"NMqu8f4SmrMC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = 'a cheeseburger, white background'\n","image_embeds, negative_image_embeds = prior_pipeline(\n","    prompt,\n","    guidance_scale=1.0\n",").to_tuple()\n","\n","image = pipeline(\n","    prompt,\n","    image_embeds=image_embeds,\n","    negative_image_embeds=negative_image_embeds,\n",").images[0]\n","\n","image.save('burger.png')"],"metadata":{"id":"Ze44jUBZnIkQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we can use Shap-E:"],"metadata":{"id":"2XGX6NamnZFL"}},{"cell_type":"code","source":["from PIL import Image\n","from diffusers import ShapEImg2ImgPipeline\n","from diffusers.utils import export_to_gif\n","\n","pipe = ShapEImg2ImgPipeline.from_pretrained(\n","    'openai/shap-e-img2img',\n","    torch_dtype=torch.float16,\n","    variant='fp16'\n",").to('cuda')"],"metadata":{"id":"Jsh7DMOanarv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = Image.open('burger.png').resize((256,256))\n","guidance_scale = 3.0\n","\n","images = pipe(\n","    image,\n","    guidance_scale=guidance_scale,\n","    num_inference_steps=64,\n","    frame_size=256,\n",").images\n","\n","export_to_gif(images[0], 'burger_3d.gif')"],"metadata":{"id":"V3aRVcW6nmuH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generate mesh"],"metadata":{"id":"eXtbXLx9nz0P"}},{"cell_type":"markdown","source":["Shap-E is a flexible model that can also generate textured mesh outputs to be rendered for downstream applications."],"metadata":{"id":"QUalgR62n3hz"}},{"cell_type":"code","source":["from diffusers import ShapEPipeline\n","import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","pipe = ShapEPipeline.from_pretrained(\n","    'openai/shap-e',\n","    torch_dtype=torch.float16,\n","    variant='fp16',\n",").to(device)"],"metadata":{"id":"C8deTv19n1II"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = 'a birthday cupcake'\n","guidance_scale = 15.0\n","\n","images = pipe(\n","    prompt,\n","    guidance_scale=guidance_scale,\n","    num_inference_steps=64,\n","    frame_size=256,\n","    output_type='mesh', # note here\n",")"],"metadata":{"id":"sM3W5D3xoB7C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Use the `export_to_ply()` to save the mesh output as a `ply` file. (We can also save the mesh output as an `obj` file with the `export_to_obj()` function.)"],"metadata":{"id":"9PNfiaxLoOm-"}},{"cell_type":"code","source":["from diffuers.utils import export_to_ply\n","\n","ply_path = export_to_ply(images[0], '3d_cake.ply')\n","print(f\"Saved to folder: {ply_path}\")"],"metadata":{"id":"W8UMW2T1oZrB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Then we can convert the `ply` file to a `glb` file with the trimesh library:"],"metadata":{"id":"oP_dpPKToY8u"}},{"cell_type":"code","source":["import trimesh\n","\n","mesh = trimesh.load('3d_cake.ply')\n","mesh_export = mesh.export('3d_cake.glb', file_type='glb')"],"metadata":{"id":"KJch7HJXonZe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A GLB file (`.glb`), \"GL Transmission Format Binary\", is a standardized file foramt used to store and share 3D data, including 3D models, scenes, textures, materials, animations, and lighting information, all contained within a single, compact binary file."],"metadata":{"id":"sc22GDRIoyQe"}},{"cell_type":"markdown","source":["By default, the mesh output is focused from the bottom viewpoint but we can change the default viewpoint by applying a rotation transform:"],"metadata":{"id":"KqkAmM3ApGuh"}},{"cell_type":"code","source":["import trimesh\n","import numpy as np\n","\n","mesh = trimesh.load('3d_cake.ply')\n","\n","rot = trimesh.transformations.rotation_matrix(-np.pi / 2, [1, 0, 0])\n","mesh = mesh.apply_transform(rot)\n","\n","mesh_export = mesh.export('3d_cake.glb', file_type='glb')"],"metadata":{"id":"zhZWsX9SpOWg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The mesh file can be visualized with the Dataset viewer once we upload it to the dataset repository."],"metadata":{"id":"IgZAbDb3pe-Z"}}]}