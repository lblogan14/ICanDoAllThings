{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPzVnWmNfF55LUv1THa0eqr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Introduction to LangGraph - Module 0"],"metadata":{"id":"3WdNdpZotMjb"}},{"cell_type":"markdown","source":["# Pre-requisites"],"metadata":{"id":"DSsx2baFuQuH"}},{"cell_type":"code","source":["!pip install -qU langchain_openai langchain_core langchain_community tavily-python langchain-tavily"],"metadata":{"id":"G4KIrLkGuSmO","executionInfo":{"status":"ok","timestamp":1755094102146,"user_tz":300,"elapsed":5575,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Chat models"],"metadata":{"id":"3DFOAwxDtaO1"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"cWt0ZxFAkfxd","executionInfo":{"status":"ok","timestamp":1755093668407,"user_tz":300,"elapsed":359,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}}},"outputs":[],"source":["from google.colab import userdata\n","import os\n","os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"]},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","\n","gpt4o_chat = ChatOpenAI(\n","    model=\"gpt-4o\",\n","    temperature=0\n",")\n","gpt5_chat = ChatOpenAI(\n","    model=\"gpt-5\",\n","    temperature=0\n",")"],"metadata":{"id":"oj4IoJkcunUi","executionInfo":{"status":"ok","timestamp":1755093706117,"user_tz":300,"elapsed":6476,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Chat models offers two generation methods:\n","- `stream`: streaming back chunks of the response\n","- `invoke`: call the chain on an input."],"metadata":{"id":"9r0zdxYyvN-Z"}},{"cell_type":"code","source":["from langchain_core.messages import HumanMessage\n","\n","# Create a user message\n","msg = HumanMessage(\n","    content=\"Hello world!\",\n","    name=\"Bin\"\n",")\n","\n","# Prepare a message list\n","messages = [msg]\n","messages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UU73Qheku1LK","executionInfo":{"status":"ok","timestamp":1755093842275,"user_tz":300,"elapsed":10,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}},"outputId":"ffcfa945-fe18-4faf-a6b4-d5f95dfe4968"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[HumanMessage(content='Hello world!', additional_kwargs={}, response_metadata={}, name='Bin')]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Invoke the model with a list of messages\n","gpt4o_chat.invoke(messages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tfa-FuDnvrhn","executionInfo":{"status":"ok","timestamp":1755093860328,"user_tz":300,"elapsed":2238,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}},"outputId":"c23a0f4e-cceb-4c1b-fdcc-43d3367ce78f"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 12, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-C46NODQuPI2aFi1xFUlc8gyQQcRv1', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a433d06f-3c1b-4df0-b501-7496e8cbacd8-0', usage_metadata={'input_tokens': 12, 'output_tokens': 9, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["The returned message is `AIMessage` object.\n","\n","We can also just invoke a chat model with a string:"],"metadata":{"id":"rJ2hq2R7vyOx"}},{"cell_type":"code","source":["gpt4o_chat.invoke(\"Hello world!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZyBxa4W_vvY-","executionInfo":{"status":"ok","timestamp":1755093908969,"user_tz":300,"elapsed":2044,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}},"outputId":"4e88da58-bbd9-4e6e-e133-13cf08a39098"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 10, 'total_tokens': 19, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ff25b2783a', 'id': 'chatcmpl-C46OBwVr85RreYZvNRH2OkmXEpNok', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8151d459-93cd-4f71-9fb8-459a4ed49061-0', usage_metadata={'input_tokens': 10, 'output_tokens': 9, 'total_tokens': 19, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["# Search Tools"],"metadata":{"id":"xO8Yum3wv_J4"}},{"cell_type":"markdown","source":["Tavily is a search engine optimized for LLMs and RAGs."],"metadata":{"id":"FGhhn3H_wA24"}},{"cell_type":"code","source":["os.environ['TAVILY_API_KEY'] = userdata.get('TAVILY_API_KEY')"],"metadata":{"id":"Lrv4LNzPv7T0","executionInfo":{"status":"ok","timestamp":1755093975850,"user_tz":300,"elapsed":1929,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from langchain_tavily import TavilySearch\n","\n","tavily_search = TavilySearch(max_results=5)\n","search_docs = tavily_search.invoke(\n","    \"What is LangGraph?\"\n",")"],"metadata":{"id":"Wk8HhcnkwLqw","executionInfo":{"status":"ok","timestamp":1755094119425,"user_tz":300,"elapsed":1961,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["search_docs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZUg-1PLUwYnm","executionInfo":{"status":"ok","timestamp":1755094122400,"user_tz":300,"elapsed":29,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}},"outputId":"c172eecd-d8aa-42f8-f9cc-9a3b5015e429"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'query': 'What is LangGraph?',\n"," 'follow_up_questions': None,\n"," 'answer': None,\n"," 'images': [],\n"," 'results': [{'url': 'https://www.ibm.com/think/topics/langgraph',\n","   'title': 'What is LangGraph?',\n","   'content': 'LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. LangGraph illuminates the processes within an AI workflow, allowing full transparency of the agent’s state. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including chatbots, state graphs and other agent-based systems. Nodes: In LangGraph, nodes represent individual components or agents within an AI workflow. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback.',\n","   'score': 0.9659543,\n","   'raw_content': None},\n","  {'url': 'https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/',\n","   'title': 'What is LangGraph?',\n","   'content': 'LangGraph is a library built on top of Langchain that is designed to facilitate the creation of cyclic graphs for large language model (LLM) –',\n","   'score': 0.96057266,\n","   'raw_content': None},\n","  {'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n","   'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?',\n","   'content': 'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.',\n","   'score': 0.9581988,\n","   'raw_content': None},\n","  {'url': 'https://huggingface.co/learn/agents-course/en/unit2/langgraph/when_to_use_langgraph',\n","   'title': 'What is LangGraph ? - Hugging Face Agents Course',\n","   'content': 'LangGraph is a framework developed by LangChain to manage the control flow of applications that integrate an LLM.',\n","   'score': 0.9451216,\n","   'raw_content': None},\n","  {'url': 'https://langchain-ai.github.io/langgraph/',\n","   'title': 'LangGraph - GitHub Pages',\n","   'content': 'LangGraph LangGraph  LangGraph  LangGraph Trusted by companies shaping the future of agents – including Klarna, Replit, Elastic, and more – LangGraph is a low-level orchestration framework for building, managing, and deploying long-running, stateful agents. from langgraph.prebuilt import create_react_agent Or, to learn how to build an agent workflow with a customizable architecture, long-term memory, and other complex task handling, see the LangGraph basics tutorials. LangGraph provides low-level supporting infrastructure for _any_ long-running, stateful workflow or agent. While LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. *   LangGraph Platform — Deploy and scale agents effortlessly with a purpose-built deployment platform for long running, stateful workflows.',\n","   'score': 0.94314384,\n","   'raw_content': None}],\n"," 'response_time': 1.28}"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":[],"metadata":{"id":"QGMAQ_bBwv6T"},"execution_count":null,"outputs":[]}]}