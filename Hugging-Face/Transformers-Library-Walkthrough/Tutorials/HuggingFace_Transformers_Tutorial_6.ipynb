{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-TXl3nW21wY"
   },
   "source": [
    "# Agents 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A89uF40p3AtX"
   },
   "source": [
    "## What is an agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObX9V0QU3EOB"
   },
   "source": [
    "Large Language Models (LLMs) trained to perform **causal language modeling** can tackle a wid range of tasks, but they often struggle with basic tasks like logic, calculation, and search.\n",
    "\n",
    "An **agent** is a system that uses an LLM as its engine, and it has access to functions called *tools*.\n",
    "\n",
    "These **tools** are functions for performing a task, and they contain all necessary description for the agent to properly use them.\n",
    "\n",
    "The agent can be programmed to\n",
    "* devise a series of actions/tools and run them all at once\n",
    "* plan and execute actions/tools one by one and wait for the outcome of each action before launching the next one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mnqwk02-_71G"
   },
   "source": [
    "## How can I build an agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oauYKL1_-Q-"
   },
   "source": [
    "To initialize an agent, we need\n",
    "* an LLM to power our agent - the agent is not exactly the LLM, it's more like the agent is a program that uses an LLM as its engine\n",
    "* a system prompt - what the LLM engine will be prompted with to generate its output\n",
    "* a toolbox from which the agent pick tools to execute\n",
    "* a parser to extract from the LLM output which tools are to call and with which arguments\n",
    "\n",
    "To start with, we need to install the `agents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16697,
     "status": "ok",
     "timestamp": 1729631425956,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "tBvaBKJx2zP2",
    "outputId": "3e239369-f408-424a-c987-1142e30fa0dc"
   },
   "outputs": [],
   "source": [
    "!pip install transformers[agents] sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsiIj50WA0Cd"
   },
   "source": [
    "Build our LLM engine by defining a `llm_engine` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUHOh1rsAzh3"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login, InferenceClient\n",
    "\n",
    "login('<HUGGINGFACE_HUB_API_TOKEN>')\n",
    "\n",
    "client = InferenceClient(model='meta-llama/Meta-Llama-3-70B-Instruct')\n",
    "\n",
    "def llm_engine(messages, stop_sequences=['Task']):\n",
    "    response = client.chat_completion(\n",
    "        messages,\n",
    "        stop=stop_sequences,\n",
    "        max_tokens=1000,\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WBaZXzaBXK0"
   },
   "source": [
    "We could use any `llm_engine` method as long as\n",
    "1. it follows the messages format(`List[Dict[str, str]]`) for its input `messages`, and it returns a `str`.\n",
    "2. it stops generating outputs at the sequences passed in the argument `stop_sequences`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_kiw9lxB6am"
   },
   "source": [
    "We will also need a `tools` argument which accepts a list of `Tools` - it can be an empty list. We can also add the default toolbox on top of our `tools` list by defining the optional argument `add_base_tool=True`.\n",
    "\n",
    "Now we can create an agent and run it. We can also create a `TransformersEngine` with a pre-initialized pipeline to run inference on our local machine using `transformers`. For convenience, since agentic behaviors generally require stronger models such as `Llama-3.1-70B-Instruct` that are difficult to run locally, we can use the `HfApiEngine` class that initializes a `huggingface_hub.InferenceClient` under the hood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhVxRgkPCgTu"
   },
   "outputs": [],
   "source": [
    "from transformers import CodeAgent, HfApiEngine\n",
    "\n",
    "llm_engine = HfApiEngine(model='meta-llama/Meta-Llama-3-70B-Instruct')\n",
    "agent = CodeAgent(tools=[],\n",
    "                  llm_engine=llm_engine,\n",
    "                  add_base_tool=True)\n",
    "\n",
    "agent.run(\n",
    "    'Could you translate this sentence from French, say it out loud and return the audio.',\n",
    "    sentence=\"OÃ¹ est la boulangerie la plus proche?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "terHDtdzDBw3"
   },
   "source": [
    "Here we used an additional `sentence` argument. We can pass text as additional arguments to the model.\n",
    "\n",
    "We can also use this to indicate the path to local or remote files for the model to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kmnB8SRDKUQ"
   },
   "outputs": [],
   "source": [
    "from transformers import ReactCodeAgent\n",
    "\n",
    "agent = ReactCodeAgent(tools=[],\n",
    "                       llm_engine=llm_engine,\n",
    "                       add_base_tool=True)\n",
    "\n",
    "agent.run(\n",
    "    \"Why does Mike not know many people in New York?\",\n",
    "    audio=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/recording.mp3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzIQf-bhEYFy"
   },
   "source": [
    "The prompt and output parser were automatically defined, but we can easily inspect them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Km2vON3QDag-"
   },
   "outputs": [],
   "source": [
    "agent.system_prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QFhMOG6ExkG"
   },
   "source": [
    "It is important to explain as clearly as possible the task we want to perform. Every `run()` operation is independent, and since an agent is powered by an LLM, minor variations in our prompt might yield completely different results.\n",
    "\n",
    "We can run an agent consecutively for different tasks: each time the attributes `agent.task` and `agent.logs` will be re-initialized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxF_rdsEFI5T"
   },
   "source": [
    "### Code execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oYcfjKYFTOf"
   },
   "source": [
    "A Python interpreter executes the code on a set of inputs passed along with your tools. The Python interpreter also doesn't allow imports by default outside of a safe list, so all the most obvious attacks shouldn't be an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ss1IimeMFHTq"
   },
   "outputs": [],
   "source": [
    "from transformers import ReactCodeAgent\n",
    "\n",
    "agent = ReactCodeAgent(tools=[],\n",
    "                       additional_authorized_imports=['requests', 'bs4'])\n",
    "\n",
    "agent.run(\n",
    "    \"Could you get me the title of the page at url 'https://huggingface.co'?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMEYV7GuFpyM"
   },
   "source": [
    "## The system prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgl6M6fOFriq"
   },
   "source": [
    "An agent, or rather the LLM that drives the agent, generates an output based on the system prompt. The system prompt can be customized and tailored to the intended task.\n",
    "\n",
    "For example, check the system prompt for the ReactCodeAgent:\n",
    "```\n",
    "You will be given a task to solve as best you can.\n",
    "You have access to the following tools:\n",
    "<<tool_descriptions>>\n",
    "\n",
    "To solve the task, you must plan forward to proceed in a series of steps, in a cycle of 'Thought:', 'Code:', and 'Observation:' sequences.\n",
    "\n",
    "At each step, in the 'Thought:' sequence, you should first explain your reasoning towards solving the task, then the tools that you want to use.\n",
    "Then in the 'Code:' sequence, you shold write the code in simple Python. The code sequence must end with '/End code' sequence.\n",
    "During each intermediate step, you can use 'print()' to save whatever important information you will then need.\n",
    "These print outputs will then be available in the 'Observation:' field, for using this information as input for the next step.\n",
    "\n",
    "In the end you have to return a final answer using the `final_answer` tool.\n",
    "\n",
    "Here are a few examples using notional tools:\n",
    "---\n",
    "{examples}\n",
    "\n",
    "Above example were using notional tools that might not exist for you. You only have acces to those tools:\n",
    "<<tool_names>>\n",
    "You also can perform computations in the python code you generate.\n",
    "\n",
    "Always provide a 'Thought:' and a 'Code:\\n```py' sequence ending with '```<end_code>' sequence. You MUST provide at least the 'Code:' sequence to move forward.\n",
    "\n",
    "Remember to not perform too many operations in a single code block! You should split the task into intermediate code blocks.\n",
    "Print results at the end of each step to save the intermediate results. Then use final_answer() to return the final result.\n",
    "\n",
    "Remember to make sure that variables you use are all defined.\n",
    "\n",
    "Now Begin!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7Nki_F7F741"
   },
   "source": [
    "The system prompt includes:\n",
    "* an *introduction* that explains how the agent should behave and what tools are.\n",
    "* a description of all the tools that is defined by a `<<tool_description>>` token that is dynamically replaced at runtime with the tools defined/chosen by the user.\n",
    "  * The tool description comes from the tool attributes, `name`, `description`, `inputs` and `output_type`, and a simple `jinja2` template that we can define.\n",
    "* The expected output format.\n",
    "\n",
    "We could improve the system prompt, for example, by adding an explanation of the output format.\n",
    "\n",
    "For maximum flexibility, we can overwrite the whole system prompt template by passing our custom prompt as an argument to the `system_prompt` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FRhczlRFrG1"
   },
   "outputs": [],
   "source": [
    "from transformers import ReactJsonAgent\n",
    "from transformers.agents import PythonInterpreterTool\n",
    "\n",
    "agent = ReactJsonAgent(tools=[PythonInterpreterTool()],\n",
    "                       system_prompt=\"{our_custom_prompt_here}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUncb1g1G5In"
   },
   "source": [
    "Make sure to define the `<<tool_descriptions>>` string somewhere in the `template` so the agent is aware of the available tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5-2MoB1HB9A"
   },
   "source": [
    "## Inspecting an agent run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEEPTlbnHEyR"
   },
   "source": [
    "* `agent.logs` stores the fine-grained logs of the agent.\n",
    "* Running `agent.write_inner_memory_from_logs()` creates an inner memory of the agent's logs for the LLM to view, as a list of chat messages. This method goes over each step of the log and only stores what it is interested in as a message: for example, it will save the system prompt and task in separate messages, then for each step it will store the LLM output as a message, and the tool call output as another message. Use this if we want a higher-level view of what has happened - but not every log will be transcripted by this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27-hulk5Hjls"
   },
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Y0VjYRgHlfx"
   },
   "source": [
    "A tool is an atomic function to be used by an agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-r0ep67sHrdx"
   },
   "source": [
    "### Default toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjqZk05ZHtHG"
   },
   "source": [
    "Add a default toolbox to our agent upon initialization with `add_base_tools = True`:\n",
    "* **Document question answering**: given a document (such as a PDF) in image format, answer a question on this document\n",
    "* **Image question answering**: given a image, answer a question on this image\n",
    "* **Speech to text**: gien an audio recording of a person talking, transcribe the speech into text\n",
    "* **Text to speech**: convert text to speech\n",
    "* **Translation**: translate a given sentence from source language to target language\n",
    "* **DuckDuckGo search**: perform a web search using DuckDuckGo brower\n",
    "* **Python code interpreter**: run the LLM generated Python code in a secure environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tytXiuG0HEdv"
   },
   "outputs": [],
   "source": [
    "from transformers import load_tool\n",
    "\n",
    "tool = load_tool('text-to-speech')\n",
    "audio = tool(\"This is a text to speech tool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeaQMbv3IvcA"
   },
   "source": [
    "### Create a new tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tush19dKIy8b"
   },
   "source": [
    "Let's create a tool that returns the most downloaded model for a given task from the hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1729632678109,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "Th2sjHzpIw4h",
    "outputId": "692433bf-d7b4-4ea4-ef34-2733c6311825"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1231czx/llama3_it_ultra_list_and_bold500'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import list_models\n",
    "\n",
    "task = 'text-classification'\n",
    "\n",
    "model = next(iter(list_models(filter=task,\n",
    "                              sort='downloads',\n",
    "                              direction=-1)))\n",
    "\n",
    "model.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dajc_zEaJEYn"
   },
   "source": [
    "This code can quickly be converted into a tool, just by wrapping it in a function and adding the `tool` decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwBMVHX5JC1I"
   },
   "outputs": [],
   "source": [
    "from transformers import tool\n",
    "\n",
    "@tool\n",
    "def model_download_tool(task:str) -> str:\n",
    "    \"\"\"\n",
    "    This is a tool that returns the most downloaded model of a given task on the Hugging Face Hub.\n",
    "    It returns the name of the checkpoint.\n",
    "\n",
    "    Args:\n",
    "        task: The task for which\n",
    "    \"\"\"\n",
    "    model = next(iter(list_models(filter=task,\n",
    "                              sort='downloads',\n",
    "                              direction=-1)))\n",
    "    return model.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3aD96mGJanS"
   },
   "source": [
    "The function needs:\n",
    "* A clear name to describe what the tool does.\n",
    "* Type hints on both inputs and output\n",
    "* A description that includes an \"Args:\" part where each argument is described. All these will be automatically baked into the agent's system prompt upon initialization.\n",
    "\n",
    "Then we can directly initialize our agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npotAfz7JRYL"
   },
   "outputs": [],
   "source": [
    "from transformers import CodeAgent\n",
    "\n",
    "agent = CodeAgent(tools=[model_download_tool],\n",
    "                  llm_engine=llm_engine)\n",
    "\n",
    "agent.run(\n",
    "    \"Can you give me the name of the model that has the most downloads in the 'text-to-video' task on the Hugging Face Hub?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kL_w-CGZKM3F"
   },
   "source": [
    "### Manage agent's toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HoB3hLlKQPP"
   },
   "source": [
    "If we have already initialized an agent, it is inconvenient to reinitialize it from scratch with a tool we want to use.\n",
    "\n",
    "We can add the `model_download_tool` to an existing agent initialized with only the default toolbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DacF2HeEKPl-"
   },
   "outputs": [],
   "source": [
    "from transformers import CodeAgent\n",
    "\n",
    "agent = CodeAgent(tools=[],\n",
    "                  llm_engine=llm_engine,\n",
    "                  add_base_tool=True)\n",
    "\n",
    "# add existing tool\n",
    "agent.toolbox.add_tool(model_download_tool)\n",
    "\n",
    "agent.run(\n",
    "    \"Can you give me the name of the model that has the most downloads in the 'text-to-video' task on the Hugging Face Hub?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-d8JaB8IKwxP"
   },
   "source": [
    "Use the `agent.toolbox.update_tool()` method to replace an existing tool in the agent's toolbox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0eR5tvsK3uZ"
   },
   "source": [
    "### Use a collection of tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltEhnhtpK5xb"
   },
   "source": [
    "We can leverage tool collections by using the `ToolCollection` object, with the slug of the collection we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0PMfuEfK20V"
   },
   "outputs": [],
   "source": [
    "from transformers import ToolCollection, ReactCodeAgent\n",
    "\n",
    "image_tool_collection = ToolCollection(collection_slug=\"huggingface-tools/diffusion-tools-6630bb19a942c2306a2cdb6f\")\n",
    "\n",
    "agent = ReactCodeAgent(tools=[*image_tool_collection],\n",
    "                       add_base_tools=True) # use default llm_engine\n",
    "\n",
    "agent.run(\"Please draw me a picture of rivers and lakes.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKhivwesOHPlCY+BcFpn54",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
