{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Model Context Protocol"
      ],
      "metadata": {
        "id": "e4haS7bM-4kJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLMs are limited by their training data and lack access to real-time information or specialized tools.\n",
        "\n",
        "The **Model Context Protocol (MCP)** enables AI models to connect with external data sources, tools, and envrionments, allowing for the seamless transfer of information and capabilities between AI systems and the broader world."
      ],
      "metadata": {
        "id": "2ZTiHJZ5-9OQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Terminology"
      ],
      "metadata": {
        "id": "KJjTDXS4_Vpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just as USB-C provides a standardized physical and logical interface for connecting various peripherals to computing devices, MCP offers a consistent protocol for linking AI models to external capabilities. This standardization beneftis the entire ecosystem:\n",
        "- Users enjoy simpler and more consistent experiences across AI applications.\n",
        "- AI application developers gain easy integration with a growing ecosystem of tools and data sources\n",
        "- Tool and data providers need only create a single implementation that works with multiple AI applications\n",
        "- The broader ecosystem benefits from increased interoperability, innovation, and reduced fragmentation"
      ],
      "metadata": {
        "id": "g__nSIpR_aa4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **MxN integration problem** refers to the challenge of connecting M different AI applications to N different external tools or data sources without a standardized approach.\n",
        "\n",
        "Without a protocol like MCP, developers would need to create MxN custom integrations - one for each possible pairing of an AI application with an external capability, which causes a lot of frictions and high mantainenance costs.\n",
        "\n",
        "MCP transforms this into an **M+N** problem by providing a standard interface:\n",
        "- *each AI application implements the client side of MCP once, and*\n",
        "- *each tool/data source implements the server side one*.\n",
        "\n",
        "Therefore, MCP is a standard like HTTP or USB-C, and is a protocol for connecting AI applications to external tools and data sources."
      ],
      "metadata": {
        "id": "pqFXH4ZS_89i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like client server relationships in HTTP, MCP has a client and a server.\n",
        "- **Host** - the user-facing AI applications that end-users interact with directly. Examples include Anthropic's Claude Desktop, AI-enhanced IDEs like Cursor, inference libraries like HuggingFace Python SDK, or custom applications built in libraries LangChain or smolagents. Hosts initiate connections to MCP Servers and orchestrate the overall flow between user requests, LLM processing, and external tools.\n",
        "\n",
        "- **Client** - a component within the host application that manages communication with a specific MCP Server. Each client maintains a 1-to-1 connection with a single Server, handling the protocol-level details of MCP communication and acting as an intermediary between the Host's logic and the external Server.\n",
        "\n",
        "- **Server** - an external program or service that exposes capabilities (tools, resources, prompts) via the MCP protocol."
      ],
      "metadata": {
        "id": "oBsndt6oBGV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The value of AI applications relies on the capabilities the applications could offer:\n",
        "\n",
        "| Capability | Description | Example |\n",
        "| --- | --- | --- |\n",
        "| Tools | Executable functions that the AI model can invoke to perform actions or retrieve computed data. Typically relating to the use case of the application. | A tool for a weather application might be a function that returns the weather in a specific location. |\n",
        "| Resources | Read-only data sources that provide context without significant computation. | A researcher assistant might have a resource for scientific papers. |\n",
        "| Prompts | Pre-defined templates or workflows that guide interactions between users, AI models, and the available capabilities. | A summarization prompt. |\n",
        "| Sampling | Server-initiated requests for the Client/Host to perform LLM interactions, enabling recursive actions where the LLM can review generated content and make further decisions. | A writing application reviewing its own output and decide to refine it further. |\n",
        "\n",
        "We may use their MCP entities in the following ways:\n",
        "\n",
        "| Entity | Name | Description |\n",
        "| --- | --- | --- |\n",
        "| Tool | Code Interpreter | A tool that can execute code that the LLM writes. |\n",
        "| Resource | Documentation | A resource that contains the documentation of the application. |\n",
        "| Prompt | Code Style | A prompt that guides the LLM to generate code. |\n",
        "| Sampling | Code Review | A sampling that allows the LLM to review the code and make further decisions. |"
      ],
      "metadata": {
        "id": "lepw3M49CDH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architectural Components of MCP"
      ],
      "metadata": {
        "id": "5XsXOH3DDJhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MCP protocol is built on a client-server architecture that enables structured communication between AI models and external systems.\n",
        "\n",
        "The MCP architecture consists of three primary components: Host, Client, and Server."
      ],
      "metadata": {
        "id": "OsmgyEaDDOba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Host"
      ],
      "metadata": {
        "id": "ns3PTB3wDdkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Host** is the user-facing AI application that end-users interact with directly.\n",
        "\n",
        "For example\n",
        "- AI Chat apps like OpenAI ChatGPT or Anthropic's Claude Desktop\n",
        "- AI-enhanced IDEs like Cursor, or integraitons to tools like Continue.dev\n",
        "- Custom AI agents and applications built in libraries like LangChain or smolagents\n",
        "\n",
        "Responsibilities of the Host:\n",
        "- managing user interactions and permissions\n",
        "- initiating connections to MCP Servers via MCP Clients\n",
        "- orchestrating the overall flow between user requests, LLM processing, and external tools\n",
        "- rendering results back to users in a coherent format\n",
        "\n",
        "\n",
        "In most cases, users will select their host application based on their needs and preferences."
      ],
      "metadata": {
        "id": "EN2QKcgpDfU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Client"
      ],
      "metadata": {
        "id": "ylgWvukIEG8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Client** is a component within the Host application that manages communication with a specific MCP Server,\n",
        "- Each Client maintains a 1-to-1 connection with a single Server\n",
        "- Handles the protocol-level details of MCP communication\n",
        "- Acts as the intermediary between the Host's logic and the external Server"
      ],
      "metadata": {
        "id": "jQgZFe9jEISJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Server"
      ],
      "metadata": {
        "id": "o-mnUHn_EdRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Server** is an external program or service that exposes capabilities to AI models via the MCP protocol.\n",
        "\n",
        "Servers\n",
        "- provide access to specific external tools, data sources, or services\n",
        "- Act as lightweight wrappers around existing functionality\n",
        "- Cuan run locally or remotely\n",
        "- Expose their cacpabilities in a standarddized format that Clients can discover and use"
      ],
      "metadata": {
        "id": "NSI4ihXHEeyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Communication Flow"
      ],
      "metadata": {
        "id": "u2OlLo0QZnaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How the Host, Client, and Server interact in a MCP workflow:\n",
        "- **User Interaction** - The user interacts with the **Host** application, expressing an intent or query.\n",
        "- **Host Processing** - The **Host** processes the user's input, potentially using an LLM to understand the request and determine which external capabilities might be needed.\n",
        "- **Client Connection** - The **Host** directs its **Client** component to connect to the appropriate **Server(s)**.\n",
        "- **Capability Discovery** - The **Client** queries the **Server** to discover what capabilities (Tools, Resources, Prompts) it offers.\n",
        "- **Capability Invocation** - Based on the user's needs or the LLM's determination, the **Host** instructs the **Client** to invoke specific capabilities from the **Server**.\n",
        "- **Server Execution** - The **Server** executes the requested funcationality and returns results to the **Client**.\n",
        "- **Result Integration** - The **Client** relays these results back to the **Host**, which incorporates them into the context for the LLM or presents them directly to the user.\n",
        "\n",
        "\n",
        "A key advantage of this architecture is its modularity. A single **Host** can connect to multiple **Servers** simultaneously via different **Clients**. New **Servers** can be added to the ecosystem without requiring changes to existing **Hosts**. Capabilities can be easily composed across different **Servers**. This modularity transforms the traditional MxN integration problem into a more manageable M+N problem."
      ],
      "metadata": {
        "id": "Sa5goD8TZrCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Communication Protocol"
      ],
      "metadata": {
        "id": "OgqsvCnOeyb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MCP defines a standardized communication protocol that enables **Clients** and **Servers** to exchange messages in a consistent, predictable way. This standardization is critical for interoperability across the community."
      ],
      "metadata": {
        "id": "y1ehHn1-e35J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSON-RPC: The Foundation"
      ],
      "metadata": {
        "id": "c-wS3S_We9gi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At its core, MCP uses **JSON-RPC 2.0** as the message format for all communication between **Clients** and **Servers**.\n",
        "\n",
        "JSON-RPC is a lightweight remote procedure call protocol encoded in JSON, which makes it\n",
        "- Human-readable and easy to debug\n",
        "- Language-agnostic, supporting implementation in any programming environment\n",
        "- Well-established, with clear specifications and widespread adoption\n",
        "\n",
        "\n",
        "```\n",
        "Client ----[    Request     ]---> Server\n",
        "       <---[    Response    ]----\n",
        "       <---[  Notification  ]----\n",
        "```\n",
        "\n",
        "The protocol defines three types of meesages as shown in the diagram above."
      ],
      "metadata": {
        "id": "Aw1JQsORfAp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Requests**\n",
        "\n",
        "-- Sent from **Client** to **Server** to initiate an operation. A **Request** message includes:\n",
        "- A unique identifier (`id`)\n",
        "- The method name to invoke (e.g., `tools/call`)\n",
        "- Parameters for the method (if any)\n",
        "\n",
        "Example Request:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"jsonrpc\": \"2.0\",\n",
        "    \"id\": 1,\n",
        "    \"method\": \"tools/call\",\n",
        "    \"params\": {\n",
        "        \"name\": \"weather\",\n",
        "        \"arguments\" {\n",
        "            \"location\": \"Houston\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "**2. Responses**\n",
        "\n",
        "-- Sent from **Server** to **Client** in reply to a Request. A **Response** message includes:\n",
        "- The same `id` as the corresponding Request\n",
        "- Either a `result` (for success) or an `error` (for failure)\n",
        "\n",
        "Example Success Response:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"jsonrpc\": \"2.0\",\n",
        "    \"id\": 1,\n",
        "    \"result\": {\n",
        "        \"temperature\": 90,\n",
        "        \"conditions\": \"Sunny\"\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "Example Error Response:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"jsonrpc\": \"2.0\",\n",
        "    \"id\": 1,\n",
        "    \"error\": {\n",
        "        \"code\" -32602,\n",
        "        \"message\": \"Invalid location parameter\"\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "**3. Notifications**\n",
        "\n",
        "-- One-way messages that don't require a response. Typically sent from **Server** to **Client** to provide updates or notifications about events.\n",
        "\n",
        "Example Notification:\n",
        "```json\n",
        "{\n",
        "    \"jsonrpc\": \"2.0\",\n",
        "    \"method\": \"progress\",\n",
        "    \"params\": {\n",
        "        \"message\": \"Processing data...\",\n",
        "        \"percent\": 50\n",
        "    }\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "VOOz6IKUhA9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transport Mechanisms"
      ],
      "metadata": {
        "id": "qE6fR4R6kgeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The JSON-RPC defines the message format, but MCP also specifies how these messages are transported between **Clients** and **Servers**. There are two primary transport mechanisms:\n",
        "\n",
        "**stdio (Standard Input/Output)**\n",
        "\n",
        "The stdio transport is used for local communication, where the Client and Server run on the same machine:\n",
        "- The **Host** application launches the **Server** as a subprocess and communicates with it by writing to its standard input (stdin) and reading from its standard output (stdout).\n",
        "- Use cases: local tools like file system access or running local scripts\n",
        "- Advantages: simple, not network configuration required, and securely sandboxed by the operating system.\n",
        "\n",
        "\n",
        "**HTTP + SSE (Server-Sent Events) / Streamable HTTP**\n",
        "\n",
        "The HTTP+SSE transport is used for remote communication, where the Client and Server might be on different machines:\n",
        "- Communication happens over HTTP, with the **Server** using Server-Sent Events (SSE) to push updates to the **Client** over a persistent connection.\n",
        "- Use cases: connecting to remote APIs, cloud services, or shared resources.\n",
        "- Advantages: work across networks, enables integration with web services, and compatible with serverless environments.\n",
        "\n",
        "**Streamable HTTP** offers more flexibility by allowing servers to dynamically upgrade to SSE for streaming when needed, while maintaining compatbility with serverless environments."
      ],
      "metadata": {
        "id": "Iw4yRrxBleYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Interaction Lifecycle"
      ],
      "metadata": {
        "id": "eIaQVZUonPmX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MCP protocol defines a structured interaction lifecycle between Clients and Servers:\n",
        "\n",
        "**Initialization**\n",
        "\n",
        "The Client connects to the Server and they exchange protocol versions and capabilities, and the Server responds with its supported protocol version and capabilities.\n",
        "\n",
        "The Client confirms the initialization is complete via a notification message.\n",
        "\n",
        "**Discovery**\n",
        "\n",
        "The Client requests information about available capabilities and the Server responds with a list of available tools.\n",
        "\n",
        "This process could be repeated for each tool, resource, or prompt type.\n",
        "\n",
        "**Execution**\n",
        "\n",
        "The Client invokes capabilities based on the Host's needs.\n",
        "\n",
        "**Termination**\n",
        "\n",
        "The connection is gracefully closed when no longer needed and the Server acknowledges the shutdown request.\n",
        "\n",
        "The Client sends the final exit message to complete the termination."
      ],
      "metadata": {
        "id": "-weF4FHFpGJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding MCP Capabilities"
      ],
      "metadata": {
        "id": "S1tofGByp0S9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MCP Servers expose a variety of capabilities to Clients through the communication protocol. These capabilities fall into four main categories, each with distinct characteristics and use cases."
      ],
      "metadata": {
        "id": "NfL4Vm_0thIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tools"
      ],
      "metadata": {
        "id": "NotecjGQtlps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tools** are executable functions or actions that the AI models can invoke through the MCP protocol:\n",
        "- **Control*** - Tools are typically **model-controlled**, meaning that the AI models decide when to call them based on the user's request and context.\n",
        "- **Safety** - Due to their ability to perform actions with side effects, tool execution can be dangerous. Therefore, they typically require explicit user approval.\n",
        "- **Use Cases** - Sending messages, creating tickets, querying APIs, performing calculations.\n",
        "\n",
        "\n",
        "Example: A weather tool that fetches current weather data for a given location:\n",
        "\n",
        "In Python\n",
        "```python\n",
        "def get_weather(location: str) -> dict:\n",
        "    \"\"\"Get the current weather for a specified location.\"\"\"\n",
        "    # Connect to weather API and fetch data\n",
        "    return {\n",
        "        \"temperature\": 90,\n",
        "        \"conditions\": \"Sunny\",\n",
        "        \"humidity\": 45\n",
        "    }\n",
        "```\n",
        "\n",
        "In JavaScript\n",
        "```javascript\n",
        "function getWeather(location) {\n",
        "    //Connect to weather API and fetch data\n",
        "    return {\n",
        "        temperature: 90,\n",
        "        conditions: \"Sunny\",\n",
        "        humidity: 45\n",
        "    };\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "Lr_37HcStnd2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resources"
      ],
      "metadata": {
        "id": "xZIbikqtup29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resources** provide read-only access to data sources, allowing the AI models to retrieve context without executing complex logic:\n",
        "- **Control** - Resources are **application-controlled**, meaning that the **Host** applications typically decide when to access them.\n",
        "- **Nature** - They are designed for data retrieval with minimal computation, similar to GET endpoints in REST APIs.\n",
        "- **Safety** - Since they are read-only, they typically present lower security risks than **Tools**.\n",
        "- **Use Cases** - Accessing file contents, retrieving database records, reading configuration information.\n",
        "\n",
        "\n",
        "Example: A resource that provides access to file content:\n",
        "\n",
        "In Python\n",
        "```python\n",
        "def read_file(filepath: str) -> str:\n",
        "    \"\"\"Read the contents of a file at the specified path.\"\"\"\n",
        "    with open(filepath, 'r') as f:\n",
        "        return f.read()\n",
        "```\n",
        "\n",
        "\n",
        "In JavaScript:\n",
        "```javascript\n",
        "function readFile(filepath) {\n",
        "    // Using fs.readFile to read file contents\n",
        "    const fs = require('fs');\n",
        "    return new Promise((resolve, reject) => {\n",
        "        fs.readFile(filepath, 'utf8', (err, data) => {\n",
        "            if (err) {\n",
        "                reject(err);\n",
        "                return;\n",
        "            }\n",
        "            resolve(data);\n",
        "        });\n",
        "    });\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "XWxR6vn9urOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompts"
      ],
      "metadata": {
        "id": "m8bIx8zEv0pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompts** are predefined templates or workflows that guide the interaction between the user, the AI model, and the Server's capabilities:\n",
        "- **Control** - Prompts are **user-controlled**, often presented as options in the **Host** application's UI.\n",
        "- **Purpose** - They structure interactions for optimal use of available **Tools** and **Resources**.\n",
        "- **Selection** - Users typically select a prompt before the AI models begin processing, setting context for the interaction.\n",
        "- **Use Cases** - Common workflows, specialized task templates, guided interactions.\n",
        "\n",
        "\n",
        "\n",
        "Example: A prompt template for generating a code review:\n",
        "\n",
        "In Python\n",
        "```python\n",
        "def code_review(code: str, language: str) -> list:\n",
        "    \"\"\"Generate a code review for the provided code snippet.\"\"\"\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"You are a code reviewer examining {language} code. Provide a detailed review highlighting best practices, potential issues, and suggestions for improvement.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Please review this {language} code:\\n\\n```{language}\\n{code}\\n```\"\n",
        "        {\n",
        "    ]\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "In JavaScript\n",
        "```javascript\n",
        "function codeReview(code, language) {\n",
        "    return [\n",
        "        {\n",
        "            role: 'system',\n",
        "            content: `You are a code reviewer examining ${language} code. Provide a detailed review highlighting best practices, potential issues, and suggestions for improvement.`\n",
        "        },\n",
        "        {\n",
        "            role: 'user',\n",
        "            content: `Please review this ${language} code:\\n\\n\\`\\`\\`${language}\\n${code}\\n\\`\\`\\``\n",
        "        }\n",
        "    ];\n",
        "}\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "oej13GQSv2m6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling"
      ],
      "metadata": {
        "id": "PVinA1yKw35E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sampling** allows **Servers** to request the **Client** (specifically, thoe **Host** application) to perform LLM interactions:\n",
        "- **Control** - Sampling is **server-initiated** but requires Client/Host facilitation.\n",
        "- **Purpose** - It enables server-driven agentic behaviors and potentially recursive or multi-step interactions.\n",
        "- **Safety** - Like Tools, sampling operations typically require user approval.\n",
        "- **Use cases** - Complex multi-step tasks, autonomous agent workflows, interactive processes.\n",
        "\n",
        "\n",
        "Example: A Server might request the Client to analyze data it has processed:\n",
        "\n",
        "In Python\n",
        "```python\n",
        "def request_sampling(messages, system_prompt=None, include_context=\"none\"):\n",
        "    \"\"\"Request LLM sampling from the client.\"\"\"\n",
        "    # In real implementation, this would send a request to the client\n",
        "    return {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"Analysis of the provided data...\"\n",
        "    }\n",
        "```\n",
        "\n",
        "\n",
        "In JavaScript\n",
        "```javascript\n",
        "function requestSampling(messages, systemPrompt = null, includeContext = \"none\") {\n",
        "    // In real implementation, this would send a request to the client\n",
        "    return {\n",
        "        role: \"assistant\",\n",
        "        content: \"Analysis of the provided data...\"\n",
        "    };\n",
        "}\n",
        "\n",
        "function handleSamplingRequest(request) {\n",
        "    const { messages, systemPrompt, includeContext } = request;\n",
        "\n",
        "    return {\n",
        "        role: 'assistant',\n",
        "        content: 'Response to the sampling request...'\n",
        "    };\n",
        "}    \n",
        "```\n",
        "\n",
        "\n",
        "The sampling flow follows the following steps:\n",
        "1. Server sends a `sampling/createMessaage` request to the Client\n",
        "2. Client reviews the request and can modify it\n",
        "3. Client samples from an LLM\n",
        "4. Client reviews the completion\n",
        "5. Client returns the result to the Server\n",
        "\n",
        "\n",
        "NOTE: **This human-in-the-loop design ensures users maintain control over what the LLM sees and generates. When implementing sampling, it is important to provide clear, well-structured prompts and include relevant context.**"
      ],
      "metadata": {
        "id": "I5Hkfx1mKVxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How These Capabilities Work Together"
      ],
      "metadata": {
        "id": "R0joOJpIMRTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Capability | Controlled By | Direction | Side Effects | Approval Needed | Typical Use Cases |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| Tools | Model (LLM) | Client -> Server | Yes (potentially) | Yes | Actions, API calls, data manipulation |\n",
        "| Resources | Application | Client -> Server | No (read-only) | Typically no | Data retrieval, context gathering |\n",
        "| Prompts | User | Server -> Client | No | No (selected by user) | Guided workflows, specialized templates |\n",
        "| Sampling | Server | Server -> Client -> Server | Indirectly | Yes | Multi-step tasks, agentic behaviors |\n",
        "\n",
        "\n",
        "- A user might select a **Prompt** to start a specialized workflow\n",
        "- The Prompt might include context from **Resources**\n",
        "- During processing, the AI model might call **Tools** to perform specific actions\n",
        "- For complex operations, the Server might use **Sampling** to request additional LLM processing"
      ],
      "metadata": {
        "id": "iiE_avAnMW1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discoery Process"
      ],
      "metadata": {
        "id": "B2ZlxcyUNT0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When a Client connects to a Server, it can query the available Tools, Resources, and Prompts through specific list methods:\n",
        "- `tools/list` - Discover available Tools\n",
        "- `resources/list` - Discover available Resources\n",
        "- `prompts/list` - Discover available Prompts\n",
        "\n",
        "This dynamic discovery mechanism allows Clients to adapt to the specific capabilities each Server offers without requiring hardcoded knowledge of the Serverâ€™s functionality."
      ],
      "metadata": {
        "id": "k1DwL4cpNW8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MCP SDK"
      ],
      "metadata": {
        "id": "LBHGJgqQNoia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Model Context Protocol provides official SDKs for both JavaScript, Python, and other languages. which makes it easy to implement MCP clients and servers in our applications.\n",
        "\n",
        "\n",
        "Both SDKs provides similar core functionality, following the MCP protocol specification we discussed in the previous section so that they can handle:\n",
        "- Protocol-level communication\n",
        "- Capability registration and discovery\n",
        "- Message serialization/deserialziation\n",
        "- Conection management\n",
        "- Error handling"
      ],
      "metadata": {
        "id": "nzXWwx_4NqZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Core Primitives Implementation"
      ],
      "metadata": {
        "id": "oLKrfi2zOnuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For [Python SDK](https://github.com/modelcontextprotocol/python-sdk), make sure to install the package first:"
      ],
      "metadata": {
        "id": "FwRSO4MCOr5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"mcp[cli]\""
      ],
      "metadata": {
        "id": "aQU8GUb1CyMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOFfrddU-o2E"
      },
      "outputs": [],
      "source": [
        "# Python Script for server.py\n",
        "\n",
        "from mcp.server.fastmcp import FastMCP\n",
        "\n",
        "# Create an MCP server\n",
        "mcp = FastMCP(\"Weather Service\")\n",
        "\n",
        "\n",
        "@mcp.tools()\n",
        "def get_weather(location: str) -> str:\n",
        "    \"\"\"Get the current weather for a specified location.\"\"\"\n",
        "    return f\"Weather in {location}: Sunny, 90 degrees\"\n",
        "\n",
        "\n",
        "@mcp.resource(\"weather://{location}\")\n",
        "def weather_resource(location: str) -> str:\n",
        "    \"\"\"Provide weather data as a resource.\"\"\"\n",
        "    return f\"Weather data for {location}: Sunny, 90 degrees.\"\n",
        "\n",
        "\n",
        "@mcp.prompts()\n",
        "def weather_report(location: str) -> str:\n",
        "    \"\"\"Create a weather report prompt.\"\"\"\n",
        "    return f\"You are a weather reporter. Weather report for {location}?\"\n",
        "\n",
        "\n",
        "# Run the server\n",
        "if __name__ == \"__main__\":\n",
        "    mcp.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we saved this as a standalone `server.py` file, we can start it by running the server script:\n",
        "```bash\n",
        "mcp dev server.py\n",
        "```\n",
        "\n",
        "This will initialize a development server running the file `server.py` and log the following output:\n",
        "```bash\n",
        "Starting MCP inspector...\n",
        "âš™ï¸ Proxy server listening on port 6277\n",
        "Spawned stdio transport\n",
        "Connected MCP client to backing server transport\n",
        "Created web app transport\n",
        "Set up MCP proxy\n",
        "ðŸ” MCP Inspector is up and running at http://127.0.0.1:6274 ðŸš€\n",
        "```\n",
        "\n",
        "We can open the MCP inspector at http://127.0.0.1:6274 to see the server's capability and interact with them."
      ],
      "metadata": {
        "id": "VVg9N_JGPknq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For JavaScript, we need to install\n",
        "```bash\n",
        "npm install @modelcontextprotocol/sdk\n",
        "```\n",
        "\n",
        "and then implement the following script\n",
        "```javascript\n",
        "import { McpServer, ResourceTemplate } from \"@modelcontextprotocol/sdk/server/mcp.js\";\n",
        "import { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\n",
        "import { z } from \"zod\";\n",
        "\n",
        "// Create an MCP server\n",
        "const server = new McpServer({\n",
        "    name: \"Weather Service\",\n",
        "    version: \"1.0.0\"\n",
        "});\n",
        "\n",
        "// Tool implementation\n",
        "server.tool(\"get_weather\",\n",
        "    { location: z.string() },\n",
        "    async ({ location }) => ({\n",
        "        content: [{\n",
        "            type: \"text\",\n",
        "            text: `Weather in ${location}: Sunny, 72Â°F`\n",
        "        }]\n",
        "    })\n",
        ");\n",
        "\n",
        "// Resource implementation\n",
        "server.resource(\n",
        "    \"weather\",\n",
        "    new ResourceTemplate(\"weather://{location}\", { list: undefined }),\n",
        "    async (uri, { location }) => ({\n",
        "        contents: [{\n",
        "            uri: uri.href,\n",
        "            text: `Weather data for ${location}: Sunny, 72Â°F`\n",
        "        }]\n",
        "    })\n",
        ");\n",
        "\n",
        "// Prompt implementation\n",
        "server.prompt(\n",
        "    \"weather_report\",\n",
        "    { location: z.string() },\n",
        "    async ({ location }) => ({\n",
        "        messages: [\n",
        "            {\n",
        "                role: \"assistant\",\n",
        "                content: {\n",
        "                    type: \"text\",\n",
        "                    text: \"You are a weather reporter.\"\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                role: \"user\",\n",
        "                content: {\n",
        "                    type: \"text\",\n",
        "                    text: `Weather report for ${location}?`\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    })\n",
        ");\n",
        "\n",
        "// Run the server\n",
        "const transport = new StdioServerTransport();\n",
        "await server.connect(transport);\n",
        "```"
      ],
      "metadata": {
        "id": "XfYLy2DKQF6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MCP Clients"
      ],
      "metadata": {
        "id": "NNxRDR1RQTgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MCP Clients act as the bridge between AI applications (Hosts) and external capabilities provided by MCP Servers.\n",
        "\n",
        "For example, Anthropic's Claude Desktop is an MCP Client, providing integration with various MCP Servers.\n",
        "\n",
        "Cursor's MCP Client enables AI-powered coding assistance through direct integration with code editing capabilities. It supports multiple MCP Server connections and provides real-time tool invocation during coding."
      ],
      "metadata": {
        "id": "29NCgAB1zds6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuring MCP Clients"
      ],
      "metadata": {
        "id": "Rav_4uc20LUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MCP Hosts use configuration files to manage server connections. These files define which servers are available and how to connect to them.\n",
        "\n",
        "The standard configuration file for MCP is named `mcp.json`. The basic structure of `mcp.json` looks like:\n",
        "```json\n",
        "{\n",
        "    \"servers\": [\n",
        "        {\n",
        "            \"name\": \"Server Name\",\n",
        "            \"transport\": {\n",
        "                \"type\": \"stdio|sse\",\n",
        "                // Transport-specific configuration\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "```\n",
        "Here we have a single server with a name and a transport type. The transport type is either `stdio` or `sse`."
      ],
      "metadata": {
        "id": "v64esgQ10PTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configuration for stdio transfport"
      ],
      "metadata": {
        "id": "5DiAON3z0z4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For local servers using stdio transport, the configuration includes the command and arguments to launch the server process:\n",
        "```json\n",
        "{\n",
        "    \"server\": [\n",
        "        {\n",
        "            \"name\": \"File Explorer\",\n",
        "            \"transport\": {\n",
        "                \"type\": \"stdio\",\n",
        "                \"command\": \"python\",\n",
        "                \"args\": [\"/path/to/file_explorer_server.py\"]\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "```\n",
        "Here we have a server called `\"File Explorer\"` that is a local script."
      ],
      "metadata": {
        "id": "rk4A56OP04Rp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configuration for HTTP+SSE transport"
      ],
      "metadata": {
        "id": "QZDm4maE1PrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For remote servers using HTTP+SSE transport, the configuration includes the server URL:\n",
        "```json\n",
        "{\n",
        "    \"servers\": [\n",
        "        {\n",
        "            \"name\": \"Remote API Server\",\n",
        "            \"transport\": {\n",
        "                \"type\": \"sse\",\n",
        "                \"url\": \"https://example.com/mcp-server\"\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "Go-nlb-T1TeV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Environment variables in configuration"
      ],
      "metadata": {
        "id": "giCOrgAW1iml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment variables can be passed to server processes using the `env` field.\n",
        "\n",
        "In Python, we can use the `os` module to access environment variables:\n",
        "```python\n",
        "import os\n",
        "\n",
        "# Access environment variables\n",
        "github_token = os.environ.get(\"GITHUB_TOKEN\")\n",
        "if not github_token:\n",
        "    raise ValueError(\"GITHUB_TOKEN environment variable is required\")\n",
        "\n",
        "# Use the token in our server code\n",
        "def make_github_request():\n",
        "    headers = {\"Authorization\": f\"Bearer {github_tokne}\"}\n",
        "    # ... rest of code\n",
        "```\n",
        "\n",
        "In JavaScript, we will use the `process.env` object to access environment variables:\n",
        "```javascript\n",
        "// Access environment variables\n",
        "const githubToken = process.env.GITHUB_TOKEN;\n",
        "if (!githubToken) {\n",
        "    throw new Error(\"GITHUB_TOKEN environment variable is required\");\n",
        "}\n",
        "\n",
        "// Use the token in your server code\n",
        "function makeGithubRequest() {\n",
        "    const headers = { \"Authorization\": `Bearer ${githubToken}` };\n",
        "    // ... rest of your code\n",
        "}\n",
        "```\n",
        "\n",
        "Next, we can implement the configuration `mcp.json` file:\n",
        "```json\n",
        "{\n",
        "    \"servers\": [\n",
        "        {\n",
        "            \"name\": \"GitHub API\",\n",
        "            \"transport\": {\n",
        "                \"type\": \"stdio\",\n",
        "                \"command\": \"python\",\n",
        "                \"args\": [\"/path/to/github.server.py\"]\n",
        "                \"env\": {\n",
        "                    \"GITHUB_TOKEN\": \"our_github_token\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "gLopXszq1lcp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configuration examples"
      ],
      "metadata": {
        "id": "91hBh2no28f_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In local server configuration, we have a local server that is a Python script which could be a file explorer or a code editor.\n",
        "```json\n",
        "{\n",
        "  \"servers\": [\n",
        "    {\n",
        "      \"name\": \"File Explorer\",\n",
        "      \"transport\": {\n",
        "        \"type\": \"stdio\",\n",
        "        \"command\": \"python\",\n",
        "        \"args\": [\"/path/to/file_explorer_server.py\"]\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "In remote server configuration, we have a remote server that is a weather API.\n",
        "```json\n",
        "{\n",
        "  \"servers\": [\n",
        "    {\n",
        "      \"name\": \"Weather API\",\n",
        "      \"transport\": {\n",
        "        \"type\": \"sse\",\n",
        "        \"url\": \"https://example.com/mcp-server\"\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "zW4Hcial3A7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Clients"
      ],
      "metadata": {
        "id": "fmbL5j343UpW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In `smolagents`, we can use the `ToolCollection` class to automatically discover and register tools from an MCP server. This is done by passing the `StdioServerParameter` or `SSEServerParameters` to the `ToolCollection.from_mcp` method."
      ],
      "metadata": {
        "id": "WN1frBTu3X8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import ToolCollection, CodeAgent\n",
        "from mcp.client.stdio import StdioServerParameters\n",
        "\n",
        "server_parameters = StdioServerParameters(\n",
        "    command='uv',\n",
        "    args=['run', 'server.py']\n",
        ")\n",
        "\n",
        "with ToolCollection.from_mcp(server_parameters, trust_remote_code=True) as tools:\n",
        "    print('\\n'.join(f\"{t.name}: {t.description}\" for t in tools))"
      ],
      "metadata": {
        "id": "Ou24HoxZQUkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also connect to an MCP server that is hosted on a remote machine. In this case, we can pass the `SSEServerParameters` to the `ToolCollection.from_mcp` method."
      ],
      "metadata": {
        "id": "bCcZflPa3-CU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents.mcp_client import MCPClient\n",
        "\n",
        "with MCPClient(\n",
        "    {'url': \"https://abidlabs-mcp-tools.hf.space/gradio_api/mcp/sse\"}\n",
        ") as tools:\n",
        "    # Tools from the remote server are available\n",
        "    print('\\n'.join(f\"{t.name}: {t.description}\" for t in tools))"
      ],
      "metadata": {
        "id": "QxQLoj6t4GRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can use the MCP Client in a code agent:"
      ],
      "metadata": {
        "id": "gqrvBh-V4bhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import ToolCollection, CodeAgent, InferenceClientModel\n",
        "from mcp.client.stdio import StdioServerParameters\n",
        "\n",
        "model = InferenceClientModel()\n",
        "\n",
        "server_parameters = StdioServerParameters(\n",
        "    command='uv',\n",
        "    args=['run', 'server.py']\n",
        ")\n",
        "\n",
        "with ToolCollection.from_mcp(\n",
        "    server_parameters,\n",
        "    trust_remote_code=True\n",
        ") as tool_collection:\n",
        "    agent = CodeAgent(\n",
        "        model=model,\n",
        "        tools=[*tool_collection.tools],\n",
        "    )\n",
        "\n",
        "    agent.run(\"What is the weather in Tokyo?\")"
      ],
      "metadata": {
        "id": "zfNEwAoQ4eEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also connect to an MCP packages. For example, to connect to the `pubmedmcp` package:"
      ],
      "metadata": {
        "id": "94IHpZUk5Etn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import ToolCollection, CodeAgent\n",
        "from mcp import StdioServerParameters\n",
        "\n",
        "server_parameters = StdioServerParameters(\n",
        "    command='uv',\n",
        "    args=['--quest', 'pubmedmcp@0.1.3'],\n",
        "    env={'UV_PYTHON': \"3.12\", **os.environ}\n",
        ")\n",
        "\n",
        "\n",
        "with ToolCollection.from_mcp(\n",
        "    server_parameters,\n",
        "    trust_remote_code=True\n",
        ") as tool_collection:\n",
        "    agent = CodeAgent(\n",
        "        tools=[*tool_collection.tools],\n",
        "        add_base_tools=True\n",
        "    )\n",
        "\n",
        "    agent.run(\"Please find a remedy for hangover.\")"
      ],
      "metadata": {
        "id": "UOSMJ-bY5K_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio MCP Integration"
      ],
      "metadata": {
        "id": "IaJD2zOm5w48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio allows developers to create UIs for their models with just a few of lines of Python code and useful for\n",
        "- creating demos and prototypes\n",
        "- sharing models with non-technical users\n",
        "- testing and debugging moel behavior\n",
        "\n",
        "With addition of MCP support, Gradio offers a straightforward way to expose AI model capabilities through the standardized MCP protocol."
      ],
      "metadata": {
        "id": "_mOtp8fy6VeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"gradio[mcp]\""
      ],
      "metadata": {
        "id": "4RuJngr65y1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also need an LLM application that supports tool calling using the MCP protocol, such as Cursor (known as MCP Hosts)."
      ],
      "metadata": {
        "id": "A7i4PHzlInPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an MCP Server with Gradio"
      ],
      "metadata": {
        "id": "FHuei25QIv2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# demo.py\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def letter_counter(word: str, letter: str) -> int:\n",
        "    \"\"\"Count the number of occurrences of a letter in a word or text.\n",
        "\n",
        "    Args:\n",
        "        word (str): The input text to search through\n",
        "        letter (str): The letter to search for\n",
        "\n",
        "    Returns:\n",
        "        int: The number of times the letter appears in the text\n",
        "    \"\"\"\n",
        "    word = word.lower()\n",
        "    letter = letter.lower()\n",
        "    count = word.count(letter)\n",
        "    return count\n",
        "\n",
        "\n",
        "# Create a standard Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=letter_counter,\n",
        "    inputs=['textbox', 'textbox'],\n",
        "    outputs='number',\n",
        "    title='Letter Counter',\n",
        "    description=\"Enter text and a letter to count how many times the letter appears in the text.\"\n",
        ")\n",
        "\n",
        "# Launch both the Gradio web interface and the MCP server\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(mcp_server=True)"
      ],
      "metadata": {
        "id": "SiY-UVL1Iy53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our letter counter function is now accessible through\n",
        "- traditional Gradio web interface for direct human interaction,\n",
        "- MCP Server that can be connected to compatible clients\n",
        "    - the MCP server is accessible at: `http://your-server:port/gradio_api/mcp/sse`"
      ],
      "metadata": {
        "id": "UCymQUnvJjLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradio <==> MCP Integration\n",
        "\n",
        "- **Tool conversion** - Each API endpoint in our Gradio app is automatically converted into an MCP tool with a corresponding name, description, and input schema. To view the tools and schemas, we can visit `http://your-server:port/gradio_api/mcp/schema` or go to the \"View API\" link in the footer of our Gradio app.\n",
        "\n",
        "- **Environment variable support** - There are two ways to enable the MCP server functionality:\n",
        "    - using the `mcp_server` parameter in `launch()`:\n",
        "    ```python\n",
        "    demo.launch(mcp_server=True)\n",
        "    ```\n",
        "    - using environment variables:\n",
        "    ```bash\n",
        "    export GRADIO_MCP_SERVER=True\n",
        "    ```\n",
        "\n",
        "- **File handling** - The server automatically handles file data conversions, including:\n",
        "    - converting base64-encoded strings to file data\n",
        "    - processing image files and returning them in the correct format\n",
        "    - managing temporary file storage\n",
        "\n",
        "- **Hosted MCP servers on HF Spaces** - We can publish our Gradio app for free on HuggingFace Spaces, which allows us to have a free hosted MCP server."
      ],
      "metadata": {
        "id": "AYSfLpBpJ2Vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Troublshooting\n",
        "\n",
        "- **Type hints and docstring** - Ensure to provide type hints and valid docstrings for our functions. The docstring should include an \"Args:\" block with indented parameter names.\n",
        "- **String inputs** - Accept input arguments as `str` and convert them to desired type inside the function.\n",
        "- **SSE Support** - Some MCP Hosts do not support SSE-based MCP Servers, so we need to use `mcp-remote`:\n",
        "    ```json\n",
        "    {\n",
        "        \"mcpServers\": {\n",
        "            \"gradio\": {\n",
        "                \"command\": \"npx\",\n",
        "                \"args: [\n",
        "                    \"mcp_remote\",\n",
        "                    \"http://our-server:port/gradio_api/mcp/sse\"\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    ```\n",
        "- **Restart** - try restrating both our MCP Client and Server if encoutering connection issues."
      ],
      "metadata": {
        "id": "hx8tNv_XK9_b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6iHRYK1mLwSB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}