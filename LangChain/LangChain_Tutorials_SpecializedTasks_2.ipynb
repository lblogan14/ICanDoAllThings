{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34646,
     "status": "ok",
     "timestamp": 1730302323421,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "VQLfD7q38RUr",
    "outputId": "9fb413a8-3c99-46ce-a652-fe874fba880a"
   },
   "outputs": [],
   "source": [
    "!pip install -qU langchain langchain_experimental langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhVmkj5k8XvM"
   },
   "source": [
    "# Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmWlRFka92wV"
   },
   "source": [
    "Synthetic data is used to simulate real data without compromising privacy or encountering real-world limitations. However, synthetic data should be used carefully, as it may not always capture real-world complexities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7Rvt0b2-GSb"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730302323422,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "E6X-a14V-EwN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "langchain_api_key = 'your_langchain_api_key_here'  # Replace with your actual LangChain API key\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_API_KEY'] = langchain_api_key\n",
    "\n",
    "openai_api_key = 'your_openai_api_key_here'  # Replace with your actual OpenAI API key\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3674,
     "status": "ok",
     "timestamp": 1730302327093,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "l40x0mY3-PY9"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_experimental.tabular_synthetic_data.openai import (\n",
    "    OPENAI_TEMPLATE,\n",
    "    create_openai_data_generator,\n",
    ")\n",
    "from langchain_experimental.tabular_synthetic_data.prompts import (\n",
    "    SYNTHETIC_FEW_SHOT_PREFIX,\n",
    "    SYNTHETIC_FEW_SHOT_SUFFIX,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSWZ3ayfDaCZ"
   },
   "source": [
    "## 1.Define Our Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWfaxxXkDdjS"
   },
   "source": [
    "Every dataset has a structure or a \"schema\". The `MedicalBilling` class below serves as our schema for the synthetic data. By defining this, we inform our synthetic data generator about the shape and nature of data we execpt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1730302410031,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "bnq9cRhmDZTH"
   },
   "outputs": [],
   "source": [
    "class MedicalBilling(BaseModel):\n",
    "    patient_id: int\n",
    "    patient_name: str\n",
    "    diagnosis_code: str\n",
    "    procedure_code: str\n",
    "    total_charge: float\n",
    "    insurance_claim_amount: float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlFRs36RD4Ka"
   },
   "source": [
    "## 2.Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRS7lUz-D5y3"
   },
   "source": [
    "To guide the synthetic data generator, it is useful to provide it with a few real-world-like examples. These examples serve as a \"seed\" - they are representative of the kind of data we want, and the generator will use them to create data that looks similar to our expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1730302538467,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "OK6sx-DCD3wB"
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        'example': \"\"\"Patient ID: 123456, Patient Name: John Doe, Diagnosis Code:\n",
    "        J20.9, Procedure Code: 99203, Total Charge: $500, Insurance Claim Amount: $350\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"example\": \"\"\"Patient ID: 789012, Patient Name: Johnson Smith, Diagnosis\n",
    "        Code: M54.5, Procedure Code: 99213, Total Charge: $150, Insurance Claim Amount: $120\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"example\": \"\"\"Patient ID: 345678, Patient Name: Emily Stone, Diagnosis Code:\n",
    "        E11.9, Procedure Code: 99214, Total Charge: $300, Insurance Claim Amount: $250\"\"\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QW6NswzyEXpq"
   },
   "source": [
    "## 3.Craft a Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoPWtn3YEalY"
   },
   "source": [
    "The generator does not know how to create our data; we need to guide it by creating a prompt template. This template helps instruct the underlying language model on how to produce synthetic data in the desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1730302698663,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "HNAG_C1jEXHW"
   },
   "outputs": [],
   "source": [
    "OPENAI_TEMPLATE = PromptTemplate(input_variables=['example'],\n",
    "                                 template='{example}')\n",
    "\n",
    "prompt_template = FewShotPromptTemplate(\n",
    "    prefix=SYNTHETIC_FEW_SHOT_PREFIX,\n",
    "    suffix=SYNTHETIC_FEW_SHOT_SUFFIX,\n",
    "    examples=examples,\n",
    "    input_variables=['subject', 'extra'],\n",
    "    example_prompt=OPENAI_TEMPLATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVMWAqTRE-wb"
   },
   "source": [
    "The `FewShotPromptTemplate` includes:\n",
    "* `prefix` and `suffix`: contain guiding context or instructions.\n",
    "* `examples`: sample data we defined earlier.\n",
    "* `input_variables`: these variables (`'subject'`, `'extra'`) are placeholders we can dynamically fill later.\n",
    "* `example_prompt`: prompt template is the format we want each example row to take in our prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_v2ZjRcNFV5a"
   },
   "source": [
    "## 4.Creating the Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXs-kAH4FYB2"
   },
   "source": [
    "With the schema and the prompt ready, we can create the data generator. This object knows how to communicate with the underlying language model to generate synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 867,
     "status": "ok",
     "timestamp": 1730302874827,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "Q-emx_luE-OJ"
   },
   "outputs": [],
   "source": [
    "synthetic_data_generator = create_openai_data_generator(\n",
    "    output_schema=MedicalBilling,\n",
    "    llm=ChatOpenAI(model='gpt-3.5-turbo', temperature=1),\n",
    "    prompt=prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWOKYm4yFphd"
   },
   "source": [
    "## 5.Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 11131,
     "status": "ok",
     "timestamp": 1730302968411,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "Scc2VY2FFpDa"
   },
   "outputs": [],
   "source": [
    "synthetic_results = synthetic_data_generator.generate(\n",
    "    subject='medical_billing',\n",
    "    extra='the name must be chosen at random. Make it something you would not normally choose.',\n",
    "    runs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGaQvpM5F_A-"
   },
   "source": [
    "The output will be a list of the `MedicalBilling` pydantic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1730302981848,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "ZzTTFeQZF9ZV",
    "outputId": "285a5ad5-c879-4fcd-95b2-14eaa8e437a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MedicalBilling(patient_id=987654, patient_name='Samantha Black', diagnosis_code='K29.7', procedure_code='99204', total_charge=400.0, insurance_claim_amount=300.0),\n",
       " MedicalBilling(patient_id=123456, patient_name='Xavier Brown', diagnosis_code='L13.9', procedure_code='99203', total_charge=250.0, insurance_claim_amount=200.0),\n",
       " MedicalBilling(patient_id=456789, patient_name='Jennifer Smith', diagnosis_code='M25.5', procedure_code='99213', total_charge=350.0, insurance_claim_amount=275.0),\n",
       " MedicalBilling(patient_id=789012, patient_name='Ezekiel Jackson', diagnosis_code='F41.1', procedure_code='99214', total_charge=500.0, insurance_claim_amount=400.0),\n",
       " MedicalBilling(patient_id=987654, patient_name='Aurora Patel', diagnosis_code='I10', procedure_code='99204', total_charge=450.0, insurance_claim_amount=350.0),\n",
       " MedicalBilling(patient_id=123456, patient_name='Xander Thompson', diagnosis_code='K22.3', procedure_code='99212', total_charge=300.0, insurance_claim_amount=240.0),\n",
       " MedicalBilling(patient_id=246801, patient_name=\"Beatrice O'Malley\", diagnosis_code='R03.0', procedure_code='99213', total_charge=400.0, insurance_claim_amount=320.0),\n",
       " MedicalBilling(patient_id=135792, patient_name='Octavius Fernandez', diagnosis_code='E11.9', procedure_code='99214', total_charge=500.0, insurance_claim_amount=400.0),\n",
       " MedicalBilling(patient_id=987654, patient_name='Lulu Patterson', diagnosis_code='F32.9', procedure_code='99215', total_charge=600.0, insurance_claim_amount=480.0),\n",
       " MedicalBilling(patient_id=123456, patient_name=\"Octavius O'Malley\", diagnosis_code='I10', procedure_code='99212', total_charge=300.0, insurance_claim_amount=240.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y49wZM32GIYo"
   },
   "source": [
    "## Other implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1730303035876,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "jgg2OZFyGJzP"
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.synthetic_data import (\n",
    "    DatasetGenerator,\n",
    "    create_data_generation_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1730303076391,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "hQoVwfdrGQi0"
   },
   "outputs": [],
   "source": [
    "# LLM\n",
    "model = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.7)\n",
    "chain = create_data_generation_chain(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 954,
     "status": "ok",
     "timestamp": 1730303101227,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "WBXRIsK0GaZx",
    "outputId": "3d06b52a-e5a9-4bff-eef9-8d525ad94e40"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-bb653fba301d>:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain({'fields': ['blue', 'yellow'], 'preferences': {}})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fields': ['blue', 'yellow'],\n",
       " 'preferences': {},\n",
       " 'text': 'The vibrant blue sky contrasted beautifully against the golden yellow sunflower fields, creating a stunning and picturesque scene that captured the essence of a perfect summer day.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'fields': ['blue', 'yellow'], 'preferences': {}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 792,
     "status": "ok",
     "timestamp": 1730303112504,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "27ChRISZGgTd",
    "outputId": "029ef077-db33-45e8-887e-e0f35a4b63cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': {'colors': ['blue', 'yellow']},\n",
       " 'preferences': {'style': 'Make it in a style of a weather forecast.'},\n",
       " 'text': \"In today's weather forecast, skies will be a stunning blend of blue and yellow, creating a vibrant and picturesque horizon for all to enjoy.\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\n",
    "    {\n",
    "        \"fields\": {\"colors\": [\"blue\", \"yellow\"]},\n",
    "        \"preferences\": {\"style\": \"Make it in a style of a weather forecast.\"},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 934,
     "status": "ok",
     "timestamp": 1730303123379,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "a4Is9h42GjGF",
    "outputId": "1f6e557c-1489-4372-b15d-6bfe02ed6884"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': {'actor': 'Tom Hanks', 'movies': ['Forrest Gump', 'Green Mile']},\n",
       " 'preferences': None,\n",
       " 'text': 'Tom Hanks, known for his iconic roles in movies such as \"Forrest Gump\" and \"Green Mile\", has captivated audiences worldwide with his exceptional talent and versatility as an actor.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\n",
    "    {\n",
    "        \"fields\": {\"actor\": \"Tom Hanks\", \"movies\": [\"Forrest Gump\", \"Green Mile\"]},\n",
    "        \"preferences\": None,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1318,
     "status": "ok",
     "timestamp": 1730303128365,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "fN3ScWlTGltv",
    "outputId": "8beefe5a-90f0-41af-c31b-6a73340a308e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': [{'actor': 'Tom Hanks', 'movies': ['Forrest Gump', 'Green Mile']},\n",
       "  {'actor': 'Mads Mikkelsen', 'movies': ['Hannibal', 'Another round']}],\n",
       " 'preferences': {'minimum_length': 200, 'style': 'gossip'},\n",
       " 'text': 'Rumor has it that Tom Hanks, known for his iconic roles in \"Forrest Gump\" and \"Green Mile\", has been spotted having lunch with the charming and enigmatic Mads Mikkelsen, star of \"Hannibal\" and \"Another Round\", sparking speculation of a potential collaboration between the two talented actors.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\n",
    "    {\n",
    "        \"fields\": [\n",
    "            {\"actor\": \"Tom Hanks\", \"movies\": [\"Forrest Gump\", \"Green Mile\"]},\n",
    "            {\"actor\": \"Mads Mikkelsen\", \"movies\": [\"Hannibal\", \"Another round\"]},\n",
    "        ],\n",
    "        \"preferences\": {\"minimum_length\": 200, \"style\": \"gossip\"},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCMAqaUnGsZc"
   },
   "source": [
    "### Generating exemplary dataset for extraction benchmarking purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2447,
     "status": "ok",
     "timestamp": 1730303251836,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "9XeOD0IIGm1t",
    "outputId": "fec572c7-7de0-468f-ebc2-cb93d2ef63c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fields': {'Actor': 'Tom Hanks',\n",
       "   'Film': ['Forrest Gump',\n",
       "    'Saving Private Ryan',\n",
       "    'The Green Mile',\n",
       "    'Toy Story',\n",
       "    'Catch Me If You Can']},\n",
       "  'preferences': {'style': 'informal', 'minimal length': 500},\n",
       "  'text': 'Tom Hanks, known for his iconic roles in films such as Forrest Gump, Saving Private Ryan, The Green Mile, Toy Story, and Catch Me If You Can, has solidified himself as one of the most versatile and talented actors in Hollywood.'},\n",
       " {'fields': {'Actor': 'Tom Hardy',\n",
       "   'Film': ['Inception',\n",
       "    'The Dark Knight Rises',\n",
       "    'Mad Max: Fury Road',\n",
       "    'The Revenant',\n",
       "    'Dunkirk']},\n",
       "  'preferences': {'style': 'informal', 'minimal length': 500},\n",
       "  'text': 'Tom Hardy, known for his versatile performances, has showcased his talent in a variety of blockbuster films such as \"Inception,\" \"The Dark Knight Rises,\" \"Mad Max: Fury Road,\" \"The Revenant,\" and \"Dunkirk.\" His ability to seamlessly embody complex characters across different genres has solidified his reputation as one of the most captivating actors in Hollywood today.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = [\n",
    "    {\n",
    "        \"Actor\": \"Tom Hanks\",\n",
    "        \"Film\": [\n",
    "            \"Forrest Gump\",\n",
    "            \"Saving Private Ryan\",\n",
    "            \"The Green Mile\",\n",
    "            \"Toy Story\",\n",
    "            \"Catch Me If You Can\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"Actor\": \"Tom Hardy\",\n",
    "        \"Film\": [\n",
    "            \"Inception\",\n",
    "            \"The Dark Knight Rises\",\n",
    "            \"Mad Max: Fury Road\",\n",
    "            \"The Revenant\",\n",
    "            \"Dunkirk\",\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "generator = DatasetGenerator(model,\n",
    "                             {'style': 'informal',\n",
    "                              'minimal length': 500})\n",
    "\n",
    "dataset = generator(inp)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uz69ZOKpHIP2"
   },
   "source": [
    "### Extraction from generated examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhinuJGTHLg6"
   },
   "source": [
    "We can extract output from this generated data and compare it with our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 128,
     "status": "ok",
     "timestamp": 1730303352254,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "ZCOZS__LHcz2"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.chains import create_extraction_chain_pydantic\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 153,
     "status": "ok",
     "timestamp": 1730303353979,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "kGREaqQFHEsK"
   },
   "outputs": [],
   "source": [
    "class Actor(BaseModel):\n",
    "    Actor: str = Field(description='name of an actor')\n",
    "    Film: List[str] = Field(description='list of names of films they starred in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Chxnp501Hhes"
   },
   "source": [
    "#### Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1384,
     "status": "ok",
     "timestamp": 1730303519581,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "8kdgz4UyHb0O",
    "outputId": "89f57966-971e-47da-f21c-dac18bf566f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(Actor='Tom Hanks', Film=['Forrest Gump', 'Saving Private Ryan', 'The Green Mile', 'Toy Story', 'Catch Me If You Can'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI()\n",
    "parser = PydanticOutputParser(pydantic_object=Actor)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Extract fields from a give ntext.\\n{format_instructions}\\n{text}\\n\",\n",
    "    input_variables=['text'],\n",
    "    partial_variables={'format_instructions': parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(text=dataset[0]['text'])\n",
    "output = llm(_input.to_string())\n",
    "\n",
    "parsed = parser.parse(output)\n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 161,
     "status": "ok",
     "timestamp": 1730303527520,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "aFGzV7vIH8ua",
    "outputId": "ebe30456-5634-4586-fee9-84dccd37395c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(parsed.Actor == inp[0][\"Actor\"]) & (parsed.Film == inp[0][\"Film\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GSb-N8AILKX"
   },
   "source": [
    "#### Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1073,
     "status": "ok",
     "timestamp": 1730303549371,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "9XMGY3jSIIkf",
    "outputId": "4e7ab908-2ec4-4871-b153-0c84bd559eb7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-768722092050>:1: LangChainDeprecationWarning: LangChain has introduced a method called `with_structured_output` thatis available on ChatModels capable of tool calling.You can read more about the method here: <https://python.langchain.com/docs/modules/model_io/chat/structured_output/>. Please follow our extraction use case documentation for more guidelineson how to do information extraction with LLMs.<https://python.langchain.com/docs/use_cases/extraction/>. If you notice other issues, please provide feedback here:<https://github.com/langchain-ai/langchain/discussions/18154>\n",
      "  extractor = create_extraction_chain_pydantic(pydantic_schema=Actor, llm=model)\n",
      "<ipython-input-24-768722092050>:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  extracted = extractor.run(dataset[1][\"text\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Actor(Actor='Tom Hardy', Film=['Inception', 'The Dark Knight Rises', 'Mad Max: Fury Road', 'The Revenant', 'Dunkirk'])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor = create_extraction_chain_pydantic(pydantic_schema=Actor, llm=model)\n",
    "extracted = extractor.run(dataset[1][\"text\"])\n",
    "extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 145,
     "status": "ok",
     "timestamp": 1730303552386,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "JZLWT_-hINrv",
    "outputId": "de2fc7f4-a07f-491c-9871-9dedbf22ea90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(extracted[0].Actor == inp[1][\"Actor\"]) & (extracted[0].Film == inp[1][\"Film\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMPppEDt6iYJWPXQtd0fLzM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
