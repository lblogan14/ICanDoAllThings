{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM8w68bpV+/+okzuCj2Mpcv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Multilingual Models for Inference"],"metadata":{"id":"JkEnN8_hAkyx"}},{"cell_type":"markdown","source":["## XLM"],"metadata":{"id":"4Zuy7WoUNz7Z"}},{"cell_type":"markdown","source":["**XLM** has many different checkpoints."],"metadata":{"id":"lLEqjegIN3dA"}},{"cell_type":"markdown","source":["### XLM with language embeddings"],"metadata":{"id":"3dgE5WlROAAz"}},{"cell_type":"markdown","source":["The following XLM models use language embeddings to specify the language used at inference:\n","* `FacebookAI/xlm-mlm-ende-1024` (Masked language modeling, English-German)\n","* `FacebookAI/xlm-mlm-enfr-1024` (Masked language modeling, English-French)\n","* `FacebookAI/xlm-mlm-enro-1024` (Masked language modeling, English-Romanian)\n","* `FacebookAI/xlm-mlm-xnli15-1024` (Masked language modeling, XNLI languages)\n","* `FacebookAI/xlm-mlm-tlm-xnli15-1024` (Masked language modeling + translation, XNLI languages)\n","* `FacebookAI/xlm-clm-enfr-1024` (Causal language modeling, English-French)\n","* `FacebookAI/xlm-clm-ende-1024` (Causal language modeling, English-German)\n","\n","Language embeddings are represented as a tensor of the same shape as the `input_ids` passed to the model. The values in these tensors depend on the language used and are identified by the tokenizer's `lang2id` and `id2lang` attributes.\n","\n","We will use `FacebookAI/xlm-clm-enfr-1024` as an example:"],"metadata":{"id":"wILCDKEnOINe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"77CCTp6aAfpl"},"outputs":[],"source":["import torch\n","from transformers import XLMTokenizer, XLMWithLMHeadModel\n","\n","tokenizer = XLMTokenizer.from_pretrained(\"facebook/xlm-clm-enfr-1024\")\n","model = XLMWithLMHeadModel.from_pretrained(\"facebook/xlm-clm-enfr-1024\")"]},{"cell_type":"markdown","source":["The `lang2id` attribute of the tokenizer displays the model''s languages and their ids:"],"metadata":{"id":"GSjwYhaAOyVg"}},{"cell_type":"code","source":["tokenizer.lang2id"],"metadata":{"id":"uYxAA67zO65d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = torch.tensor(\n","    [tokenizer.encode(\"Wikipedia was used to\")] # batch size of 1\n",")"],"metadata":{"id":"xIAgndkZO8g9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Set the language id as `\"en\"` and use it to define the language embeddings. The language embedding is a tensor filled with 0 since that is the language id for English. This tensor should be the same size as `input_ids`."],"metadata":{"id":"Zalft2eDPIGi"}},{"cell_type":"code","source":["language_id = tokenizer.lang2id['en']\n","langs = torch.tensor([language_id] * input_ids.shape[1])\n","# reshape it to be the size (batch_size, sequence_length)\n","langs = langs.view(1, -1)\n","\n","langs.size() == input_ids.size()"],"metadata":{"id":"Z11YK5_fPXSt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we can pass the `input_ids` and language embedding to the model:"],"metadata":{"id":"t1InYhe6PuHr"}},{"cell_type":"code","source":["outputs = model(input_ids, langs=langs)"],"metadata":{"id":"oBaXX5M5PyLJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### XLM without language embeddings"],"metadata":{"id":"RSCVa4quP-yY"}},{"cell_type":"markdown","source":["* `FacebookAI/xlm-mlm-17-1280` (Masked language modeling, 17 languages)\n","* `FacebookAI/xlm-mlm-100-1280` (Masked language modeling, 100 languages)\n","\n","These models are used for generic sentence representations, unlike the previous XLM checkpoints with language embeddings."],"metadata":{"id":"EoqXfAgAQEBR"}},{"cell_type":"markdown","source":["## BERT"],"metadata":{"id":"a69Y9telQOF8"}},{"cell_type":"markdown","source":["* `google-bert/bert-base-multilingual-uncased` (Masked language modeling + Next sentence prediction, 102 languages)\n","* `google-bert/bert-base-multilingual-cased` (Masked language modeling + Next sentence prediction, 104 languages)\n","\n","These models do not require language embeddings during inference. They should identify the language from the context and infer accordingly."],"metadata":{"id":"mM9IfBIGQQn6"}},{"cell_type":"markdown","source":["### XLM-RoBERTa"],"metadata":{"id":"R1ntid5VQc6m"}},{"cell_type":"markdown","source":["* `FacebookAI/xlm-roberta-base` (Masked language modeling, 100 languages)\n","* `FacebookAI/xlm-roberta-large` (Masked language modeling, 100 languages)\n","\n","XLM-RoBERTa was trained on 2.5TB of newly created and cleaned CommonCrawl data in 100 languages.. It provides strong gains over previously releated multilingual models like mBERT or XLM on downstream tasks like classification, sequence labeling, and question answering."],"metadata":{"id":"g1PFLOgQQfyA"}},{"cell_type":"markdown","source":["## M2M100"],"metadata":{"id":"XOfLO0xnQy-R"}},{"cell_type":"markdown","source":["* `facebook/m2m100_418M` (Translation)\n","* `facebook/m2m100_1.2B` (Translation)\n","\n","We will load the `facebook/m2m100_418M` checkpoint to translate from Chinese to English."],"metadata":{"id":"ZpnV83-ZQ22E"}},{"cell_type":"code","source":["from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n","\n","en_text = \"Do not meddle in the affairs of wizards, for they are subtle and quick to anger.\"\n","chinese_text = \"不要插手巫師的事務, 因為他們是微妙的, 很快就會發怒.\"\n","\n","tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\", src_lang=\"zh\")\n","model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")"],"metadata":{"id":"YjfjJYAoQCqN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_zh = tokenizer(chinese_text, return_tensors='pt')"],"metadata":{"id":"vd_5T7vLRCqT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["M2M100 forces the target language id as the first generated token to translate the target language. We can set the `forced_bos_token_id` to `en` in the `generate` method to translate to English:"],"metadata":{"id":"PmmC_6GSRGLu"}},{"cell_type":"code","source":["generated_tokens = model.generate(\n","    **encoded_zh,\n","    forced_bos_token_id=tokenizer.get_lang_id('en')\n",")\n","\n","tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"],"metadata":{"id":"MlIiFP5xRQeZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## MBart"],"metadata":{"id":"1fbWttfERcoa"}},{"cell_type":"markdown","source":["* `facebook/mbart-large-50-one-to-many-mmt` (One-to-many multilingual machine translation, 50 languages)\n","* `facebook/mbart-large-50-many-to-many-mmt` (Many-to-many multilingual machine translation, 50 languages)\n","* `facebook/mbart-large-50-many-to-one-mmt` (Many-to-one multilingual machine translation, 50 languages)\n","* `facebook/mbart-large-50` (Multilingual translation, 50 languages)\n","* `facebook/mbart-large-cc25`\n","\n","We will load the `facebook/mbart-large-50-many-to-many-mmt` to translate Finnish to English."],"metadata":{"id":"Q5G6BUQLRevu"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","en_text = \"Do not meddle in the affairs of wizards, for they are subtle and quick to anger.\"\n","fi_text = \"Älä sekaannu velhojen asioihin, sillä ne ovat hienovaraisia ja nopeasti vihaisia.\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\", src_lang=\"fi_FI\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")"],"metadata":{"id":"rn4RMj3cRdzV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_en = tokenizer(en_text, return_tensors=\"pt\")"],"metadata":{"id":"zVZngmzbRtba"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MBart forces the target language id as the first generated token to translate to the target language. We set the `forced_bos_token_id` to `en` in the `generate` method to translate to English:"],"metadata":{"id":"7Hp-7PNmRwIS"}},{"cell_type":"code","source":["generated_tokens = model.generate(\n","    **encoded_en,\n","    forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]\n",")\n","tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"],"metadata":{"id":"r_KE5KJdR7JI"},"execution_count":null,"outputs":[]}]}