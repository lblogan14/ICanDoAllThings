{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPTCpmwDWKBKBA1dddwYOdF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# LLM Gateway for PII Detection"],"metadata":{"id":"_x1TFsGzOl6l"}},{"cell_type":"markdown","source":["A common complaint around adopting LLMs for enterprise use-cases are those around data privacy.\n","\n","While open-weight models are always a great option and *should be trialed if possible*, sometimes we just want to demo things really quickly or have really good reasons for using an LLM API. In these cases, it is good practice to have some gateway that can handle scrubbing of **Personal Identifiable Information** (PII) data to mitigate the risk of PII leaking.\n","\n","In this example, we will look at the [`ai4privacy/pii-masking-200k`](https://huggingface.co/datasets/ai4privacy/pii-masking-200k) dataset and use the [`CohereForAI/c4ai-command-r-plus`](https://huggingface.co/CohereForAI/c4ai-command-r-plus) for PII Scrubbing."],"metadata":{"id":"xh44StDZOvwS"}},{"cell_type":"markdown","source":["## Setups"],"metadata":{"id":"eJ_p46YzQN1V"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lU9XXzOqOczv"},"outputs":[],"source":["import os\n","from llm_gateway.providers.cohere import CohereWrapper\n","from datasets import load_dataset\n","import cohere\n","import types\n","import re\n","\n","COHERE_API_KEY = os.environ[\"COHERE_API_KEY\"]\n","# default database url: \"postgresql://postgres:postgres@postgres:5432/llm_gateway\"\n","DATABASE_URL = os.environ[\"DATABASE_URL\"]"]},{"cell_type":"markdown","source":["## LLM Wrapper"],"metadata":{"id":"2KBPyu1jQoHS"}},{"cell_type":"code","source":["wrapper = CohereWrapper()"],"metadata":{"id":"OlrsdLSQQpNd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example = \"Bin Liu (binliuliu@gmail.com, (+1) 111-111-1111) committed a mistake when he used PyTorch Trainer instead of HF Trainer.\""],"metadata":{"id":"gIbhUedscAMH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response, db_record = wrapper.send_cohere_request(\n","    endpoint='generate',\n","    model='command-r-plus',\n","    max_tokens=25,\n","    prompt=f\"{example}\\n\\nSummarize the above text in 1-2 sentences\",\n","    temperature=0.3\n",")"],"metadata":{"id":"0wKKcKq9cCMJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(response)"],"metadata":{"id":"swpXcph5cU8E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(db_record)"],"metadata":{"id":"ZtrHJvvhcVY4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The `db_record` is the database record. As we can see, the prompt was scrubbed and the actual `user_input` that was sent out is\n","```\n","Bin Liu ([REDACTED EMAIL ADDRESS], (+1) [REDACTED PHONE NUMBER]) committed a mistake when he used PyTorch Trainer instead of HF Trainer.\\n\\nSummarize the above text in 1-2 sentences.\n","```"],"metadata":{"id":"wAQ9zRVqcYGv"}},{"cell_type":"markdown","source":["## Scrubbers"],"metadata":{"id":"o0TuYomldAJP"}},{"cell_type":"markdown","source":["From their repository, they implemented the following as scrubbers:\n","```\n","ALL_SCRUBBERS = [\n","    scrub_phone_numbers,\n","    scrub_credit_card_numbers,\n","    scrub_email_addresses,\n","    scrub_postal_codes,\n","    scrub_sin_numbers,\n","]\n","```\n","\n","If we need to implement another scrubber, we can do that by modifying the wrapper's method."],"metadata":{"id":"ZMQ9kllvdbg2"}},{"cell_type":"code","source":["def my_custom_scrubber(text: str) -> str:\n","    \"\"\"Scrub name in text\"\"\"\n","    return re.sub(r\"Bin Liu\", \"[REDACTED PERSON]\", text, re.IGNORECASE)"],"metadata":{"id":"LzS_XrBIdBeu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["original_method = wrapper.send_cohere_request\n","\n","def modified_method(self, **kwargs):\n","    self._validate_cohere_endpoint(kwargs.get('endpoint', None))\n","    prompt = kwargs.get('prompt', None)\n","\n","    text = my_custom_scrubber(prompt)\n","    kwargs['prompt'] = text\n","    return original_method(self, **kwargs)\n","\n","# assign a new method to the instance\n","wrapper.send_cohere_request = types.MethodType(modified_method, wrapper)"],"metadata":{"id":"sIQrIsoweRjj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response, db_record = wrapper.send_cohere_request(\n","    endpoint=\"generate\",\n","    model=\"command-r-plus\",\n","    max_tokens=25,\n","    prompt=f\"{example}\\n\\nSummarize the above text in 1-2 sentences.\",\n","    temperature=0.3,\n",")\n","\n","print(response)"],"metadata":{"id":"dhh5abbGevNI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(db_record)"],"metadata":{"id":"AYVMH_iqexb_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The scrubbers are applied sequentially, so if our custom scrubber interferes with any of the default scrubbers, they may behave odd."],"metadata":{"id":"yAuda0bXe0Aj"}},{"cell_type":"markdown","source":["## Dataset"],"metadata":{"id":"NwbVhxlDe_LD"}},{"cell_type":"code","source":["pii_ds = load_dataset(\"ai4privacy/pii-masking-200k\")"],"metadata":{"id":"IDWRucHnfAAX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pii_ds['train'][0]['source_text']"],"metadata":{"id":"90l5okvkfDqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example = pii_ds['train'][0]['source_text']\n","\n","response, db_record = wrapper.send_cohere_request(\n","    endpoint='generate',\n","    model='command-r-plus',\n","    max_tokens=50,\n","    prompt=f\"{example}\\n\\nSummarize the above text in 1-2 sentences\",\n","    temperature=0.3\n",")"],"metadata":{"id":"aMBN90f9fG1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(response)"],"metadata":{"id":"Efeb1teIfPoQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(db_record)"],"metadata":{"id":"crmMJtEtfQrP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Regular output"],"metadata":{"id":"4-AUV23-fTXE"}},{"cell_type":"code","source":["co = cohere.Client(api_key=os.environ['COHERE_API_KEY']\n","\n","\n","response_vanilla = co.generate(\n","    prompt=f\"{example}\\n\\nSummarize the above text in 1-2 sentences.\",\n","    model=\"command-r-plus\",\n","    max_tokens=50,\n","    temperature=0.3\n",")"],"metadata":{"id":"Mpq2-zfQfUOY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(response_vanilla)"],"metadata":{"id":"UUmIL_XNfecX"},"execution_count":null,"outputs":[]}]}