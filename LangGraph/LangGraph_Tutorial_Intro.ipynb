{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31871,
     "status": "ok",
     "timestamp": 1731419504353,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "6q6QC5bxb8k0",
    "outputId": "388d0d9e-7e52-455e-c6b7-3e3fa330c821"
   },
   "outputs": [],
   "source": [
    "!pip install -qU langgraph langsmith langchain_anthropic langchain langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWynlcjijGtX"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_RfFl_ijH9E"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMmZGBgYjJAR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"YOUR_ANTHROPIC_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYwP2-Pmc-RU"
   },
   "source": [
    "# Build a Basic Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wguXznMjjkh"
   },
   "source": [
    "Start with a `StateGraph`, which defines the structure of the chatbot as a \"state machine\". We later will add\n",
    "* `nodes` to represent the LLM and functions which the chatbot can call, and\n",
    "* `edges` to specify how the bot should transition between these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAktsDmpjhMk"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1731337568190,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "zreY3LZtkZj2",
    "outputId": "24341b9b-5a7f-45fe-e9ef-b7880fb1e2cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x796a37a0bb50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\".\n",
    "    # The `add_messages` function in the annotation\n",
    "    # defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlYUENfclELg"
   },
   "source": [
    "The first thing when defining a graph is define the `State` of the graph. The `State` consists of the schema of the graph and `reducer functions` which specify how to apply updates to the state.\n",
    "\n",
    "Here, `State` is a `TypedDict` with a single key: `messages`. The `messages` key is annotated with the `add_messages` reducer function, which tells LangGraph to append new messages to the existing list, rather than overwriting it.\n",
    "\n",
    "`State` keys without an annotation will be overwritten by each update, storing the most recent value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VufwJpD8m7O0"
   },
   "source": [
    "The graph we defined knows two things:\n",
    "1. Every `node` we define will receive the current `State` as input and return a value that updates that state.\n",
    "2. `messages` will be appended to the current list, rather than directly overwritten. This is communicated via the prebuilt `add_messages` function in the `Annotated` syntax.\n",
    "\n",
    "Next, we add a \"`chatbot`\" node. Nodes represent units of work. They are typically regular python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQxooab3lDrI"
   },
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\n",
    "        'messages': [llm.invoke(state['messages'])]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1731337570582,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "UH73OOB0oFTJ",
    "outputId": "6bf5c9d5-963a-4f00-c37a-c52a8e2bcc66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x796a37a0bb50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st arg is the unique node name\n",
    "# 2nd arg is the function or object called when the node is used\n",
    "graph_builder.add_node('chatbot', chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4l-lkYAowj4"
   },
   "source": [
    "The `chatbot` node function takes the current `State` as input and returns a dictionary containing an updated `messages` list under the key `\"messages\"`. This is the basic pattern for all LangGraph node functions.\n",
    "\n",
    "The `add_messages` function in the `State` will append the LLM's response messages to whatever messages are already in the state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvkZ1xaVpK39"
   },
   "source": [
    "Next, we add an `entry` point, which tells our graph **where to start its work**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1731337571422,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "SoO6G6jvonsL",
    "outputId": "f4407abe-43f0-4703-cfb9-e811e136e22b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x796a37a0bb50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, 'chatbot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMxNFFtopYAA"
   },
   "source": [
    "Similarly, we need to set a `finish` point, which instructs the graph **any time this node is run, we can exit**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1731337571796,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "TJ4EaZoTpXCB",
    "outputId": "68730793-a011-41e0-caee-3be0a22d6365"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x796a37a0bb50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge('chatbot', END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UGY5UZnp99_"
   },
   "source": [
    "Finally, to run the graph, we cal `compile()` on the `graph_builder`, which creates a `CompiledGraph` we can use invoke on our state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZh_Yq2mp9Xp"
   },
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8z450jVqNxo"
   },
   "source": [
    "We can visualize the graph as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1731337574210,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "iWrhEVLuqLlD",
    "outputId": "e206a737-fa07-49e4-ba32-bb4d7daad13f"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(\n",
    "    graph.get_graph().draw_mermaid_png()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ggD8RNfxqej6"
   },
   "source": [
    "Now we can test this chatbot. We can exit the chatbot loop at any time by typing \"quit\", \"exit\" or \"q\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R6e7_1gqqbKe"
   },
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({'messages': [('user', user_input)]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54498,
     "status": "ok",
     "timestamp": 1731337631645,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "hk6q3Zd7rX0L",
    "outputId": "a5b8f54a-fdc8-45fd-ef4f-13bc43e92bf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi\n",
      "Assistant: Hello! How can I assist you today? Feel free to ask any questions or let me know if you need help with anything.\n",
      "User: What is your name?\n",
      "Assistant: My name is Claude.\n",
      "User: what version are you?\n",
      "Assistant: I'm Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest. I don't have a specific version number.\n",
      "User: are you 3.5 or 2.5?\n",
      "Assistant: I am Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest. I don't have a version number like 3.5 or 2.5.\n",
      "User: which is larger, 9.11 or 9.8?\n",
      "Assistant: To compare decimal numbers, we can look at each digit from left to right.\n",
      "\n",
      "1) First, let's compare the whole number part:\n",
      "   Both numbers have 9 as the whole number, so we need to look at the decimal part.\n",
      "\n",
      "2) Now, let's compare the tenths (the first digit after the decimal point):\n",
      "   9.11 has 1 in the tenths place\n",
      "   9.8 has 8 in the tenths place\n",
      "\n",
      "3) Since 8 is greater than 1, we don't need to look any further.\n",
      "\n",
      "Therefore, 9.8 is larger than 9.11.\n",
      "User: q\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "exit_msg = ['quit', 'exit', 'q']\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input('User: ')\n",
    "        if user_input.lower() in exit_msg:\n",
    "            print('Goodbye!')\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPtkjZe6zWH0"
   },
   "source": [
    "# Enhancing the Chatbot with Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FT61HL8jzdZF"
   },
   "source": [
    "We can integrate a web search tool to find relevant information and provide better responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur9eioGCr6tS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TAVILY_API_KEY'] = 'YOUR_TAVILY_API_KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXdhEZSRz2Vd"
   },
   "source": [
    "Define the search tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iomwEGGHz1FX"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search_tool = TavilySearchResults(max_reuslts=3)\n",
    "tools = [search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4104,
     "status": "ok",
     "timestamp": 1731361456255,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "WRex7hcCz9T8",
    "outputId": "d7a696d0-7dbd-4072-8293-99cb1c6b5924"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141',\n",
       "  'content': 'Nodes: Nodes are the building blocks of your LangGraph. Each node represents a function or a computation step. You define nodes to perform specific tasks, such as processing input, making'},\n",
       " {'url': 'https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48',\n",
       "  'content': 'StateGraph: StateGraph in LangGraph is a class that allows us to create graphs whose nodes communicate by reading and writing to a shared state. The StateGraph class is parameterized by a user'},\n",
       " {'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'content': \"In LangGraph, each node represents an LLM agent, and the edges are the communication channels between these agents. This structure allows for clear and manageable workflows, where each agent performs specific tasks and passes information to other agents as needed. State management. One of LangGraph's standout features is its automatic state\"},\n",
       " {'url': 'https://langchain-ai.github.io/langgraph/',\n",
       "  'content': 'LangGraph adds the input message to the internal state, then passes the state to the entrypoint node, \"agent\". The \"agent\" node executes, invoking the chat model. The chat model returns an AIMessage. LangGraph adds this to the state. Graph cycles the following steps until there are no more tool_calls on AIMessage:'},\n",
       " {'url': 'https://blog.futuresmart.ai/langgraph-tutorial-for-beginners',\n",
       "  'content': 'By representing workflows as cyclical graphs, LangGraph allows developers to orchestrate the interactions of multiple LLM agents, ensuring smooth communication and efficient execution of complex tasks. from langgraph.graph.message import add_messages You can expand upon this by incorporating more sophisticated state management and different LLM models or by connecting to external tools and APIs. The key is to define clear nodes for different tasks and use edges to establish the desired flow of information and control within the chatbot. from langgraph.graph.message import add_messages graph_builder.add_edge(\"tools\", \"chatbot\") Loop Back: After executing the tool, use graph_builder.add_edge() to direct the flow back to the chatbot node, allowing the conversation to continue. from langgraph.graph.message import add_messages graph_builder.add_edge(\"tools\", \"chatbot\")'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the tool\n",
    "search_results = search_tool.invoke(\"What is a node in LangGraph?\")\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1731340306207,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "4pmhzIw70cuU",
    "outputId": "839285a0-28b4-43ab-ee6f-971f12f79d72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['url', 'content'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVlTVa3tG65F"
   },
   "source": [
    "The results contain page summaries that our chatbot can use to answer questions.\n",
    "\n",
    "Next, we can start defining our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1731340307530,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "iGbQ-c1GG3MQ",
    "outputId": "061a0f05-8d1e-44ea-d57f-6535ac21aa57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x796a36f9e560>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "llm = ChatAnthropic(model='claude-3-5-sonnet-20240620')\n",
    "# Add tools\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot_with_tools(state: State):\n",
    "    return {\n",
    "        'messages': [llm_with_tools.invoke(state['messages'])]\n",
    "    }\n",
    "\n",
    "graph_builder.add_node('chatbot-tools', chatbot_with_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5TtLj8FykTK"
   },
   "source": [
    "Next we need to create a function to actually run the tools if they are called. We need to implement a `BasicToolNode` that checks the most recent message in the state and calls tools if the message contains `tool_calls`. It relies on the LLM's `tool_calling` support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1731340310329,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "6EPMZv4Hye8X",
    "outputId": "dd536ac0-4a69-4cd3-f332-06de458d32d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x796a36f9e560>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get('messages', []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError('No message found in input')\n",
    "\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call['name']].invoke(tool_call['args'])\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call['name'],\n",
    "                    tool_call_id=tool_call['id'],\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "        return {'messages': outputs}\n",
    "\n",
    "\n",
    "# create a tool node\n",
    "tool_node = BasicToolNode(tools=[search_tool])\n",
    "# add this node to graph\n",
    "graph_builder.add_node('tools', tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iE1RPH3v3VzB"
   },
   "source": [
    "With the tool node added, we can define the `conditional_edges`.\n",
    "\n",
    "The **edges** route the control flow from one node to the next. **Conditional edges** usually contain \"if\" statements to route to different nodes depending on the current graph state. These functions receive the current graph `state` and return a string or a list of strings indicating which node(s) to call next.\n",
    "\n",
    "We will define a router function called `route_tools` that checks for tool calls in the chatbot's output. Then we pass it to the graph by calling `add_conditional_edges`, which tells the graph that whenver the `chatbot` node completes to check this function to see where to go next. The condition will route to `tools` if tool calls are present and `END` if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7leZn1v0PN8"
   },
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "def route_tools(state: State):\n",
    "    \"\"\"\n",
    "    Used in the conditional-edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the END.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get('messages', []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "\n",
    "    if hasattr(ai_message, 'tool_calls') and len(ai_message.tool_calls) > 0:\n",
    "        return 'tools'\n",
    "    return END\n",
    "\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool,\n",
    "# and \"END\" if it is fine directly responding.\n",
    "# This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    'chatbot-tools',\n",
    "    route_tools,\n",
    "    # The following dictionary lets us tell the graph to interpret the condition's outputs\n",
    "    # as a specific node.\n",
    "    # It defaults to the identity function, but if us want to use a node\n",
    "    # named something else apart from \"tools\",\n",
    "    # we can update the value of the dictionary to something else,\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\", END: END}\n",
    ")\n",
    "\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge('tools', 'chatbot-tools')\n",
    "graph_builder.add_edge(START, 'chatbot-tools')\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B96P911Q6UvZ"
   },
   "source": [
    "The conditional edges start from a single node, which tells the graph \"any time the `chatbot` node runs, either go to `tools` if it calls a tool, or end the loop if it responds directly.\n",
    "\n",
    "When the graph transitions to `END`, it has no more tasks to complete and ceases execution. Because the condition can return `END`, we do not need to explicitly set a `finish_point` this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 985,
     "status": "ok",
     "timestamp": 1731340330698,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "CJmjI3ay6QYZ",
    "outputId": "f5b020f3-90de-4cb1-eee7-3438155c1bd2"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(\n",
    "    graph.get_graph().draw_mermaid_png()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jIPWfXI7QOQ"
   },
   "source": [
    "Now we can ask the chatbot questions outside its trianing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59987,
     "status": "ok",
     "timestamp": 1731340516730,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "AM6nfFg17D-G",
    "outputId": "e277e0f4-9729-4715-da7b-8c9d3c1d8840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi\n",
      "Assistant: Hello! Welcome. How can I assist you today? I'm here to help with any questions or tasks you might have. Is there anything specific you'd like to know or discuss?\n",
      "User: What do you know about LangChain?\n",
      "Assistant: [{'text': \"To provide you with accurate and up-to-date information about LangChain, I'll need to search for the latest details. Let me do that for you.\", 'type': 'text'}, {'id': 'toolu_014gzkFn5FoDanJ8ApnnR8JJ', 'input': {'query': 'LangChain framework for AI applications'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Assistant: [{\"url\": \"https://www.33rdsquare.com/langchain/\", \"content\": \"Core Concepts\\nA LangChain application consists of 5 key components working in conjunction:\\nLLM Wrappers\\u2026\\nPrompts\\nChains\\nVector Stores\\nAgents\\nEvolution of LangChain\\nLangChain originated from techniques detailed in academic papers published by researchers at Anthropic \\u2013 an AI safety startup that open sourced the framework [2].\\n This comprehensive guide covers what LangChain provides, underlying concepts, use cases, performance analysis, current limitations and more.\\nIntroduction to LangChain\\nReleased in 2022, LangChain allows developers to connect large language models like GPT-3, BLOOM and Codex to external knowledge sources like databases, documents and proprietary data. This facilitates:\\nInitial use cases demonstrate 2-4x gains in task success rate for data heavy applications by grounding language models, reducing hallucinated output and speculation [1].\\nLangChain moves LLM applications beyond solely conversational to being able to query knowledge bases and take pragmatic actions. Limitations and Challenges\\nWhile promising, LangChain has challenges to scale to enterprise grade applications:\\nThere are also issues intrinsic to LLMs like GPT-3:\\n Architectural Deep Dive\\nUnder the surface, a LangChain deployment comprises of several key components [6]:\\nVectorstore\\nServing layer that stores vector encodings of text (embeddings) for low latency retrieval.\"}, {\"url\": \"https://www.ibm.com/topics/langchain\", \"content\": \"Applications made with LangChain provide great utility for a variety of use cases, from straightforward question-answering and text generation tasks to more complex solutions that use an LLM as a \\u201creasoning engine.\\u201d\\nTrain, validate, tune and deploy generative AI, foundation models and machine learning capabilities with ease and build AI applications in a fraction of the time with a fraction of the data.\\n When building a chain for an agent, inputs include:\\nDespite their heralded power and versatility, LLMs have important limitations: namely, a lack of up-to-date information, a lack of domain-specific expertise and a general difficulty with math.\\nLangChain tools\\u00a0(link resides outside ibm.com) are a set of functions that empower LangChain agents to interact with real-world information in order to expand or improve the services it can provide. Launched by Harrison Chase in October 2022, LangChain enjoyed a meteoric rise to prominence: as of June 2023, it was the single fastest-growing open source project on Github.1 Coinciding with the momentous launch of OpenAI\\u2019s ChatGPT the following month, LangChain has played a significant role in making generative AI more accessible to enthusiasts in the wake of its widespread popularity.\\n Reimagine how you work with\\u00a0AI: our diverse, global team of more than 20,000 AI\\u00a0experts can help you quickly and confidently\\u00a0design and scale AI and automation across your\\u00a0business, working across our own IBM\\u00a0watsonx\\u00a0technology\\u00a0and an open ecosystem of partners to deliver any\\u00a0AI model, on any cloud, guided by ethics and trust.\\n While it\\u2019s the GPT model that interprets the user\\u2019s input and composes a natural language response, it\\u2019s the application that (among other things) provides an interface for the user to type and read and a UX design that governs the chatbot experience.\"}, {\"url\": \"https://www.langchain.com/langchain\", \"content\": \"Augment the power\\nof\\u00a0LLMs with your data\\nLangChain helps connect LLMs to your company\\u2019s private sources\\nof data and APIs to create context-aware, reasoning applications.\\n Our Methods\\nReady to start shipping\\nreliable GenAI apps faster?\\nLangChain and LangSmith are critical parts of the reference\\narchitecture to get you from prototype to production. The largest community building the future of LLM apps\\nLangChain\\u2019s flexible abstractions and AI-first toolkit make it\\u00a0the\\u00a0#1\\u00a0choice for developers when building with GenAI.\\n Why choose LangChain?\\nLangChain is easy to get started with and\\u00a0gives\\u00a0you choice, flexibility, and power as\\u00a0you scale.\\n Get customizability and control with a durable runtime baked in\\nLangChain Expression Language (LCEL) lets you build your app in a truly composable way, allowing you to customize it as you see fit.\"}, {\"url\": \"https://python.langchain.com/docs/introduction/\", \"content\": \"How to use tools in a chain How to migrate from legacy LangChain agents to LangGraph How to use chat models to call tools LangChain is a framework for developing applications powered by large language models (LLMs). Development: Build your applications using LangChain's open-source building blocks, components, and third-party integrations. langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. LangServe: Deploy LangChain chains as REST APIs. LangSmith: A developer platform that lets you debug, test, evaluate, and monitor LLM applications. Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\"}, {\"url\": \"https://github.com/AI-App/LangChain\", \"content\": \"\\u26a1 Building applications with LLMs through composability \\u26a1\\nLicense\\nAI-App/LangChain\\nFolders and files\\nLatest commit\\nHistory\\n.github\\n.github\\ndocs\\ndocs\\nlangchain\\nlangchain\\ntests\\ntests\\n.flake8\\n.flake8\\n.gitignore\\n.gitignore\\nCITATION.cff\\nCITATION.cff\\nLICENSE\\nLICENSE\\nMakefile\\nMakefile\\nREADME.md\\nREADME.md\\npoetry.lock\\npoetry.lock\\npoetry.toml\\npoetry.toml\\npyproject.toml\\npyproject.toml\\nreadthedocs.yml\\nreadthedocs.yml\\nRepository files navigation\\n\\ud83e\\udd9c\\ufe0f\\ud83d\\udd17 LangChain\\n\\u26a1 Building applications with LLMs through composability \\u26a1\\nProduction Support: About\\n\\u26a1 Building applications with LLMs through composability \\u26a1\\nResources\\nLicense\\nStars\\nWatchers\\nForks\\nReleases\\nPackages\\n0\\nLanguages\\nFooter\\nFooter navigation Common examples of these types of applications include:\\n\\u2753 Question Answering over specific documents\\n\\ud83d\\udcac Chatbots\\n\\ud83e\\udd16 Agents\\n\\ud83d\\udcd6 Documentation\\nPlease see here for full documentation on:\\n\\ud83d\\ude80 These are, in increasing order of complexity:\\n\\ud83d\\udcc3 LLMs and Prompts:\\nThis includes prompt management, prompt optimization, generic interface for all LLMs, and common utilities for working with LLMs.\\n What is this?\\nLarge language models (LLMs) are emerging as a transformative technology, enabling\\ndevelopers to build applications that they previously could not.\\n\"}]\n",
      "Assistant: Based on the search results, I can provide you with comprehensive information about LangChain:\n",
      "\n",
      "LangChain is a popular framework for developing applications powered by large language models (LLMs). It was released in 2022 and has quickly become one of the fastest-growing open-source projects on GitHub. Here are key points about LangChain:\n",
      "\n",
      "1. Purpose:\n",
      "   - LangChain allows developers to connect large language models (like GPT-3, BLOOM, and Codex) to external knowledge sources such as databases, documents, and proprietary data.\n",
      "   - It helps create context-aware, reasoning applications that go beyond simple conversational interfaces.\n",
      "\n",
      "2. Core Components:\n",
      "   LangChain applications typically consist of five key components:\n",
      "   a) LLM Wrappers\n",
      "   b) Prompts\n",
      "   c) Chains\n",
      "   d) Vector Stores\n",
      "   e) Agents\n",
      "\n",
      "3. Key Features:\n",
      "   - Enables querying knowledge bases and taking pragmatic actions\n",
      "   - Provides tools for interacting with real-world information\n",
      "   - Offers flexible abstractions and an AI-first toolkit\n",
      "   - Includes LangChain Expression Language (LCEL) for building composable applications\n",
      "\n",
      "4. Benefits:\n",
      "   - Improves task success rates for data-heavy applications by 2-4 times\n",
      "   - Reduces hallucinated output and speculation from LLMs\n",
      "   - Allows for customization and control with a durable runtime\n",
      "   - Facilitates easy integration with various data sources and APIs\n",
      "\n",
      "5. Use Cases:\n",
      "   - Question-answering over specific documents\n",
      "   - Chatbots\n",
      "   - Intelligent agents\n",
      "   - Text generation tasks\n",
      "   - Complex solutions using LLMs as \"reasoning engines\"\n",
      "\n",
      "6. Ecosystem:\n",
      "   - LangChain is part of a broader ecosystem that includes:\n",
      "     - LangServe: For deploying LangChain chains as REST APIs\n",
      "     - LangSmith: A developer platform for debugging, testing, evaluating, and monitoring LLM applications\n",
      "     - LangGraph: For building stateful, multi-actor applications with LLMs\n",
      "\n",
      "7. Challenges and Limitations:\n",
      "   - Scaling to enterprise-grade applications can be challenging\n",
      "   - Inherits limitations of underlying LLMs (e.g., lack of up-to-date information, domain-specific expertise, difficulty with math)\n",
      "\n",
      "8. Community and Growth:\n",
      "   - Has a large and active developer community\n",
      "   - As of June 2023, it was the fastest-growing open-source project on GitHub\n",
      "\n",
      "9. Origins:\n",
      "   - LangChain originated from techniques detailed in academic papers published by researchers at Anthropic, an AI safety startup.\n",
      "\n",
      "LangChain has become a crucial tool in the development of AI applications, especially in the wake of the increasing popularity of generative AI models like ChatGPT. It provides developers with the necessary tools and abstractions to create more sophisticated and context-aware AI applications.\n",
      "User: q\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "exit_msg = ['quit', 'exit', 'q']\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input('User: ')\n",
    "        if user_input.lower() in exit_msg:\n",
    "            print('Goodbye!')\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V88SwZrT8AOH"
   },
   "source": [
    "Our chatbot still can't remember past interaction on its own, limiting its ability to have coherent, multi-turn converations.\n",
    "\n",
    "We can now replace our `BasicToolNode` for the prebuilt `ToolNode` and our `route_tools` condition with the prebuilt `tools_condition`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2fiGUVd8hxQ"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model='claude-3-5-sonnet-20240620')\n",
    "# Add tools\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot_with_tools(state: State):\n",
    "    return {\n",
    "        'messages': [llm_with_tools.invoke(state['messages'])]\n",
    "    }\n",
    "\n",
    "graph_builder.add_node('chatbot-tools', chatbot_with_tools)\n",
    "\n",
    "# Define tool node\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "\n",
    "# Add conditional edge\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot-tools\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge('tools', 'chatbot-tools')\n",
    "graph_builder.set_entry_point('chatbot-tools')\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clx2ToX8FWOE"
   },
   "source": [
    "# Add Memory to the Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKiYwurpOhG0"
   },
   "source": [
    "LangGraph can enable multi-turn interactions by enabling **persistent checkpointing**. If we provide a `checkpointer` when compiling the graph and a `thread_id` when calling our graph, LangGraph automatically saves the state after each step. When we invoke the graph again using the same `thread_id`, the graph loads its saved state, allowing the chatbot to pick up where it left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UD6J1aOFZWw"
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZnHQ7m1PIjT"
   },
   "source": [
    "We are using an in-memory checkpointer. In a production application, we may want to change this to use `SqliteSaver` or `PostgresSaver` and connect to our own database.\n",
    "\n",
    "Next, define the graph with tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIs8v2a7PE7q"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# add tools\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "# add llm\n",
    "llm = ChatAnthropic(model='claude-3-5-sonnet-20240620')\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\n",
    "        'messages': [llm_with_tools.invoke(state['messages'])]\n",
    "    }\n",
    "\n",
    "graph_builder.add_node('chatbot', chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    'chatbot',\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "graph_builder.add_edge('tools', 'chatbot')\n",
    "graph_builder.add_edge(START, 'chatbot')\n",
    "\n",
    "# Compile the graph with the checkpointer\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1731346208258,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "KkDJwCItRl6R",
    "outputId": "fc31e819-b33e-4173-ceb1-4af9d0347b53"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(\n",
    "    graph.get_graph().draw_mermaid_png()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GoKGD-gRp2y"
   },
   "source": [
    "The connectivity of the graph has not changed but we add a memory checkpointer.\n",
    "\n",
    "Now we can interact with our bot. First, create a thread id to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2064,
     "status": "ok",
     "timestamp": 1731346382578,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "5oqmygHERpO-",
    "outputId": "11e1b497-40cd-4f22-fdf5-3768fac5f043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi! My name is Bin\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Bin! It's nice to meet you. How can I assist you today? Is there any specific information you're looking for or any questions you have?\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'configurable': {'thread_id': '1'}\n",
    "}\n",
    "\n",
    "# then we can call the bot\n",
    "user_input = 'Hi! My name is Bin'\n",
    "\n",
    "# config is passed as the positional argument\n",
    "events = graph.stream(\n",
    "    {'messages': [('user', user_input)]},\n",
    "    config,\n",
    "    stream_mode='values',\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCg3_CylSZJb"
   },
   "source": [
    "The `config` was provided as the **2nd positional argument** when calling our graph.\n",
    "\n",
    "We can check if our bot remember our name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1580,
     "status": "ok",
     "timestamp": 1731346465288,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "zHKRMcTQSTWw",
    "outputId": "b2731b71-72b8-442a-c071-e8627a4a468f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bin. You introduced yourself at the beginning of our conversation.\n"
     ]
    }
   ],
   "source": [
    "user_input = 'What is my name?'\n",
    "\n",
    "events = graph.stream(\n",
    "    {'messages': [('user', user_input)]},\n",
    "    config,\n",
    "    stream_mode='values',\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lSABb7TSp68"
   },
   "source": [
    "If we set up with another thread id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3029,
     "status": "ok",
     "timestamp": 1731346505599,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "KdAltu3ISnqh",
    "outputId": "64bc82c0-3957-49a6-b4f0-a045b4908e2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I apologize, but I don't have access to personal information about individual users. As an AI language model, I don't have knowledge of specific individuals or their personal details. Is there something else I can help you with or a different question you'd like to ask?\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {'messages': [('user', user_input)]},\n",
    "    {'configurable': {'thread_id': '2'}},\n",
    "    stream_mode='values',\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QD2pSQUJS0hn"
   },
   "source": [
    "We can inspect a graph's `state` for a given `config` at any time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1731346568966,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "btqYD1XgSxJn",
    "outputId": "09b8a117-0861-4e50-ce1a-5100428c8519"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Hi! My name is Bin', additional_kwargs={}, response_metadata={}, id='33d2a085-bb3f-490c-bf1c-8686bf973b8a'), AIMessage(content=\"Hello Bin! It's nice to meet you. How can I assist you today? Is there any specific information you're looking for or any questions you have?\", additional_kwargs={}, response_metadata={'id': 'msg_01SC1aLkWtRw3HZXisWZeYcX', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 404, 'output_tokens': 36}}, id='run-30a4ab20-602a-4d26-a188-f2b6d0f20800-0', usage_metadata={'input_tokens': 404, 'output_tokens': 36, 'total_tokens': 440, 'input_token_details': {}}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}, id='71421686-77fc-45c1-b4c6-2833f24a7b4c'), AIMessage(content='Your name is Bin. You introduced yourself at the beginning of our conversation.', additional_kwargs={}, response_metadata={'id': 'msg_01PARjcBffMavf6C5u4GWV4P', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 448, 'output_tokens': 19}}, id='run-08f4d676-b514-4d02-a419-f042ddd1a614-0', usage_metadata={'input_tokens': 448, 'output_tokens': 19, 'total_tokens': 467, 'input_token_details': {}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efa0533-1c94-66a1-8004-49cad13d709c'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content='Your name is Bin. You introduced yourself at the beginning of our conversation.', additional_kwargs={}, response_metadata={'id': 'msg_01PARjcBffMavf6C5u4GWV4P', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 448, 'output_tokens': 19}}, id='run-08f4d676-b514-4d02-a419-f042ddd1a614-0', usage_metadata={'input_tokens': 448, 'output_tokens': 19, 'total_tokens': 467, 'input_token_details': {}})]}}, 'thread_id': '1', 'step': 4, 'parents': {}}, created_at='2024-11-11T17:34:24.977841+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efa0533-1014-6093-8003-012a5c4a7b87'}}, tasks=())"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1731346586601,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "erFgadMMTBSc",
    "outputId": "e5ba88d0-0d16-4ae4-960c-be83608c3471"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQvqt-ffTGgH"
   },
   "source": [
    "The `snapshot` contains the current state values, corresponding config, and the `next` node to process. In our case, the graph has reached an `END` state, so `next` is empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cJ0g9KYTRVC"
   },
   "source": [
    "# Human-in-the-loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FXxYFATnEwX"
   },
   "source": [
    "LangGraph supports `human-in-the-loop` workflows in a number of ways. In this section, we use `interrupt_before` functionality to always break the tool node.\n",
    "\n",
    "Reuse the our graph from last section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 906,
     "status": "ok",
     "timestamp": 1731351986017,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "qzWg5AkwTFmx",
    "outputId": "7d9532f3-65f6-4929-916f-c3c9cf70327c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x796a2933f190>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4f1ujxVnsgk"
   },
   "source": [
    "Now we can compile the graph, specifying to `interrupt_before` the `tools` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xP7bckESnri6"
   },
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=['tools'], # newly added here\n",
    "    # there is also an `interrupt_after`\n",
    "    # interrupt_after=['tools'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3444,
     "status": "ok",
     "timestamp": 1731352251683,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "A8VGyxUBoRjW",
    "outputId": "54a94158-f2d0-4244-9092-f7b07c69966a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine. Let me search for information about LangGraph.\", 'type': 'text'}, {'id': 'toolu_01XC8Nm2oKin3nWf4b5VTib5', 'input': {'query': 'LangGraph: what is it, how is it used in AI development'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01XC8Nm2oKin3nWf4b5VTib5)\n",
      " Call ID: toolu_01XC8Nm2oKin3nWf4b5VTib5\n",
      "  Args:\n",
      "    query: LangGraph: what is it, how is it used in AI development\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {'configurable': {'thread_id': '1'}}\n",
    "\n",
    "# add config to stream or invoke method\n",
    "events = graph.stream(\n",
    "    {'messages': [('user', user_input)]},\n",
    "    config,\n",
    "    stream_mode='values',\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if 'messages' in event:\n",
    "        event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgHbs7Ero0f3"
   },
   "source": [
    "We can inspect the graph state to confirm if it worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1731352308309,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "pedIqa0qor5w",
    "outputId": "29ecc2dd-099f-46ef-b77d-eef74e9644bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7O3K1-EZo7QN"
   },
   "source": [
    "Unlike last time, the \"next\" node is set to `'tools'`. We have interrupted here. Now we can check the tool invocation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1731352363331,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "jmJSqhgxo6fl",
    "outputId": "c83da2dc-f7bf-4c47-87d9-e1bc52845eba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'LangGraph: what is it, how is it used in AI development'},\n",
       "  'id': 'toolu_01XC8Nm2oKin3nWf4b5VTib5',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_message = snapshot.values['messages'][-1]\n",
    "existing_message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rDd6KexpK5v"
   },
   "source": [
    "This query seems reasonable. The simplest thing the human can do is to allow the graph continue executing.\n",
    "\n",
    "To continue the graph, we need to pass in `None` so the graph can continue where it left off without adding anything new to the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11995,
     "status": "ok",
     "timestamp": 1731352598157,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "m9fE53OtpH7p",
    "outputId": "a830aad5-07e2-415a-a6c5-6777cfa92f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine. Let me search for information about LangGraph.\", 'type': 'text'}, {'id': 'toolu_01XC8Nm2oKin3nWf4b5VTib5', 'input': {'query': 'LangGraph: what is it, how is it used in AI development'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01XC8Nm2oKin3nWf4b5VTib5)\n",
      " Call ID: toolu_01XC8Nm2oKin3nWf4b5VTib5\n",
      "  Args:\n",
      "    query: LangGraph: what is it, how is it used in AI development\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"LangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. It simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing\"}, {\"url\": \"https://medium.com/@gopiariv/langgraph-a-beginners-guide-to-building-ai-workflows-e500965f2ef9\", \"content\": \"LangGraph is a part of the LangChain ecosystem, but it's installed separately from the main LangChain package. Here's a guide on how to install LangGraph: 1. Basic Installation: You can\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the search results, I can provide you with some information about LangGraph:\n",
      "\n",
      "1. What is LangGraph?\n",
      "LangGraph is a library that's part of the LangChain ecosystem. It's designed to address challenges in developing complex AI applications, particularly those involving multiple language models (LLMs) or chains.\n",
      "\n",
      "2. Purpose and Functionality:\n",
      "- LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents or chains in a structured manner.\n",
      "- It simplifies the development process for AI applications that require complex interactions between different components.\n",
      "- One of its key features is enabling the creation of cyclical graphs, which are essential for developing more sophisticated AI workflows.\n",
      "\n",
      "3. Installation:\n",
      "- LangGraph is installed separately from the main LangChain package.\n",
      "- You can install it using a package manager like pip, though the exact command wasn't provided in the search results.\n",
      "\n",
      "4. Use in AI Development:\n",
      "- LangGraph is particularly useful for developers working on AI projects that require orchestrating multiple AI agents or processes.\n",
      "- It helps in creating more structured and manageable workflows when dealing with complex AI systems.\n",
      "- The library seems to be especially valuable when you need to create AI applications that involve multiple steps, feedback loops, or interactions between different AI components.\n",
      "\n",
      "5. Relationship to LangChain:\n",
      "- While it's part of the LangChain ecosystem, LangGraph appears to focus specifically on the graphical representation and execution of AI workflows.\n",
      "- It complements LangChain by providing additional tools for structuring and managing complex AI processes.\n",
      "\n",
      "Learning LangGraph could be beneficial if you're working on AI projects that involve:\n",
      "- Multiple AI agents interacting with each other\n",
      "- Complex workflows with various steps and decision points\n",
      "- Applications requiring structured coordination between different AI components\n",
      "\n",
      "To learn more about LangGraph, you might want to look into:\n",
      "- Official documentation (if available)\n",
      "- Practical tutorials or examples of LangGraph in use\n",
      "- How it integrates with other LangChain components\n",
      "- Specific use cases or projects where LangGraph has been applied successfully\n",
      "\n",
      "Would you like me to search for any specific aspect of LangGraph, such as tutorials, example projects, or more detailed technical information?\n"
     ]
    }
   ],
   "source": [
    "# `None` will append nothing new to the current state,\n",
    "# letting it resume as if it had never been interrupted.\n",
    "events = graph.stream(\n",
    "    None,\n",
    "    config,\n",
    "    stream_mode='values',\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if 'messages' in event:\n",
    "        event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qd2r1uLkqCyd"
   },
   "source": [
    "Notice that the state is loaded in the first step so that our chatbot can continue where it left off.\n",
    "\n",
    "This is how we can use an `interrupt` method to add human-in-the-loop execution to our chatbot, allowing for human oversight and intervention when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdJUxCFWqfdo"
   },
   "source": [
    "# Manually Updating the State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohzY0N6cqiI8"
   },
   "source": [
    "In the previous section, we interrupted a graph so that a human could inspect its actions. This lets the human `read` the state, but if they want to change their agent's course, they will need to have `write` access.\n",
    "\n",
    "Updating the state lets us control the agent's trajectory by modifying its actions. This is useful when we want to correct the agent's mistakes, explore alternative paths, or guide the agent towards a specific goal.\n",
    "\n",
    "We will reuse our chatbot from last section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COyb4F2mp-Zg"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # This is new!\n",
    "    interrupt_before=[\"tools\"],\n",
    "    # Note: can also interrupt **after** actions, if desired.\n",
    "    # interrupt_after=[\"tools\"]\n",
    ")\n",
    "\n",
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream({\"messages\": [(\"user\", user_input)]}, config)\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 153,
     "status": "ok",
     "timestamp": 1731361472339,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "H3pLF8tSrLp5",
    "outputId": "d798ad11-8c8a-43dd-b648-b9b3e78038bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_01AyJjvNzsmBKyDWfR9YY8L6', 'input': {'query': 'LangGraph: what is it, features, and usage in AI development'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01AyJjvNzsmBKyDWfR9YY8L6)\n",
      " Call ID: toolu_01AyJjvNzsmBKyDWfR9YY8L6\n",
      "  Args:\n",
      "    query: LangGraph: what is it, features, and usage in AI development\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "existing_message = snapshot.values['messages'][-1]\n",
    "existing_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUsN58xNrWvb"
   },
   "source": [
    "The LLM just requested to use the search engine tool and our graph was interrupted just like what we had in the previous section. If we proceed as before, the tool will be called to search the web.\n",
    "\n",
    "If the user wants to intercede, we need to correct this response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 165,
     "status": "ok",
     "timestamp": 1731361478602,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "pV2V52HyrUo6",
    "outputId": "e9846cb9-97dc-4a11-8852-eb7e0b3b2ec2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a library for building stateful, multi-actor applications with LLMs.\n",
      "\n",
      "\n",
      "Last 2 messages;\n",
      "[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='85325e49-d686-4e2f-a45c-58c62615e949', tool_call_id='toolu_01AyJjvNzsmBKyDWfR9YY8L6'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', additional_kwargs={}, response_metadata={}, id='fa7cd39c-6e60-42a2-92c0-7dff00dbec6a')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "answer = ('LangGraph is a library for building stateful, multi-actor applications with LLMs.')\n",
    "\n",
    "new_messages = [\n",
    "    # The LLM API expects some ToolMessage to match its tool call.\n",
    "    # We will satify that here.\n",
    "    ToolMessage(\n",
    "        content=answer,\n",
    "        tool_call_id=existing_message.tool_calls[0]['id'],\n",
    "    ),\n",
    "    # and then directly \"put words in the LLM's mouth\" by populating its response.\n",
    "    AIMessage(content=answer),\n",
    "]\n",
    "\n",
    "new_messages[-1].pretty_print()\n",
    "\n",
    "graph.update_state(\n",
    "    # Which state to update\n",
    "    config,\n",
    "    # The updated values to provide.\n",
    "    # The messages in our \"State\" are \"append-only\",\n",
    "    # meaning this will be appended to the existing state.\n",
    "    {'messages': new_messages},\n",
    ")\n",
    "\n",
    "print(\"\\n\\nLast 2 messages;\")\n",
    "print(graph.get_state(config).values['messages'][-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpRUWIKLtRfF"
   },
   "source": [
    "Now the graph is complete, since we have provided the final response message! Since state updates simulate a graph step, they even generate corresponding traces.\n",
    "\n",
    "Our new messages are *appended* to the messages already in the state.\n",
    "```python\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "```\n",
    "We annotated `messages` with the pre-built `add_messages` function, which instructs the graph to append values to the existing list, rather than overwritting the list directly, so the messages we passed to `update_state` were appended here.\n",
    "\n",
    "The `update_state` function operates as if it were one of the nodes in our graph. By default, the update operation uses the node that was last executed, but we can manually specify it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1731361482134,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "S7gin4Vos5Bo",
    "outputId": "9d71ff73-4ad7-4af7-fa4e-3031b5f36a17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1efa0762-87a6-688e-8003-15fc2e5e6c89'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(\n",
    "    config,\n",
    "    {'messages': [AIMessage(content=\"I'm an AI expert!\")]},\n",
    "    # which node for this function to act as. It will automatically continue\n",
    "    # processing as if this node just ran.\n",
    "    as_node='chatbot',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQEnIqmGujK6"
   },
   "source": [
    "We just told the graph to treat the update `as_node=\"chatbot\"`. If we follow the diagram and stat from the `chatbot` node, we nautrally end up in the `tools_condition` edge and then `__end__` since our updated message lacks tool calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1731361484011,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "9SKIauBWugdR",
    "outputId": "10ad7036-9562-4775-8ed9-5a62ad5d63dc"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(\n",
    "    graph.get_graph().draw_mermaid_png()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HV39eNlAu2nX"
   },
   "source": [
    "We can inspect the curent state as before to confirm the checkpoint reflects our manual updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 145,
     "status": "ok",
     "timestamp": 1731361487458,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "z76hRPJou1R0",
    "outputId": "8e3b136b-7cc1-4ea0-8cb3-07d5aac20c56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='85325e49-d686-4e2f-a45c-58c62615e949', tool_call_id='toolu_01AyJjvNzsmBKyDWfR9YY8L6'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', additional_kwargs={}, response_metadata={}, id='fa7cd39c-6e60-42a2-92c0-7dff00dbec6a'), AIMessage(content=\"I'm an AI expert!\", additional_kwargs={}, response_metadata={}, id='a4603647-1a03-4209-b8cf-78236a286a76')]\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "print(snapshot.values['messages'][-3:])\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkWo-KS_vErl"
   },
   "source": [
    "We have continued to add AI messages to the state. Since we act as the `chatbot` and respond with an AIMessage that does not contain `tool_calls`, the graph knows that it has entered a fnished state (`next` is empty)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wofYdk3pvboQ"
   },
   "source": [
    "## What if we want to overwrite existing messages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69n4NVDFLAXQ"
   },
   "source": [
    "The `add_messages` function we used to annotate our graph's `State` controls how updates are made to the `messages` key. This function looks at any message IDs in the new `messages` list. If the ID matches a message in the existing state, `add_messages` overwrites the existing message with the new content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2598,
     "status": "ok",
     "timestamp": 1731361513903,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "YprOyRJFu_tL",
    "outputId": "ecfcbfe0-bc71-4ad8-815c-3862643057dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_019WQXXXx12LmV9maQs8mCNu', 'input': {'query': 'LangGraph framework for language models'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_019WQXXXx12LmV9maQs8mCNu)\n",
      " Call ID: toolu_019WQXXXx12LmV9maQs8mCNu\n",
      "  Args:\n",
      "    query: LangGraph framework for language models\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\n",
    "    'configurable': {'thread_id': '2'} # start a new thread\n",
    "}\n",
    "\n",
    "events = graph.stream(\n",
    "    {'messages': [('user', user_input)]},\n",
    "    config,\n",
    "    stream_mode='values',\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if 'messages' in event:\n",
    "        event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcHY99BHMFdC"
   },
   "source": [
    "Next, we update the tool invocation for our agent. We may want to search for human-in-the-loop workflows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1731361793933,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "XQR_yARHMBa1",
    "outputId": "2f1ac019-f1d2-4e37-ef9a-b46a460342db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "Message ID run-6d994a9c-953b-4ec2-823a-a86e8aa5890f-0\n",
      "{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph framework for language models'}, 'id': 'toolu_019WQXXXx12LmV9maQs8mCNu', 'type': 'tool_call'}\n",
      "Updated\n",
      "{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph human-in-the-loop workflow'}, 'id': 'toolu_019WQXXXx12LmV9maQs8mCNu', 'type': 'tool_call'}\n",
      "Message ID run-6d994a9c-953b-4ec2-823a-a86e8aa5890f-0\n",
      "\n",
      "\n",
      "Tool calls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'LangGraph human-in-the-loop workflow'},\n",
       "  'id': 'toolu_019WQXXXx12LmV9maQs8mCNu',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "snapshot = graph.get_state(config)\n",
    "existing_message = snapshot.values['messages'][-1]\n",
    "print(\"Original\")\n",
    "print('Message ID', existing_message.id)\n",
    "print(existing_message.tool_calls[0])\n",
    "\n",
    "new_tool_call = existing_message.tool_calls[0].copy()\n",
    "new_tool_call['args']['query'] = 'LangGraph human-in-the-loop workflow'\n",
    "new_messages = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[new_tool_call],\n",
    "    # IMPORTANT:\n",
    "    # The ID is how LangGraph knows to REPLACE the message in the state\n",
    "    # rather than APPEND this message\n",
    "    id=existing_message.id,\n",
    ")\n",
    "\n",
    "print(\"Updated\")\n",
    "print(new_messages.tool_calls[0])\n",
    "print('Message ID', new_messages.id)\n",
    "graph.update_state(\n",
    "    config,\n",
    "    {'messages': [new_messages]}\n",
    ")\n",
    "\n",
    "print('\\n\\nTool calls')\n",
    "graph.get_state(config).values['messages'][-1].tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVIOfTD6NOC6"
   },
   "source": [
    "We have modified the AI's tool invocation to search for \"LangGraph human-in-the-loop workflow\" instead of the simple \"LangGraph\".\n",
    "\n",
    "Now we can resume the graph by streaming with an input of `None` and the existing config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12280,
     "status": "ok",
     "timestamp": 1731361928623,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "c76VIFnONGY3",
    "outputId": "c0719fce-4b59-4b67-beed-0219ad865536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_019WQXXXx12LmV9maQs8mCNu', 'input': {'query': 'LangGraph framework for language models'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_019WQXXXx12LmV9maQs8mCNu)\n",
      " Call ID: toolu_019WQXXXx12LmV9maQs8mCNu\n",
      "  Args:\n",
      "    query: LangGraph human-in-the-loop workflow\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.youtube.com/watch?v=9BPCV5TYPmg\", \"content\": \"In this video, I'll show you how to handle persistence with LangGraph, enabling a unique Human-in-the-Loop workflow. This approach allows a human to grant an\"}, {\"url\": \"https://medium.com/@kbdhunga/implementing-human-in-the-loop-with-langgraph-ccfde023385c\", \"content\": \"Implementing a Human-in-the-Loop (HIL) framework in LangGraph with the Streamlit app provides a robust mechanism for user engagement and decision-making. By incorporating breakpoints and\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! I've found some useful information about LangGraph, particularly focusing on its human-in-the-loop capabilities. Let me summarize what I've learned for you:\n",
      "\n",
      "1. LangGraph and Human-in-the-Loop (HIL):\n",
      "   LangGraph supports human-in-the-loop workflows, which is a significant feature for creating more interactive and adaptable AI systems. This capability allows for human intervention and decision-making within the AI process.\n",
      "\n",
      "2. Persistence Handling:\n",
      "   There's a focus on handling persistence with LangGraph. This feature is crucial for maintaining state and allowing for more complex, multi-step processes that can be paused and resumed.\n",
      "\n",
      "3. Implementation with Streamlit:\n",
      "   LangGraph can be implemented with Streamlit, a popular Python library for creating web apps. This combination provides a robust mechanism for user engagement and decision-making in AI applications.\n",
      "\n",
      "4. Breakpoints:\n",
      "   The implementation of LangGraph with HIL involves incorporating breakpoints. These breakpoints likely serve as pause points in the workflow where human input or decision-making can be integrated.\n",
      "\n",
      "5. Flexibility and Control:\n",
      "   The human-in-the-loop approach in LangGraph seems to offer more flexibility and control over the AI process. It allows for human intervention at crucial points, which can be particularly useful for complex decision-making scenarios or when human expertise is needed to guide the AI.\n",
      "\n",
      "6. Video Tutorial:\n",
      "   There's a video tutorial available that demonstrates how to handle persistence with LangGraph, enabling a unique human-in-the-loop workflow. This could be a valuable resource if you want to see a practical implementation.\n",
      "\n",
      "7. Potential Applications:\n",
      "   While not explicitly stated in the search results, the human-in-the-loop capabilities of LangGraph suggest it could be particularly useful in fields like content moderation, medical diagnosis assistance, or any scenario where AI suggestions need human verification or refinement.\n",
      "\n",
      "LangGraph appears to be a powerful tool for creating more interactive and adaptable AI workflows, with a strong emphasis on integrating human expertise and decision-making into the process. Its ability to handle persistence and integrate with web frameworks like Streamlit makes it a versatile choice for developing sophisticated AI applications.\n",
      "\n",
      "Would you like me to delve deeper into any specific aspect of LangGraph, or do you have any questions about what I've summarized?\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    None,\n",
    "    config,\n",
    "    stream_mode='values',\n",
    ")\n",
    "for event in events:\n",
    "    if 'messages' in event:\n",
    "        event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwtxE4vvNrLF"
   },
   "source": [
    "Notice how the graph queries the search engine using our updated query term. We are able to manually override the LLM's search!\n",
    "\n",
    "All of this is reflected in the graph's checkpointed memory, meaning if we continue the conversation, it will recall all the *modified* state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3854,
     "status": "ok",
     "timestamp": 1731362068063,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "HvtXnQ82NkTh",
    "outputId": "7decf392-cbde-4be8-b686-fb293af608e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember what I am learning about?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Of course! You mentioned that you are learning LangGraph. I apologize for not explicitly restating that in my previous response. To refresh:\n",
      "\n",
      "You told me: \"I'm learning LangGraph.\"\n",
      "\n",
      "LangGraph is the topic you're currently studying and interested in. My previous explanation was aimed at providing you with information about LangGraph to support your learning process. Is there a specific aspect of LangGraph you'd like to focus on or any particular questions you have as you're learning about it?\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {'messages': (\n",
    "        'user',\n",
    "        'Remember what I am learning about?',\n",
    "    )},\n",
    "    config,\n",
    "    stream_mode='values',\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if 'messages' in event:\n",
    "        event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9tdiqRMOO-b"
   },
   "source": [
    "# Customizing State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIwxXoQ2pH4x"
   },
   "source": [
    "We have relied on a simple state with a list of messages so far. In this section, we will have a more complicated state to let our chatbot have the choice of relying on a human interruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3JQFwKvOIXR"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu4ig0c7p6R-"
   },
   "outputs": [],
   "source": [
    "# New State class\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # add new flag\n",
    "    ask_human: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FglfVCYjqFph"
   },
   "source": [
    "Next, we define a schema to show the model to let it decide to request assistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0Be11hvqFUs"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class RequestAssistance(BaseModel):\n",
    "    \"\"\"\n",
    "    Escalate the conversation to an expert. Use this if we are unable to assist directly or\n",
    "    if the user requires support beyond our permissions.\n",
    "\n",
    "    To use this function, relay the user's `request` so the expert can provide the right guidance.\n",
    "    \"\"\"\n",
    "    request: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDy5vSA7qgoI"
   },
   "source": [
    "Next, define the chatbot node. The primary modifidiaction is to flip the `ask_human` flag if we see that the chatbot has invoked the `RequestAssistance` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnI6KnFFqgHf"
   },
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "# We can bind the llm to a tool definition, a pydantic model, or a json schema\n",
    "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    response = llm_with_tools.invoke(state['messages'])\n",
    "    ask_human = False\n",
    "\n",
    "    if (\n",
    "        response.tool_calls\n",
    "        and response.tool_calls[0]['name'] == RequestAssistance.__name__\n",
    "    ):\n",
    "        ask_human = True\n",
    "\n",
    "    return {\n",
    "        'messages': [response],\n",
    "        'ask_human': ask_human,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1qJ0hFYs5rQ"
   },
   "source": [
    "Next, create the graph builder and add the chatbot and tools nodes to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1731420517971,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "gigc21n3roxF",
    "outputId": "65207642-2978-4e76-82fc-3f2da8601622"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7b8fff4adf00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node('chatbot', chatbot)\n",
    "graph_builder.add_node('tools', ToolNode(tools=tools))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qk4b_dgltH7Y"
   },
   "source": [
    "Next, create the \"human\" `node`, which is a placeholder in our graph that will trigger an interrupt. If the human does not manually update the state during the `interrupt`, it inserts a tool message so the LLM knows the user was requested but didn't respond. This node also unsets the `ask_human` flag so the graph knows not to revisit the node unless further requests are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 129,
     "status": "ok",
     "timestamp": 1731420861339,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "j_ySenHCtHUM",
    "outputId": "ae984b71-fae5-4b46-961e-b1e8b32f23af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7b8fff4adf00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "\n",
    "def create_response(response: str, ai_message: AIMessage):\n",
    "    return ToolMessage(\n",
    "        content=response,\n",
    "        tool_call_id=ai_message.tool_calls[0]['id'],\n",
    "    )\n",
    "\n",
    "\n",
    "def human_node(state: State):\n",
    "    new_messages = []\n",
    "    if not isinstance(state['messages'][-1], ToolMessage):\n",
    "        # Typically, the user will have updated the state during the interrupt.\n",
    "        # If they choose not to, we will include a placeholder ToolMessage to\n",
    "        # let the LLM continue.\n",
    "        new_messages.append(\n",
    "            create_response('No response from human.', state['messages'][-1])\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        # Append the new messages\n",
    "        'messages': new_messages,\n",
    "        # Unset the flag\n",
    "        'ask_human': False,\n",
    "    }\n",
    "\n",
    "\n",
    "graph_builder.add_node('human', human_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXUCnDlmubf9"
   },
   "source": [
    "Next, define the conditional logic. The `select_next_node` will route to the `human` node if the flag is set. Otherwise, it lets the prebuilt `tools_condition` function choose the next node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 125,
     "status": "ok",
     "timestamp": 1731421006611,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "FC22IopeubIs",
    "outputId": "d6a089db-83c4-4ba0-c535-dd2b20b9af1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7b8fff4adf00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_next_node(state: State):\n",
    "    if state['ask_human']:\n",
    "        return 'human'\n",
    "    # otherwise,\n",
    "    return tools_condition(state)\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    'chatbot',\n",
    "    select_next_node,\n",
    "    {'human': 'human', 'tools': 'tools', END: END},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRLQzOAovA23"
   },
   "source": [
    "Finally, we add the simple directed edges and compile the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53-JvOWqu7Mo"
   },
   "outputs": [],
   "source": [
    "graph_builder.add_edge('tools', 'chatbot')\n",
    "graph_builder.add_edge('human', 'chatbot')\n",
    "graph_builder.add_edge(START, 'chatbot')\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # We interrupt before 'human' here\n",
    "    interrupt_before=['human'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1731421113621,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "YJ_3LSYbvWH_",
    "outputId": "f028b76a-2867-41f0-c3e4-73e01b62620a"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(\n",
    "    graph.get_graph().draw_mermaid_png()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TodLH3CAvbbR"
   },
   "source": [
    "The chatbot can either request help from a human (chatbot -> select -> human), invoke the search engine tool (chatbot -> select -> action), or directly responsd (chatbot -> select -> end). Once an action or request has been made, the graph will transition back to the `chatbot` node to continue operatons.\n",
    "\n",
    "To see this graph in action. We will request for expert assistance to illustrate our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3646,
     "status": "ok",
     "timestamp": 1731421318298,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "3GdK12BhvYuW",
    "outputId": "88e4d055-cb9d-45cd-ea8a-850efa264b64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I need some expert guidance for building this AI agent. Could you request assistance for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to request assistance from an expert regarding guidance for building an AI agent. I'll use the RequestAssistance function to escalate your request to an expert who can provide more specific and detailed information. Let me do that for you right away.\", 'type': 'text'}, {'id': 'toolu_01TUZPVfjowi9FuPua6YKAiJ', 'input': {'request': 'The user needs expert guidance for building an AI agent. They are seeking assistance and specialized knowledge in this area.'}, 'name': 'RequestAssistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  RequestAssistance (toolu_01TUZPVfjowi9FuPua6YKAiJ)\n",
      " Call ID: toolu_01TUZPVfjowi9FuPua6YKAiJ\n",
      "  Args:\n",
      "    request: The user needs expert guidance for building an AI agent. They are seeking assistance and specialized knowledge in this area.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I need some expert guidance for building this AI agent. Could you request assistance for me?\"\n",
    "config = {'configurable': {'thread_id': '1'}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {'messages': [('user', user_input)]},\n",
    "    config,\n",
    "    stream_mode='values',\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if 'messages' in event:\n",
    "        event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMwwg2T0wUqK"
   },
   "source": [
    "The LLM has invoked the `RequestAssistance` tool we provided it, and the interrupt has been set. We can inspect the graph state to confirm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 128,
     "status": "ok",
     "timestamp": 1731421397977,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "FmSRwffGwJ2Y",
    "outputId": "cb09684b-2f49-412a-e6d2-41ce568d240f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human',)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oilfmp6WwfV9"
   },
   "source": [
    "The graph state is indeed **interrupted** before the `'human'` node. We can act as the \"expert\" in this scenario and manually update the state by adding a new ToolMessage with our input.\n",
    "\n",
    "Next, we respond to the chatbot's request by:\n",
    "1. Creating a `ToolMessage` with our response. This will be passed back to the `chatbot`.\n",
    "2. Calling `update_state` to manually update the graph state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1731421597794,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "q5V3gLZsweKD",
    "outputId": "ff10d6c3-6945-4d29-ef4a-23524db7dcbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1efa1022-0d75-6926-8002-3eb8e1dadde5'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message = snapshot.values['messages'][-1]\n",
    "human_response = (\n",
    "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
    "    \" It's much more reliable and extensible than simple autonomous agents.\"\n",
    ")\n",
    "\n",
    "tool_message = create_response(human_response, ai_message)\n",
    "graph.update_state(\n",
    "    config,\n",
    "    {'messages': [tool_message]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 144,
     "status": "ok",
     "timestamp": 1731421615571,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "l0JkOJIpxO73",
    "outputId": "647a0964-956b-4b4f-f87f-4799972a05ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='I need some expert guidance for building this AI agent. Could you request assistance for me?', additional_kwargs={}, response_metadata={}, id='51ea1237-f818-44bc-851a-85a9ba2232e5'),\n",
       " AIMessage(content=[{'text': \"Certainly! I'd be happy to request assistance from an expert regarding guidance for building an AI agent. I'll use the RequestAssistance function to escalate your request to an expert who can provide more specific and detailed information. Let me do that for you right away.\", 'type': 'text'}, {'id': 'toolu_01TUZPVfjowi9FuPua6YKAiJ', 'input': {'request': 'The user needs expert guidance for building an AI agent. They are seeking assistance and specialized knowledge in this area.'}, 'name': 'RequestAssistance', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01FRsWZFAqqn8nrqFLxB5Dgy', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 517, 'output_tokens': 131}}, id='run-7bf3b00d-4001-4f29-a128-e88eb4e8dc07-0', tool_calls=[{'name': 'RequestAssistance', 'args': {'request': 'The user needs expert guidance for building an AI agent. They are seeking assistance and specialized knowledge in this area.'}, 'id': 'toolu_01TUZPVfjowi9FuPua6YKAiJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 517, 'output_tokens': 131, 'total_tokens': 648, 'input_token_details': {}}),\n",
       " ToolMessage(content=\"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\", id='a68f6bd1-07ca-474b-9524-d915c329b7b1', tool_call_id='toolu_01TUZPVfjowi9FuPua6YKAiJ')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values['messages']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSjU5LQMxWRd"
   },
   "source": [
    "Next, resume the graph by invoking it with `None` as the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5144,
     "status": "ok",
     "timestamp": 1731421677534,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "vJWSL9n5xTR3",
    "outputId": "b9168089-cdff-4137-fa93-5b5d8e623a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for your patience. I've escalated your request to our expert team, and they have provided some initial guidance. Here's what they suggest:\n",
      "\n",
      "The experts recommend that you look into LangGraph for building your AI agent. They mention that LangGraph is a more reliable and extensible option compared to simple autonomous agents.\n",
      "\n",
      "LangGraph is likely a framework or tool designed specifically for creating complex AI agents. It seems to offer advantages in terms of reliability and extensibility, which are crucial factors when developing sophisticated AI systems.\n",
      "\n",
      "To follow up on this recommendation, you might want to:\n",
      "\n",
      "1. Research LangGraph to understand its features, capabilities, and how it compares to other agent-building frameworks.\n",
      "2. Look for documentation, tutorials, or getting started guides for LangGraph.\n",
      "3. Consider the specific requirements of your AI agent project and how LangGraph might address them.\n",
      "\n",
      "Do you have any specific questions about LangGraph or building AI agents that you'd like me to request further clarification on from the experts? Or would you like more information on any particular aspect of AI agent development?\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    None,\n",
    "    config,\n",
    "    stream_mode='values',\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if 'messages' in event:\n",
    "        event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dv_5GjeYxmj8"
   },
   "source": [
    "Now the chatbot has incorporated the updated state in its final response. Since everything was checkpointed, the \"expert\" human in the loop cloud perform the update at any time without impacting the graph's execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afA2nWIHx04y"
   },
   "source": [
    "# Time Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HokXXg3zzFeJ"
   },
   "source": [
    "In this section, we will \"rewind\" our graph by fetching a checkpoint using the graph's `get_state_history` method. We can then resume execution at this previous point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liFCYA1FxhMI"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IS5r_DGhzl7T"
   },
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    ask_human: bool\n",
    "\n",
    "\n",
    "class RequestAssistance(BaseModel):\n",
    "    \"\"\"\n",
    "    Escalate the conversation to an expert. Use this if we are unable to assist directly or\n",
    "    if the user requires support beyond our permissions.\n",
    "\n",
    "    To use this function, relay the user's `request` so the expert can provide the right guidance.\n",
    "    \"\"\"\n",
    "    request: str\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 128,
     "status": "ok",
     "timestamp": 1731428675286,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "zypksIJ5LOzm",
    "outputId": "225e9688-93b5-4e19-b4cd-6ab2d55e46c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7b8ffe1ff490>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chatbot(state: State):\n",
    "    response = llm_with_tools.invoke(state['messages'])\n",
    "    ask_human = False\n",
    "\n",
    "    if (\n",
    "        response.tool_calls\n",
    "        and response.tool_calls[0]['name'] == RequestAssistance.__name__\n",
    "    ):\n",
    "        ask_human = True\n",
    "\n",
    "    return {\n",
    "        'messages': [response],\n",
    "        'ask_human': ask_human,\n",
    "    }\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node('chatbot', chatbot)\n",
    "graph_builder.add_node('tools', ToolNode(tools=tools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1731428854967,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "UtQlgoNKL3Zx",
    "outputId": "efd7d1c9-3ee3-41cd-dc97-b67d826bd49e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7b8ffe1ff490>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_response(response: str, ai_message: AIMessage):\n",
    "    return ToolMessage(\n",
    "        content=response,\n",
    "        tool_call_id=ai_message.tool_calls[0]['id'],\n",
    "    )\n",
    "\n",
    "\n",
    "def human_node(state: State):\n",
    "    new_messages = []\n",
    "    if not isinstance(state['messages'][-1], ToolMessage):\n",
    "        # Typically, the user will have updated the state during the interrupt.\n",
    "        # If they choose not to, we will include a placeholder ToolMessage to\n",
    "        # let the LLM continue.\n",
    "        new_messages.append(\n",
    "            create_response('No response from human.', state['messages'][-1])\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        # append new messages\n",
    "        'messages': new_messages,\n",
    "        # unset the flag\n",
    "        'ask_human': False,\n",
    "    }\n",
    "\n",
    "\n",
    "graph_builder.add_node('human', human_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UssWkmgyM4QY"
   },
   "outputs": [],
   "source": [
    "def select_next_node(state: State):\n",
    "    if state['ask_human']:\n",
    "        return 'human'\n",
    "\n",
    "    # otherwise\n",
    "    return tools_condition(state)\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    'chatbot',\n",
    "    select_next_node,\n",
    "    {'human': 'human', 'tools': 'tools', END: END},\n",
    ")\n",
    "\n",
    "graph_builder.add_edge('tools', 'chatbot')\n",
    "graph_builder.add_edge('human', 'chatbot')\n",
    "graph_builder.add_edge(START, 'chatbot')\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=['human'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "executionInfo": {
     "elapsed": 153,
     "status": "ok",
     "timestamp": 1731428973015,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "8AfZNKuINPM8",
    "outputId": "26ad4328-e88f-45d1-f869-90e323019b6c"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(\n",
    "    graph.get_graph().draw_mermaid_png()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cNAvGOcNax-"
   },
   "source": [
    "Let's have our graph take a couple steps. Every step will be checkpointed in its state history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16439,
     "status": "ok",
     "timestamp": 1731429088158,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "KMF057RYNXhp",
    "outputId": "9f8af475-6c5f-4b6d-f60b-64a74f0675ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_01NwgkDb768BV3ok6wnFwHZb', 'input': {'query': 'LangGraph framework for language models'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01NwgkDb768BV3ok6wnFwHZb)\n",
      " Call ID: toolu_01NwgkDb768BV3ok6wnFwHZb\n",
      "  Args:\n",
      "    query: LangGraph framework for language models\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. ... LangChain is a framework for including AI from large language models inside data pipelines and applications. This tutorial provides an overview of what you can do with LangChain, including the problems that\"}, {\"url\": \"https://python.langchain.com/docs/introduction/\", \"content\": \"How to use tools in a chain How to migrate from legacy LangChain agents to LangGraph How to use chat models to call tools LangChain is a framework for developing applications powered by large language models (LLMs). Development: Build your applications using LangChain's open-source building blocks, components, and third-party integrations. langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. LangServe: Deploy LangChain chains as REST APIs. LangSmith: A developer platform that lets you debug, test, evaluate, and monitor LLM applications. Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for your interest in learning about LangGraph. Based on the search results, I can provide you with some information about LangGraph and its relationship to LangChain. Let me summarize the key points for you:\n",
      "\n",
      "1. What is LangGraph?\n",
      "LangGraph is a framework designed for defining, coordinating, and executing multiple LLM (Large Language Model) agents or chains in a structured manner. It's particularly useful for building stateful, multi-actor applications with LLMs.\n",
      "\n",
      "2. Relationship to LangChain:\n",
      "LangGraph integrates smoothly with LangChain, which is a broader framework for developing applications powered by large language models. However, it's worth noting that LangGraph can also be used independently of LangChain.\n",
      "\n",
      "3. LangChain Overview:\n",
      "Since LangGraph is closely related to LangChain, it's helpful to understand LangChain as well:\n",
      "   - LangChain is a framework for including AI from large language models inside data pipelines and applications.\n",
      "   - It provides open-source building blocks, components, and third-party integrations for developing LLM-powered applications.\n",
      "   - LangChain includes features like chains, agents, and retrieval strategies that make up an application's cognitive architecture.\n",
      "\n",
      "4. LangChain Ecosystem:\n",
      "LangChain is part of a larger ecosystem that includes:\n",
      "   - LangServe: For deploying LangChain chains as REST APIs.\n",
      "   - LangSmith: A developer platform for debugging, testing, evaluating, and monitoring LLM applications.\n",
      "\n",
      "5. Use Cases:\n",
      "LangGraph and LangChain can be used for various purposes, including:\n",
      "   - Using tools in a chain\n",
      "   - Migrating from legacy LangChain agents to LangGraph\n",
      "   - Using chat models to call tools\n",
      "\n",
      "6. Learning Resources:\n",
      "The search results mention a tutorial on DataCamp that provides an overview of what you can do with LangChain, which could be a good starting point for understanding the ecosystem that LangGraph is part of.\n",
      "\n",
      "As you're learning LangGraph, you might want to focus on:\n",
      "1. Understanding its core concepts and how it structures multi-agent LLM applications.\n",
      "2. Exploring how it integrates with LangChain and how it can be used independently.\n",
      "3. Practicing with examples that demonstrate stateful, multi-actor LLM applications.\n",
      "4. Familiarizing yourself with the broader LangChain ecosystem, as it's closely related and may enhance your use of LangGraph.\n",
      "\n",
      "Is there any specific aspect of LangGraph you'd like to know more about? Or do you have any questions about how it relates to LangChain or other LLM development frameworks?\n"
     ]
    }
   ],
   "source": [
    "config = {'configurable': {'thread_id': '1'}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        'messages': [\n",
    "            ('user', \"I'm learning LangGraph. Could you do some research on it for me?\"),\n",
    "        ]\n",
    "    },\n",
    "    config,\n",
    "    stream_mode='values',\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if 'messages' in event:\n",
    "        event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20603,
     "status": "ok",
     "timestamp": 1731429146176,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "KMfgorg6Nvql",
    "outputId": "38e03514-9f21-45d0-cde1-cd0de2b9500e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Yes that's helpful. Maybe I'll build an autonomous agent with it!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"That's an excellent idea! Building an autonomous agent with LangGraph is a great way to apply your learning and explore the capabilities of this framework. Let me provide some insights and suggestions to help you get started with this project.\", 'type': 'text'}, {'id': 'toolu_01Wfn9BfnEJ7gJa9uh6ZH8uT', 'input': {'query': 'building autonomous agents with LangGraph and LangChain'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01Wfn9BfnEJ7gJa9uh6ZH8uT)\n",
      " Call ID: toolu_01Wfn9BfnEJ7gJa9uh6ZH8uT\n",
      "  Args:\n",
      "    query: building autonomous agents with LangGraph and LangChain\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://blog.langchain.dev/how-to-build-the-ultimate-ai-automation-with-multi-agent-collaboration/\", \"content\": \"Introducing LangGraph. LangGraph is an extension of LangChain aimed at creating agent and multi-agent flows. It adds in the ability to create cyclical flows and comes with memory built in - both important attributes for creating agents. LangGraph provides developers with a high degree of controllability and is important for creating custom\"}, {\"url\": \"https://www.datacamp.com/tutorial/building-langchain-agents-to-automate-tasks-in-python\", \"content\": \"They are autonomous or semi-autonomous tools that can perform tasks, make decisions, and interact with other tools and APIs. They represent a significant leap forward in automating complex workflows with LLMs. In this article, you will learn how to build your own LangChain agents that can perform tasks not strictly possible with today's chat applications like ChatGPT. A LangChain agent is made up of several components, such as chat models, prompt templates, external tools, and other related constructs. We can already bind this set of tools to a chat model without creating an agent: After defining the model and the tools, we create the agent. Then we looked at the key components you need to know about in order to build an agent: chat models, tools, and prompt templates.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm excited to hear that you're considering building an autonomous agent with LangGraph! This is an excellent way to apply your learning and delve deeper into the capabilities of both LangGraph and LangChain. Based on the latest information, let me provide you with some guidance on how you can approach this project:\n",
      "\n",
      "1. Understanding LangGraph for Agent Creation:\n",
      "   - LangGraph is an extension of LangChain specifically aimed at creating agent and multi-agent flows.\n",
      "   - It adds the ability to create cyclical flows and comes with built-in memory, which are crucial for developing sophisticated agents.\n",
      "   - LangGraph provides developers with a high degree of controllability, which is important for creating custom agent behaviors.\n",
      "\n",
      "2. Components of an Autonomous Agent:\n",
      "When building your agent with LangGraph and LangChain, you'll likely work with these key components:\n",
      "   - Chat models: The underlying language model that powers your agent's understanding and generation capabilities.\n",
      "   - Prompt templates: Structured ways to format inputs for your language model.\n",
      "   - External tools: APIs or functions that your agent can use to perform actions or gather information.\n",
      "   - Memory: Built-in capability in LangGraph to maintain context and information across interactions.\n",
      "\n",
      "3. Steps to Build Your Agent:\n",
      "   a. Define your agent's purpose and capabilities.\n",
      "   b. Choose and set up the appropriate chat model.\n",
      "   c. Create necessary prompt templates.\n",
      "   d. Integrate relevant external tools and APIs.\n",
      "   e. Design the agent's flow using LangGraph, incorporating cyclical patterns if needed.\n",
      "   f. Implement memory to allow your agent to maintain context.\n",
      "   g. Test and refine your agent's performance.\n",
      "\n",
      "4. Advantages of Using LangGraph:\n",
      "   - Ability to create more complex, stateful agents compared to traditional LangChain agents.\n",
      "   - Better support for multi-agent systems and collaborative AI workflows.\n",
      "   - Enhanced control over the agent's decision-making process and flow of operations.\n",
      "\n",
      "5. Potential Use Cases:\n",
      "   - Task automation: Create agents that can perform complex, multi-step tasks autonomously.\n",
      "   - Decision support systems: Develop agents that can analyze data, make recommendations, and assist in decision-making processes.\n",
      "   - Interactive assistants: Build sophisticated chatbots or virtual assistants that can maintain context and perform actions.\n",
      "   - Workflow automation: Design agents that can manage and optimize business processes or research workflows.\n",
      "\n",
      "6. Best Practices:\n",
      "   - Start simple and gradually increase complexity as you become more familiar with LangGraph.\n",
      "   - Pay attention to prompt engineering, as it significantly impacts your agent's performance.\n",
      "   - Implement proper error handling and fallback mechanisms to make your agent more robust.\n",
      "   - Regularly test your agent with various scenarios to ensure it behaves as expected.\n",
      "\n",
      "7. Resources:\n",
      "   - Explore LangChain's documentation for detailed information on working with agents and tools.\n",
      "   - Look for tutorials or examples specifically related to LangGraph, as it's a newer extension of LangChain.\n",
      "   - Join community forums or discussion groups where developers share their experiences with LangGraph and LangChain.\n",
      "\n",
      "Building an autonomous agent with LangGraph is an exciting project that will give you hands-on experience with cutting-edge AI development techniques. As you progress, you'll gain valuable insights into how to create more sophisticated AI systems that can handle complex tasks and interactions.\n",
      "\n",
      "Do you have a specific type of autonomous agent in mind, or would you like suggestions on potential projects to start with?\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        'messages': [\n",
    "            ('user', \"Yes that's helpful. Maybe I'll build an autonomous agent with it!\")\n",
    "        ]\n",
    "    },\n",
    "    config,\n",
    "    stream_mode='values',\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if 'messages' in event:\n",
    "        event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOTZC_-9OABW"
   },
   "source": [
    "Now that we have had the agent take a couple of steps, we can `replay` the full state history to see everything that occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1731429264183,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "-7fVXnuHN8zq",
    "outputId": "3685b3c7-01c4-45c0-bda1-bf5143fd6bb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  8 Next,  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  7 Next,  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next,  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next,  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next,  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next,  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next,  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next,  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next,  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next,  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values['messages']), \"Next, \", state.next)\n",
    "    print('-'*80)\n",
    "\n",
    "    if len(state.values['messages']) == 6:\n",
    "        # We are somehow arbitrarily selecting a specific state based on\n",
    "        # the number of chat meesages in the state\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NFCtuPFOi4Q"
   },
   "source": [
    "Checkpoints are saved for every step of the graph. This spans invocations so we can rewind across a full thread's history. We picked out `to_replay` as a state to resume from. This is the state after the `chatbot` node in the second graph invocation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1731429405490,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "YRkbItj-OenV",
    "outputId": "ecfd8f2f-7253-4a15-a8a4-1c0caae94796"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"I'm learning LangGraph. Could you do some research on it for me?\", additional_kwargs={}, response_metadata={}, id='51e00848-4136-45eb-9505-e1d640154233'),\n",
       "  AIMessage(content=[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_01NwgkDb768BV3ok6wnFwHZb', 'input': {'query': 'LangGraph framework for language models'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01BU4M9QhgXP4edHVgMeA3eD', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 516, 'output_tokens': 115}}, id='run-9c2f92fc-07b4-4eed-acdc-0070e7d16c33-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph framework for language models'}, 'id': 'toolu_01NwgkDb768BV3ok6wnFwHZb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 516, 'output_tokens': 115, 'total_tokens': 631, 'input_token_details': {}}),\n",
       "  ToolMessage(content='[{\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. ... LangChain is a framework for including AI from large language models inside data pipelines and applications. This tutorial provides an overview of what you can do with LangChain, including the problems that\"}, {\"url\": \"https://python.langchain.com/docs/introduction/\", \"content\": \"How to use tools in a chain How to migrate from legacy LangChain agents to LangGraph How to use chat models to call tools LangChain is a framework for developing applications powered by large language models (LLMs). Development: Build your applications using LangChain\\'s open-source building blocks, components, and third-party integrations. langchain: Chains, agents, and retrieval strategies that make up an application\\'s cognitive architecture. LangServe: Deploy LangChain chains as REST APIs. LangSmith: A developer platform that lets you debug, test, evaluate, and monitor LLM applications. Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\"}]', name='tavily_search_results_json', id='0bb36805-1151-4ec8-9585-92bbf5b4b093', tool_call_id='toolu_01NwgkDb768BV3ok6wnFwHZb', artifact={'query': 'LangGraph framework for language models', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?', 'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial', 'content': 'LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. ... LangChain is a framework for including AI from large language models inside data pipelines and applications. This tutorial provides an overview of what you can do with LangChain, including the problems that', 'score': 0.99976224, 'raw_content': None}, {'title': 'Introduction |  LangChain', 'url': 'https://python.langchain.com/docs/introduction/', 'content': \"How to use tools in a chain How to migrate from legacy LangChain agents to LangGraph How to use chat models to call tools LangChain is a framework for developing applications powered by large language models (LLMs). Development: Build your applications using LangChain's open-source building blocks, components, and third-party integrations. langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. LangServe: Deploy LangChain chains as REST APIs. LangSmith: A developer platform that lets you debug, test, evaluate, and monitor LLM applications. Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\", 'score': 0.99890983, 'raw_content': None}], 'response_time': 2.71}),\n",
       "  AIMessage(content=\"Thank you for your interest in learning about LangGraph. Based on the search results, I can provide you with some information about LangGraph and its relationship to LangChain. Let me summarize the key points for you:\\n\\n1. What is LangGraph?\\nLangGraph is a framework designed for defining, coordinating, and executing multiple LLM (Large Language Model) agents or chains in a structured manner. It's particularly useful for building stateful, multi-actor applications with LLMs.\\n\\n2. Relationship to LangChain:\\nLangGraph integrates smoothly with LangChain, which is a broader framework for developing applications powered by large language models. However, it's worth noting that LangGraph can also be used independently of LangChain.\\n\\n3. LangChain Overview:\\nSince LangGraph is closely related to LangChain, it's helpful to understand LangChain as well:\\n   - LangChain is a framework for including AI from large language models inside data pipelines and applications.\\n   - It provides open-source building blocks, components, and third-party integrations for developing LLM-powered applications.\\n   - LangChain includes features like chains, agents, and retrieval strategies that make up an application's cognitive architecture.\\n\\n4. LangChain Ecosystem:\\nLangChain is part of a larger ecosystem that includes:\\n   - LangServe: For deploying LangChain chains as REST APIs.\\n   - LangSmith: A developer platform for debugging, testing, evaluating, and monitoring LLM applications.\\n\\n5. Use Cases:\\nLangGraph and LangChain can be used for various purposes, including:\\n   - Using tools in a chain\\n   - Migrating from legacy LangChain agents to LangGraph\\n   - Using chat models to call tools\\n\\n6. Learning Resources:\\nThe search results mention a tutorial on DataCamp that provides an overview of what you can do with LangChain, which could be a good starting point for understanding the ecosystem that LangGraph is part of.\\n\\nAs you're learning LangGraph, you might want to focus on:\\n1. Understanding its core concepts and how it structures multi-agent LLM applications.\\n2. Exploring how it integrates with LangChain and how it can be used independently.\\n3. Practicing with examples that demonstrate stateful, multi-actor LLM applications.\\n4. Familiarizing yourself with the broader LangChain ecosystem, as it's closely related and may enhance your use of LangGraph.\\n\\nIs there any specific aspect of LangGraph you'd like to know more about? Or do you have any questions about how it relates to LangChain or other LLM development frameworks?\", additional_kwargs={}, response_metadata={'id': 'msg_017uaxKtnf8jrBFBHzd8MQ4g', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 953, 'output_tokens': 615}}, id='run-66f7d8b6-c433-4f71-a974-8a9817a7764a-0', usage_metadata={'input_tokens': 953, 'output_tokens': 615, 'total_tokens': 1568, 'input_token_details': {}}),\n",
       "  HumanMessage(content=\"Yes that's helpful. Maybe I'll build an autonomous agent with it!\", additional_kwargs={}, response_metadata={}, id='f2fc2bd9-b13b-4701-8dac-f2098c7934d1'),\n",
       "  AIMessage(content=[{'text': \"That's an excellent idea! Building an autonomous agent with LangGraph is a great way to apply your learning and explore the capabilities of this framework. Let me provide some insights and suggestions to help you get started with this project.\", 'type': 'text'}, {'id': 'toolu_01Wfn9BfnEJ7gJa9uh6ZH8uT', 'input': {'query': 'building autonomous agents with LangGraph and LangChain'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01Qt1V4cMXUTo2xhQ7EESsTf', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 1586, 'output_tokens': 116}}, id='run-6d81ddd8-7f5c-4e48-818e-b6c774d14d8b-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'building autonomous agents with LangGraph and LangChain'}, 'id': 'toolu_01Wfn9BfnEJ7gJa9uh6ZH8uT', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1586, 'output_tokens': 116, 'total_tokens': 1702, 'input_token_details': {}})],\n",
       " 'ask_human': False}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replay.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9wUc3jUPKtd"
   },
   "source": [
    "Resuming from this point should call the **action** node next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1731429414708,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "dc4-rB9yPBC-",
    "outputId": "23f21991-73e1-429a-feb9-b10736715ba4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replay.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1731429425990,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "hPoKSKn5PDW3",
    "outputId": "b1d68c25-fafe-4ad9-9348-09d42faed8d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1efa113a-959b-6ff7-8006-4b1bce9b9bb2'}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replay.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uId7DM-POw5"
   },
   "source": [
    "The checkopint's config `to_replay.config` contains a `checkpoint_id` timestamp. Providing this `checkpoint_id` value tells LangGraph's checkpointer to load the state from that moment in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18261,
     "status": "ok",
     "timestamp": 1731429590927,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 360
    },
    "id": "YXE1iGoaPGHh",
    "outputId": "bb740fdb-ec52-424f-9172-431af53b9dcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"That's an excellent idea! Building an autonomous agent with LangGraph is a great way to apply your learning and explore the capabilities of this framework. Let me provide some insights and suggestions to help you get started with this project.\", 'type': 'text'}, {'id': 'toolu_01Wfn9BfnEJ7gJa9uh6ZH8uT', 'input': {'query': 'building autonomous agents with LangGraph and LangChain'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01Wfn9BfnEJ7gJa9uh6ZH8uT)\n",
      " Call ID: toolu_01Wfn9BfnEJ7gJa9uh6ZH8uT\n",
      "  Args:\n",
      "    query: building autonomous agents with LangGraph and LangChain\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://blog.langchain.dev/how-to-build-the-ultimate-ai-automation-with-multi-agent-collaboration/\", \"content\": \"Introducing LangGraph. LangGraph is an extension of LangChain aimed at creating agent and multi-agent flows. It adds in the ability to create cyclical flows and comes with memory built in - both important attributes for creating agents. LangGraph provides developers with a high degree of controllability and is important for creating custom\"}, {\"url\": \"https://www.datacamp.com/tutorial/building-langchain-agents-to-automate-tasks-in-python\", \"content\": \"They are autonomous or semi-autonomous tools that can perform tasks, make decisions, and interact with other tools and APIs. They represent a significant leap forward in automating complex workflows with LLMs. In this article, you will learn how to build your own LangChain agents that can perform tasks not strictly possible with today's chat applications like ChatGPT. A LangChain agent is made up of several components, such as chat models, prompt templates, external tools, and other related constructs. We can already bind this set of tools to a chat model without creating an agent: After defining the model and the tools, we create the agent. Then we looked at the key components you need to know about in order to build an agent: chat models, tools, and prompt templates.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm excited to hear that you're considering building an autonomous agent with LangGraph! This is indeed an excellent way to apply your knowledge and create something practical. Based on the latest information, let me provide you with some guidance on how you can approach this project:\n",
      "\n",
      "1. Understanding LangGraph for Agent Development:\n",
      "   - LangGraph is an extension of LangChain specifically designed for creating agent and multi-agent flows.\n",
      "   - It adds the ability to create cyclical flows and comes with built-in memory, which are crucial for developing sophisticated agents.\n",
      "   - LangGraph offers developers a high degree of controllability, which is important for creating custom agent behaviors.\n",
      "\n",
      "2. Components of an Autonomous Agent:\n",
      "When building your agent with LangGraph, you'll likely work with several key components:\n",
      "   - Chat models: These form the core of your agent's language understanding and generation capabilities.\n",
      "   - Prompt templates: These help structure the input to your language model for consistent and effective responses.\n",
      "   - External tools: These allow your agent to interact with APIs, databases, or other external resources.\n",
      "   - Memory: LangGraph's built-in memory capabilities will help your agent maintain context and learn from interactions.\n",
      "\n",
      "3. Advantages of Using LangGraph:\n",
      "   - Cyclical Flows: Unlike simple linear chains, LangGraph allows you to create more complex, cyclical decision-making processes.\n",
      "   - Built-in Memory: This feature helps your agent maintain context across multiple interactions or steps in a task.\n",
      "   - Integration with LangChain: You can leverage the broader LangChain ecosystem for additional tools and capabilities.\n",
      "\n",
      "4. Steps to Build Your Agent:\n",
      "   a. Define your agent's purpose and the tasks it should perform.\n",
      "   b. Choose appropriate language models and tools for your agent's needs.\n",
      "   c. Design the agent's decision-making flow using LangGraph's cyclical capabilities.\n",
      "   d. Implement memory to allow your agent to learn and adapt.\n",
      "   e. Integrate external tools and APIs as needed for your agent's functionality.\n",
      "   f. Test and refine your agent's performance.\n",
      "\n",
      "5. Potential Project Ideas:\n",
      "   - Task Automation Agent: Create an agent that can break down complex tasks and execute them step by step.\n",
      "   - Research Assistant: Develop an agent that can gather information from multiple sources and synthesize it.\n",
      "   - Personal Productivity Agent: Build an agent that helps manage schedules, set reminders, and organize information.\n",
      "   - Customer Service Bot: Create an agent that can handle customer inquiries and escalate complex issues when necessary.\n",
      "\n",
      "6. Best Practices:\n",
      "   - Start Simple: Begin with a basic agent and gradually add complexity.\n",
      "   - Focus on Robustness: Ensure your agent can handle unexpected inputs or situations gracefully.\n",
      "   - Prioritize Ethical Considerations: Be mindful of potential biases and ethical implications in your agent's decision-making.\n",
      "   - Iterate and Improve: Continuously test and refine your agent based on its performance and user feedback.\n",
      "\n",
      "Remember, building an autonomous agent is an iterative process. Start with a clear goal, implement the basic functionality, and then gradually enhance its capabilities. LangGraph's flexibility will allow you to evolve your agent's complexity as you become more comfortable with the framework.\n",
      "\n",
      "Do you have a specific type of autonomous agent in mind, or would you like to discuss potential project ideas further? I'd be happy to help you brainstorm or provide more detailed guidance on any aspect of the development process.\n"
     ]
    }
   ],
   "source": [
    "# `checkpoint_id` in the `to_replay.config` corresponds to a state we persisted to our checkpointer\n",
    "for event in graph.stream(\n",
    "    None,\n",
    "    to_replay.config,\n",
    "    stream_mode='values',\n",
    "):\n",
    "    if 'messages' in event:\n",
    "        event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htxY_BQVPp9h"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPN/zmNdmW3JPJ4nq49O4ms",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
