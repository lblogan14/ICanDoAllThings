{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMRngvhQaWEen+KtwW+5wQT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install -qU diffusers transformers accelerate peft"],"metadata":{"id":"kpLMDguHLkrk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Trajectory Consistency Distillation-LoRA"],"metadata":{"id":"GWZ_CqsUDKo-"}},{"cell_type":"markdown","source":["**Trajectory Consistency Distillation (TCD)** enables a model to generate higher quality and more detailed images with fewer steps. Owing to the effective error mitigation during the distillation process, TCD demonstrates superior performance even under conditions of large inference steps.\n","\n","The major advantages of TCD are:\n","* Better than Teacher: TCD demonstrates superior generative quality at both small and large inference steps and exceeds the performance of `DPM-Solver++(2S)` with SDXL. There is no additional discriminator or LPIPS supervision included during TCD training.\n","* Flexible Inference Steps: The inference steps for TCD sampling can be freely adjusted without adversely affecting the image quality.\n","* Freely change detail level: During inference, the level of detail in the image can be adjusted with a single hyperparameter, *gamma*.\n","\n","For large models like SDXL, TCD is trained with LoRA to reduce memory usage."],"metadata":{"id":"JzwFDMbFIUsr"}},{"cell_type":"markdown","source":["## General tasks"],"metadata":{"id":"UNfSY5UxLmiF"}},{"cell_type":"markdown","source":["We will use `StableDiffusionXLPipeline` and `TCDScheduler`.\n","\n","Notes for TCD-LoRA inference:\n","* Keep the `num_inference_steps` between 4 and 50\n","* Set `eta` (to control stochasticity at each step) between 0 and 1. We should use a higher `eta` when increasing the number of inference steps, but the downside is that a larger `eta` in `TCDScheduler` leads to blurrier images. A value of 0.3 is recommended to produce good results."],"metadata":{"id":"x3FPPCOWOy46"}},{"cell_type":"markdown","source":["##### text-to-image"],"metadata":{"id":"7VxAZM4tZw7A"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"640lj_mpDEYy"},"outputs":[],"source":["from diffusers import StableDiffusionXLPipeline, TCDScheduler\n","import torch\n","\n","device = 'cuda'\n","base_model_id = 'stabilityai/stable-diffusion-xl-base-1.0'\n","tcd_lora_id = 'h1t/TCD-SDXL-LoRA'\n","\n","pipe = StableDiffusionXLPipeline.from_pretrained(\n","    base_model_id,\n","    torch_dtype=torch.float16,\n","    variant='fp16'\n",").to(device)\n","\n","# swtich to TCDScheudler\n","pipe.scheduler = TCDScheduler.from_config(pipe.scheduler.config)\n","\n","# load TCS-LoRA\n","pipe.load_lora_weights(tcd_lora_id)\n","pipe.fuse_lora()"]},{"cell_type":"code","source":["prompt = \"Painting of the orange cat Otto von Garfield, Count of Bismarck-Sch√∂nhausen, Duke of Lauenburg, Minister-President of Prussia. Depicted wearing a Prussian Pickelhaube and eating his favorite meal - lasagna.\"\n","generator = torch.Generator(device).manual_seed(111)\n","\n","image = pipe(\n","    prompt,\n","    num_inference_steps=4,\n","    guidance_scale=0,\n","    eta=0.3,\n","    generator=generator,\n",").images[0]\n","image"],"metadata":{"id":"UwTq12UcaP8H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = pipe(\n","    prompt,\n","    num_inference_steps=30,\n","    guidance_scale=0,\n","    eta=0.3,\n","    generator=generator,\n",").images[0]\n","image"],"metadata":{"id":"Wka53n5SabZu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### inpainting"],"metadata":{"id":"Rpkejt5jadvX"}},{"cell_type":"code","source":["from diffusers import AutoPipelineForInpainting, TCDScheduler\n","from diffusers.utils import load_image, make_image_grid\n","import torch\n","\n","device = 'cuda'\n","base_model_id = 'diffusers/stable-diffusion-xl-1.0-inpainting-0.1'\n","tcd_lora_id = 'h1t/TCD-SDXL-LoRA'\n","\n","pipe = AutoPipelineForInpainting.from_pretrained(\n","    base_model_id,\n","    torch_dtype=float16,\n","    variant='fp16'\n",").to(device)\n","\n","pipe.scheduler = TCDScheduler.from_config(pipe.scheduler.config)\n","pipe.load_lora_weights(tcd_lora_id)\n","pipe.fuse_lora()"],"metadata":{"id":"kaQ99tODafPq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\n","mask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n","\n","init_image = load_image(img_url).resize((1024, 1024))\n","mask_image = load_image(mask_url).resize((1024, 1024))\n","\n","prompt = 'a tiger sitting on a park bench'\n","generator = torch.Generator(device).manual_seed(111)\n","\n","image = pipe(\n","    prompt,\n","    image=init_image,\n","    mask_image=mask_image,\n","    num_inference_steps=8,\n","    guidance_scale=0,\n","    eta=0.3,\n","    strength=0.99 # make sure to use strength below 1.0\n","    generator=generator,\n",").images[0]\n","make_image_grid([init_image, mask_image, image], rows=1, cols=3)"],"metadata":{"id":"VUTc1bnYbGQj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = pipe(\n","    prompt,\n","    image=init_image,\n","    mask_image=mask_image,\n","    num_inference_steps=30,\n","    guidance_scale=0,\n","    eta=0.3,\n","    strength=0.99 # make sure to use strength below 1.0\n","    generator=generator,\n",").images[0]\n","make_image_grid([init_image, mask_image, image], rows=1, cols=3)"],"metadata":{"id":"7kWH6OXBbbCs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Community models"],"metadata":{"id":"oPjmQQkdbdTc"}},{"cell_type":"code","source":["from diffusers import StableDiffusionXLPipeline, TCDScheduler\n","import torch\n","\n","device = 'cuda'\n","# let's use a finetuned SDXL\n","base_model_id = 'cagliostrolab/animagine-xl-3.0'\n","tcd_lora_id = 'h1t/TCD-SDXL-LoRA'\n","\n","pipe = StableDiffusionXLPipeline.from_pretrained(\n","    base_model_id,\n","    torch_dtype=torch.float16,\n","    variant='fp16'\n",").to(device)\n","\n","pipe.scheduler = TCDScheduler.from_config(pipe.scheduler.config)\n","pipe.load_lora_weights(tcd_lora_id)\n","pipe.fuse_lora()"],"metadata":{"id":"8EQmBm-jbev3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"A man, clad in a meticulously tailored military uniform, stands with unwavering resolve. The uniform boasts intricate details, and his eyes gleam with determination. Strands of vibrant, windswept hair peek out from beneath the brim of his cap.\"\n","generator = torch.Generator(device).manual_seed(111)\n","\n","image = pipe(\n","    prompt,\n","    num_infernence_steps=8,\n","    guidance_scale=0,\n","    eta=0.3,\n","    generator=generator,\n",").images[0]\n","image"],"metadata":{"id":"cgwN_CeSb4Mv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can also combine other LoRA with TCD-LoRA"],"metadata":{"id":"K3L0YqB6cDXd"}},{"cell_type":"code","source":["from diffusers import StableDiffusionXLPipeline, TCDScheduler\n","import torch\n","\n","device = 'cuda'\n","base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n","tcd_lora_id = \"h1t/TCD-SDXL-LoRA\"\n","styled_lora_id = \"TheLastBen/Papercut_SDXL\"\n","\n","pipe = StableDiffusionXLPipeline.from_pretrained(\n","    base_model_id,\n","    torch_dtype=torch.float16,\n","    variant=\"fp16\"\n",").to(device)\n","# switch to TCS scheduler\n","pipe.scheduler = TCDScheduler.from_config(pipe.scheduler.config)\n","# load TCS-LoRA\n","pipe.load_lora_weights(tcd_lora_id, adapter_name=\"tcd\")\n","# load style LoRA\n","pipe.load_lora_weights(styled_lora_id, adapter_name=\"style\")\n","pipe.set_adapters([\"tcd\", \"style\"], adapter_weights=[1.0, 1.0])"],"metadata":{"id":"bZFXqcrrcLKz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"papercut of a winter mountain, snow\"\n","generator = torch.Generator(device).manual_seed(111)\n","\n","image = pipe(\n","    prompt,\n","    num_inference_steps=4,\n","    guidance_scale=0,\n","    eta=0.3,\n","    generator=generator,\n",").images[0]\n","image"],"metadata":{"id":"pN6V484TciK2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Adapters"],"metadata":{"id":"AJcZFnAncsHj"}},{"cell_type":"markdown","source":["### ControlNet"],"metadata":{"id":"VD2jSfd9c3sl"}},{"cell_type":"markdown","source":["#### Depth ControlNet"],"metadata":{"id":"aCVctQWedoKy"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from PIL import Image\n","from transformers import DPTImageProcessor, DPTForDepthEstimation\n","from diffusers import ControlNetModel, StableDiffusionXLControlNetPipeline, TCDScheduler\n","from diffusers.utils import load_image, make_image_grid\n","\n","device = 'cuda'\n","\n","base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n","controlnet_id = \"diffusers/controlnet-depth-sdxl-1.0\"\n","tcd_lora_id = \"h1t/TCD-SDXL-LoRA\"\n","\n","# ControlNet\n","controlnet = ControlNetModel.from_pretrained(\n","    controlnet_id,\n","    torch_dtype=torch.float16,\n","    variant='fp16'\n",")\n","\n","# SDXL\n","pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n","    base_model_id,\n","    controlnet=controlnet,\n","    torch_dtype=torch.float16,\n","    variant='fp16'\n",").to(device)\n","pipe.enable_model_cpu_offload()\n","\n","# TCD\n","pipe.scheduler = TCDScheduler.from_config(pipe.scheduler.config)\n","pipe.load_lora_weights(tcd_lora_id)\n","pipe.fuse_lora()"],"metadata":{"id":"0KaSWPpJcs5a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# depth-map extractor\n","feature_extractor = DPTImageProcessor.from_pretrained('Intel/dpt-hybrid-midas')\n","depth_estimator = DPTForDepthEstimation.from_pretrained('Intel/dpt-hybrid-midas').to(device)\n","\n","\n","def get_depth_map(image):\n","    image = feature_extractor(\n","        image=image,\n","        return_tensors='pt'\n","    ).pixel_values.to(device)\n","\n","    with torch.no_grad(), torch.autocast(device):\n","        depth_map = depth_estimator(image).predicted_depth\n","\n","    depth_map = torch.nn.functional.interpolate(\n","        depth_map.unsqueeze(1),\n","        size=(1024, 1024),\n","        mode='bicubic',\n","        align_corners=False\n","    )\n","\n","    depth_min = torch.amin(depth_map, dim=[1,2,3], keepdim=True)\n","    depth_max = torch.amax(depth_map, dim=[1,2,3], keepdim=True)\n","    depth_map = (depth_map - depth_min) / (depth_max - depth_min)\n","\n","    image = torch.cat([depth_map] * 3, dim=1)\n","    image = image.permute(0, 2, 3, 1).cpu().numpy()[0]\n","    image = Image.fromarray((image * 255).clip(0, 255).astype(np.uint8))\n","\n","    return image"],"metadata":{"id":"aqnUCAUUeYcp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["init_image = load_image(\"https://huggingface.co/lllyasviel/sd-controlnet-depth/resolve/main/images/stormtrooper.png\")\n","depth_image = get_depth_map(init_image)"],"metadata":{"id":"zwPlqzobfctR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = 'stormtrooper lecture, photorealistic'\n","controlnet_conditioning_scale = 0.5\n","generator = torch.Generator(device).manual_seed(111)\n","\n","image = pipe(\n","    prompt,\n","    image=depth_image,\n","    controlnet_conditioning_scale=controlnet_conditioning_scale,\n","    num_inference_steps=4,\n","    guidance_scale=0,\n","    eta=0.3,\n","    generator=generator,\n",").images[0]\n","make_image_grid([init_image, depth_image, image], rows=1, cols=3)"],"metadata":{"id":"YCIbF1LMffcl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Canny ControlNet"],"metadata":{"id":"pMPDsn78fyJJ"}},{"cell_type":"code","source":["import torch\n","from diffusers import ControlNetModel, StableDiffusionXLControlNetPipeline, TCDScheduler\n","from diffusers.utils import load_image, make_image_grid\n","\n","device = 'cuda'\n","\n","base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n","controlnet_id = \"diffusers/controlnet-canny-sdxl-1.0\"\n","tcd_lora_id = \"h1t/TCD-SDXL-LoRA\"\n","\n","# ControlNet\n","controlnet = ControlNetModel.from_pretrained(\n","    controlnet_id,\n","    torch_dtype=torch.float16,\n","    variant='fp16'\n",")\n","\n","# SDXL\n","pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n","    base_model_id,\n","    controlnet=controlnet,\n","    torch_dtype=torch.float16,\n","    variant='fp16'\n",").to(device)\n","pipe.enable_model_cpu_offload()\n","\n","# TCD\n","pipe.scheduler = TCDScheduler.from_config(pipe.scheduler.config)\n","pipe.load_lora_weights(tcd_lora_id)\n","pipe.fuse_lora()"],"metadata":{"id":"W37cTNV-f0Ne"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["canny_image = load_image(\"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd_controlnet/bird_canny.png\")\n","\n","prompt = \"ultrarealistic shot of a furry blue bird\"\n","controlnet_conditioning_scale = 0.5\n","generator = torch.Generator(device).manual_seed(111)\n","\n","image = pipe(\n","    prompt,\n","    image=canny_image,\n","    controlnet_conditioning_scale=controlnet_conditioning_scale,\n","    num_inference_steps=4,\n","    guidance_scale=0,\n","    eta=0.3,\n","    generator=generator,\n",").images[0]\n","make_image_grid([canny_image, image], rows=1, cols=2)"],"metadata":{"id":"kZD7oOH2f9rs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### IP-Adapter"],"metadata":{"id":"3h0AkJDVgN-T"}},{"cell_type":"code","source":["pip install -qU git+https://github.com/tencent-ailab/IP-Adapter.git"],"metadata":{"id":"wSw8bH8-hrN5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from diffusers import StableDiffusionXLPipeline, TCDScheduler\n","from diffusers.utils import load_image, make_image_grid\n","from ip_adapter import IPAdapterXL\n","\n","device = \"cuda\"\n","base_model_path = \"stabilityai/stable-diffusion-xl-base-1.0\"\n","image_encoder_path = \"sdxl_models/image_encoder\"\n","ip_ckpt = \"sdxl_models/ip-adapter_sdxl.bin\"\n","tcd_lora_id = \"h1t/TCD-SDXL-LoRA\"\n","\n","pipe = StableDiffusionXLPipeline.from_pretrained(\n","    base_model_path,\n","    torch_dtype=torch.float16,\n","    variant=\"fp16\"\n",")\n","pipe.scheduler = TCDScheduler.from_config(pipe.scheduler.config)\n","\n","pipe.load_lora_weights(tcd_lora_id)\n","pipe.fuse_lora()\n","\n","# IP-Adapter\n","ip_model = IPAdapterXL(\n","    pipe,\n","    image_encoder_path,\n","    ip_ckpt,\n","    device\n",")"],"metadata":{"id":"p7UY3HLUgPQX","executionInfo":{"status":"ok","timestamp":1739319610177,"user_tz":360,"elapsed":463,"user":{"displayName":"Bin Liu","userId":"03585165976699804089"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["ref_image = load_image(\"https://raw.githubusercontent.com/tencent-ailab/IP-Adapter/main/assets/images/woman.png\").resize((512, 512))\n","prompt = \"best quality, high quality, wearing sunglasses\"\n","\n","image = ip_model.generate(\n","    pil_image=ref_image,\n","    prompt=prompt,\n","    scale=0.5,\n","    num_samples=1,\n","    num_inference_steps=4,\n","    guidance_scale=0,\n","    eta=0.3,\n","    seed=0,\n",")[0]\n","\n","grid_image = make_image_grid([ref_image, image], rows=1, cols=2)"],"metadata":{"id":"SEbvZAQ9iAlV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### AnimateDiff"],"metadata":{"id":"6ygq6ConiHR2"}},{"cell_type":"code","source":["import torch\n","from diffusers import MotionAdapter, AnimateDiffPipeline, DDIMScheduler, TCDScheduler\n","from diffusers.utils import export_to_gif\n","\n","adapter = MotionAdapter.from_pretrained(\n","    'guoyww/animatediff-motion-adapter-v1-5'\n",")\n","\n","pipe = AnimateDiffPipeline.from_pretrained(\n","    'frankjoshua/toonyou_beta6',\n","    motion_adapter=adapter,\n",").to('cuda')\n","\n","# TCD-LoRA\n","pipe.scheduler = TCDScheduler.from_config(pipe.scheduler.config)\n","pipe.load_lora_weights('h1t/TCD-SDXL-LoRA', adapter_name='tcd')\n","\n","# Motion LoRA\n","pipe.load_lora_weights(\n","    'guoyww/animatediff-motion-lora-zoom-in',\n","    weight_name='diffusion_pytorch_model.safetensors'\n","    adapter_name='motion-lora'\n",")\n","\n","pipe.set_adapters(['tcd', 'motion-lora'], adapter_weights=[1.0, 1.2])"],"metadata":{"id":"Xy7zgjmWiJbJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"best quality, masterpiece, 1girl, looking at viewer, blurry background, upper body, contemporary, dress\"\n","generator = torch.manual_seed(111)\n","\n","frames = pipe(\n","    prompt,\n","    num_inference_steps=5,\n","    guidance_scale=0,\n","    cross_attention_kwargs={'scale': 1},\n","    num_frames=24,\n","    eta=0.3,\n","    generator=generator\n",").frames[0]\n","export_to_gif(frames, 'animation.gif')"],"metadata":{"id":"NOiu7EUYiyE8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qhR5g45bi_Zm"},"execution_count":null,"outputs":[]}]}