{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28716,
     "status": "ok",
     "timestamp": 1730467336307,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "n6k-qlS9s0Dm",
    "outputId": "26c46b05-2440-4fb7-dc1b-f60269298725"
   },
   "outputs": [],
   "source": [
    "!pip install -qU langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFQkCcgxs87j"
   },
   "source": [
    "# Build an Extraction Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IF4LYrMlv96t"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1730467336308,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "CuxFCZPcwALM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "langchain_api_key = 'your_langchain_api_key_here'  # Replace with your actual LangChain API key\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_API_KEY'] = langchain_api_key\n",
    "\n",
    "openai_api_key = 'your_openai_api_key_here'  # Replace with your actual OpenAI API key\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZYHuzJu3gMz"
   },
   "source": [
    "## The Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8XSnpQH3luv"
   },
   "source": [
    "First, we need to describe what information we want to extract from the text.\n",
    "\n",
    "We will use Pydantic to define an example schema to extract personal information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 667,
     "status": "ok",
     "timestamp": 1730467336970,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "9tEpjG9o3fTp"
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it.\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "\n",
    "    name: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description='The name of the person',\n",
    "    )\n",
    "    hair_color: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"The color of the person's hair if known\",\n",
    "    )\n",
    "    height_in_meters: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"The height measured in meters\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVr9ZNB_44x7"
   },
   "source": [
    "When defining schema:\n",
    "1. Document the **attributes** and the **schema** itself: This information is sent to the LLM and is used to improve the quality of information extraction.\n",
    "2. Do NOT force the LLM to make up information! Above we used `Optional` for the attributes allowing the LLM to output `None` if it does not know the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih5ArvHU5MIV"
   },
   "source": [
    "## The Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xm0RKfMu5OcW"
   },
   "source": [
    "We can create an information extractor using the schema we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4482,
     "status": "ok",
     "timestamp": 1730467341450,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "s4AjKaeQ44Sy"
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define a custom prompt to provide instructions and any additional context.\n",
    "# 1) We can add examples into the prompt template to improve extraction quality\n",
    "# 2) Introduce additional parameters to take context into account (e.g., include\n",
    "#    metadata about the document from which the text was extracted.)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Only extract relevant information from the text. \"\n",
    "            \"If you do not know the value of an attribute asked to extract, \"\n",
    "            \"return null for the attribute's value.\"\n",
    "        ),\n",
    "\n",
    "        # Check the how-to about improving performance with\n",
    "        # reference examples.\n",
    "        #MessagesPlaceholder(variable_name='examples'),\n",
    "        ('human', '{text}'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg-kMAZB6Nwh"
   },
   "source": [
    "We need a model that supports function/tool calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4761,
     "status": "ok",
     "timestamp": 1730467349204,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "c6-MTB-t6Mu6"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "runnable = prompt | llm.with_structured_output(schema=Person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1730468087797,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "v_cO4hcL6f-y",
    "outputId": "381d617b-6e32-4860-d643-df0717f1ad24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Haobo Sun', hair_color='blue', height_in_meters='1.83')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "text = \"Haobo Sun is 6 feet tall. His hair color is blue.\"\n",
    "result = runnable.invoke({'text': text})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 161,
     "status": "ok",
     "timestamp": 1730468101454,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "-16trzC75NOK",
    "outputId": "a9acb6f7-492b-43f7-85c3-e8602c186e87"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'My name is Haobo Sun, my hair color is blue, and my height is 1.83 meters.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"My name is {result.name}, my hair color is {result.hair_color}, and my height is {result.height_in_meters} meters.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsvV8X2A7dl4"
   },
   "source": [
    "## Multiple Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fNtEPzc7gcH"
   },
   "source": [
    "In most cases, we should be extracting a list of entities rather than a single entity.\n",
    "\n",
    "This can be achieved using pydantic by nesting models inside one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1730468456454,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "-1wd67WY6n62"
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it.\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "\n",
    "    name: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description='The name of the person',\n",
    "    )\n",
    "    hair_color: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"The color of the person's hair if known\",\n",
    "    )\n",
    "    height_in_meters: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"The height measured in meters\",\n",
    "    )\n",
    "\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about people\"\"\"\n",
    "\n",
    "    # Create a model so that we can extract multiple entities\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1166,
     "status": "ok",
     "timestamp": 1730468458680,
     "user": {
      "displayName": "Bin Liu",
      "userId": "03585165976699804089"
     },
     "user_tz": 300
    },
    "id": "I-qH9DKh7532",
    "outputId": "cd00a1d5-1fbf-4db6-973f-6167871d9c17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='Bin', hair_color='black', height_in_meters='1.91'), Person(name='Anna', hair_color='black', height_in_meters=None), Person(name='Haobo Sun', hair_color='blue', height_in_meters='1.91')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable = prompt | llm.with_structured_output(schema=Data)\n",
    "\n",
    "text = \"\"\"\n",
    "My name is Bin, my hair is black and I am 6 feet 3 inches tall.\n",
    "Anna has the same color hair as me.\n",
    "Haobo Sun has the same height as Bin but has blue hair.\n",
    "\"\"\"\n",
    "\n",
    "runnable.invoke({'text': text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wcO5kii8KVo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP2hUJXOCKkRqTT/Xsx3aA0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
